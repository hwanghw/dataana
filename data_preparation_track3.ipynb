{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "from datetime import date\n",
    "import random \n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ignore_features=['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV', 'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kaggle_csv(filepath, num_rows, root=\"D:/wangh/Kaggle/HomeCredit/Data\"):\n",
    "    csv_path = os.path.join(root, filepath)\n",
    "    \n",
    "    if not os.path.isfile(csv_path) :\n",
    "            csv_path = os.path.join(\"E:/SparkExerciseData/Kaggle\", filepath)\n",
    "        \n",
    "    return pd.read_csv(csv_path, nrows = num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = True):\n",
    "    # Read data and merge\n",
    "    df = load_kaggle_csv('application_train.csv', num_rows)\n",
    "    test_df = load_kaggle_csv('application_test.csv', num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    \n",
    "    # Categorical features: Binary features and One-Hot encoding\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    #AMT_INCOME_TOTAL 117000000 -> nan\n",
    "    df['AMT_INCOME_TOTAL'].replace(117000000, np.nan, inplace= True)\n",
    "    \n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = load_kaggle_csv('bureau.csv', num_rows)\n",
    "    bb = load_kaggle_csv('bureau_balance.csv', num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(columns= 'SK_ID_BUREAU', inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACT_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLS_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = load_kaggle_csv('previous_application.csv', num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APR_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REF_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = load_kaggle_csv('POS_CASH_balance.csv', num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = load_kaggle_csv('installments_payments.csv', num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INS_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INS_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = load_kaggle_csv('credit_card_balance.csv', num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(columns = ['SK_ID_PREV'], inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_AUC(alg, input_train, input_Y, input_test, input_test_Y) :\n",
    "    predictions_train = alg.predict(input_train)\n",
    "    predictions_prob_train = alg.predict_proba(input_train)[:,1]\n",
    "    print(\"Train Accuracy Score:\", metrics.accuracy_score(input_Y, predictions_train))\n",
    "    print(\"Train AUC Score:\", metrics.roc_auc_score(input_Y, predictions_prob_train))\n",
    "\n",
    "    predictions = alg.predict(input_test)\n",
    "    predictions_prob = alg.predict_proba(input_test)[:,1]\n",
    "\n",
    "    print(\"Accuracy Score:\", metrics.accuracy_score(input_test_Y, predictions))\n",
    "    print(\"AUC Score:\", metrics.roc_auc_score(input_test_Y, predictions_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_alg(alg, cv_df, num_folds=5, stratified = True):\n",
    "    print(\"Starting CV {}. CV shape: {}\".format(alg.__class__.__name__,cv_df.shape))\n",
    "    \n",
    "    global g_ignore_features\n",
    "    \n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "        \n",
    "    feats = [f for f in cv_df.columns if f not in g_ignore_features]\n",
    "    \n",
    "    cv_df_feats = cv_df[feats]\n",
    "    cv_df_TARGET = cv_df['TARGET']\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(cv_df_feats, cv_df_TARGET)):\n",
    "        train_x, train_y = cv_df_feats.iloc[train_idx], cv_df_TARGET.iloc[train_idx]\n",
    "        valid_x, valid_y = cv_df_feats.iloc[valid_idx], cv_df_TARGET.iloc[valid_idx]   \n",
    "        alg.fit(train_x, train_y)\n",
    "        print_AUC(alg, train_x, train_y, valid_x,  valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def fit_alg(alg, fit_train_df, fit_val_df=None):\n",
    "    print(\"Starting fit {}. fit shape: {}\".format(alg.__class__.__name__,fit_train_df.shape))\n",
    "\n",
    "    global g_ignore_features\n",
    "    \n",
    "    feats = [f for f in fit_train_df.columns if f not in g_ignore_features]\n",
    "    \n",
    "    fit_X_train = fit_train_df[feats]\n",
    "    fit_y_train = fit_train_df['TARGET']\n",
    "    \n",
    "    if fit_val_df is None :\n",
    "        alg.fit(fit_X_train, fit_y_train)\n",
    "    else :\n",
    "        fit_X_test = fit_val_df[feats]\n",
    "        fit_y_test = fit_val_df['TARGET']          \n",
    "        alg.fit(fit_X_train, fit_y_train)\n",
    "\n",
    "        print_AUC(alg, fit_X_train, fit_y_train, fit_X_test,  fit_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, clf, num_folds, stratified = False):\n",
    "    global g_ignore_features\n",
    "    \n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in g_ignore_features]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 100)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances-01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Bureau df shape: (305811, 122)\n",
      "Process bureau and bureau_balance - done in 27s\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 31s\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 16s\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 35s\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def prepare_data(debug = False):\n",
    "num_rows = 10000 if debug else None\n",
    "df = application_train_test(num_rows)\n",
    "with timer(\"Process bureau and bureau_balance\"):\n",
    "    bureau = bureau_and_balance(num_rows)\n",
    "    print(\"Bureau df shape:\", bureau.shape)\n",
    "    df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process previous_applications\"):\n",
    "    prev = previous_applications(num_rows)\n",
    "    print(\"Previous applications df shape:\", prev.shape)\n",
    "    df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process POS-CASH balance\"):\n",
    "    pos = pos_cash(num_rows)\n",
    "    print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "    df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process installments payments\"):\n",
    "    ins = installments_payments(num_rows)\n",
    "    print(\"Installments payments df shape:\", ins.shape)\n",
    "    df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process credit card balance\"):\n",
    "    cc = credit_card_balance(num_rows)\n",
    "    print(\"Credit card balance df shape:\", cc.shape)\n",
    "    df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "del bureau\n",
    "del prev\n",
    "del pos\n",
    "del ins  \n",
    "del cc\n",
    "gc.collect()\n",
    "#with timer(\"Run LightGBM with kfold\"):\n",
    "    #feat_importance = kfold_lightgbm(df, num_folds= 5, stratified = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.919271\n",
       "1.0    0.080729\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['TARGET'].value_counts()/train_df.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[col for col in df.columns if df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "ignore_features_median =  ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV']\n",
    "relevant_features_median = [col for col in df.columns if col not in ignore_features_median]\n",
    "df_imp = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "for col in relevant_features_median :\n",
    "    col_median = df_imp[col].median()\n",
    "    if math.isnan(col_median) : \n",
    "        print(\"is nan:\", col)\n",
    "        col_median=0.0\n",
    "    df_imp[col].fillna(col_median, inplace=True)\n",
    "train_df_imp = df_imp[df_imp['TARGET'].notnull()]\n",
    "test_df_imp = df_imp[df_imp['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TARGET'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp.columns[np.isfinite(df_imp).all()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size= 0.3, random_state=1001)\n",
    "for train_index, val_index in split.split(train_df, train_df['TARGET']):\n",
    "    X_train, X_val = train_df.loc[train_index], train_df.loc[val_index]\n",
    "    X_train_imp, X_val_imp = train_df_imp.loc[train_index], train_df_imp.loc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['TARGET'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219233    0.0\n",
       "41378     0.0\n",
       "128296    0.0\n",
       "284923    0.0\n",
       "271614    0.0\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['TARGET'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 816), (215257, 816), (92254, 816), (215257, 816), (92254, 816))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, X_train.shape, X_val.shape, X_train_imp.shape, X_val_imp.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.isfinite(X_train_imp).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imp.columns[np.isfinite(X_train_imp).all()==False]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_imp.isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "ignore_features_imputer =  ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV']\n",
    "relevant_features_imputer = [col for col in df.columns if col not in ignore_features_imputer]\n",
    "imp.fit(df[relevant_features_imputer])\n",
    "train_df_imp = pd.DataFrame(imp.transform(train_df[relevant_features_imputer]))\n",
    "train_df_imp = pd.concat([train_df[['TARGET','SK_ID_CURR']], train_df_imp], axis=1)\n",
    "test_df_imp = pd.DataFrame(imp.transform(test_df[relevant_features_imputer]).replace([np.inf, -np.inf], np.nan))\n",
    "test_df_imp = pd.concat([test_df[['TARGET','SK_ID_CURR']], test_df_imp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INS_PAYMENT_PERC_MAX</th>\n",
       "      <th>INS_PAYMENT_PERC_MEAN</th>\n",
       "      <th>INS_PAYMENT_PERC_SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      INS_PAYMENT_PERC_MAX  INS_PAYMENT_PERC_MEAN  INS_PAYMENT_PERC_SUM\n",
       "5687                   inf                    inf                   inf\n",
       "5688              1.000000               0.857143             12.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[relevant_features_median].iloc[5687:5689, 654:657].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INS_PAYMENT_PERC_MAX</th>\n",
       "      <th>INS_PAYMENT_PERC_MEAN</th>\n",
       "      <th>INS_PAYMENT_PERC_SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.617193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      INS_PAYMENT_PERC_MAX  INS_PAYMENT_PERC_MEAN  INS_PAYMENT_PERC_SUM\n",
       "5687                   1.0               1.000000             24.617193\n",
       "5688                   1.0               0.857143             12.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_imp[relevant_features_median].iloc[5687:5689, 654:657].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>EMERGENCYSTATE_MODE_nan</th>\n",
       "      <th>FONDKAPREMONT_MODE_not specified</th>\n",
       "      <th>FONDKAPREMONT_MODE_org spec account</th>\n",
       "      <th>FONDKAPREMONT_MODE_reg oper account</th>\n",
       "      <th>FONDKAPREMONT_MODE_reg oper spec account</th>\n",
       "      <th>FONDKAPREMONT_MODE_nan</th>\n",
       "      <th>HOUSETYPE_MODE_block of flats</th>\n",
       "      <th>HOUSETYPE_MODE_specific housing</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>HOUSETYPE_MODE_nan</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_nan</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Academic degree</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Incomplete higher</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Lower secondary</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondary / secondary special</th>\n",
       "      <th>NAME_EDUCATION_TYPE_nan</th>\n",
       "      <th>NAME_FAMILY_STATUS_Civil marriage</th>\n",
       "      <th>NAME_FAMILY_STATUS_Married</th>\n",
       "      <th>NAME_FAMILY_STATUS_Separated</th>\n",
       "      <th>NAME_FAMILY_STATUS_Single / not married</th>\n",
       "      <th>NAME_FAMILY_STATUS_Unknown</th>\n",
       "      <th>NAME_FAMILY_STATUS_Widow</th>\n",
       "      <th>NAME_FAMILY_STATUS_nan</th>\n",
       "      <th>NAME_HOUSING_TYPE_Co-op apartment</th>\n",
       "      <th>NAME_HOUSING_TYPE_House / apartment</th>\n",
       "      <th>NAME_HOUSING_TYPE_Municipal apartment</th>\n",
       "      <th>NAME_HOUSING_TYPE_Office apartment</th>\n",
       "      <th>NAME_HOUSING_TYPE_Rented apartment</th>\n",
       "      <th>NAME_HOUSING_TYPE_With parents</th>\n",
       "      <th>NAME_HOUSING_TYPE_nan</th>\n",
       "      <th>NAME_INCOME_TYPE_Businessman</th>\n",
       "      <th>NAME_INCOME_TYPE_Commercial associate</th>\n",
       "      <th>NAME_INCOME_TYPE_Maternity leave</th>\n",
       "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
       "      <th>NAME_INCOME_TYPE_State servant</th>\n",
       "      <th>NAME_INCOME_TYPE_Student</th>\n",
       "      <th>NAME_INCOME_TYPE_Unemployed</th>\n",
       "      <th>NAME_INCOME_TYPE_Working</th>\n",
       "      <th>NAME_INCOME_TYPE_nan</th>\n",
       "      <th>NAME_TYPE_SUITE_Children</th>\n",
       "      <th>NAME_TYPE_SUITE_Family</th>\n",
       "      <th>NAME_TYPE_SUITE_Group of people</th>\n",
       "      <th>NAME_TYPE_SUITE_Other_A</th>\n",
       "      <th>NAME_TYPE_SUITE_Other_B</th>\n",
       "      <th>NAME_TYPE_SUITE_Spouse, partner</th>\n",
       "      <th>NAME_TYPE_SUITE_Unaccompanied</th>\n",
       "      <th>NAME_TYPE_SUITE_nan</th>\n",
       "      <th>OCCUPATION_TYPE_Accountants</th>\n",
       "      <th>OCCUPATION_TYPE_Cleaning staff</th>\n",
       "      <th>OCCUPATION_TYPE_Cooking staff</th>\n",
       "      <th>OCCUPATION_TYPE_Core staff</th>\n",
       "      <th>OCCUPATION_TYPE_Drivers</th>\n",
       "      <th>OCCUPATION_TYPE_HR staff</th>\n",
       "      <th>OCCUPATION_TYPE_High skill tech staff</th>\n",
       "      <th>OCCUPATION_TYPE_IT staff</th>\n",
       "      <th>OCCUPATION_TYPE_Laborers</th>\n",
       "      <th>OCCUPATION_TYPE_Low-skill Laborers</th>\n",
       "      <th>OCCUPATION_TYPE_Managers</th>\n",
       "      <th>OCCUPATION_TYPE_Medicine staff</th>\n",
       "      <th>OCCUPATION_TYPE_Private service staff</th>\n",
       "      <th>OCCUPATION_TYPE_Realty agents</th>\n",
       "      <th>OCCUPATION_TYPE_Sales staff</th>\n",
       "      <th>OCCUPATION_TYPE_Secretaries</th>\n",
       "      <th>OCCUPATION_TYPE_Security staff</th>\n",
       "      <th>OCCUPATION_TYPE_Waiters/barmen staff</th>\n",
       "      <th>OCCUPATION_TYPE_nan</th>\n",
       "      <th>ORGANIZATION_TYPE_Advertising</th>\n",
       "      <th>ORGANIZATION_TYPE_Agriculture</th>\n",
       "      <th>ORGANIZATION_TYPE_Bank</th>\n",
       "      <th>ORGANIZATION_TYPE_Business Entity Type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Business Entity Type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Business Entity Type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Cleaning</th>\n",
       "      <th>ORGANIZATION_TYPE_Construction</th>\n",
       "      <th>ORGANIZATION_TYPE_Culture</th>\n",
       "      <th>ORGANIZATION_TYPE_Electricity</th>\n",
       "      <th>ORGANIZATION_TYPE_Emergency</th>\n",
       "      <th>ORGANIZATION_TYPE_Government</th>\n",
       "      <th>ORGANIZATION_TYPE_Hotel</th>\n",
       "      <th>ORGANIZATION_TYPE_Housing</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 10</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 11</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 12</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 13</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 5</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 6</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 7</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 8</th>\n",
       "      <th>ORGANIZATION_TYPE_Industry: type 9</th>\n",
       "      <th>ORGANIZATION_TYPE_Insurance</th>\n",
       "      <th>ORGANIZATION_TYPE_Kindergarten</th>\n",
       "      <th>ORGANIZATION_TYPE_Legal Services</th>\n",
       "      <th>ORGANIZATION_TYPE_Medicine</th>\n",
       "      <th>ORGANIZATION_TYPE_Military</th>\n",
       "      <th>ORGANIZATION_TYPE_Mobile</th>\n",
       "      <th>ORGANIZATION_TYPE_Other</th>\n",
       "      <th>ORGANIZATION_TYPE_Police</th>\n",
       "      <th>ORGANIZATION_TYPE_Postal</th>\n",
       "      <th>ORGANIZATION_TYPE_Realtor</th>\n",
       "      <th>ORGANIZATION_TYPE_Religion</th>\n",
       "      <th>ORGANIZATION_TYPE_Restaurant</th>\n",
       "      <th>ORGANIZATION_TYPE_School</th>\n",
       "      <th>ORGANIZATION_TYPE_Security</th>\n",
       "      <th>ORGANIZATION_TYPE_Security Ministries</th>\n",
       "      <th>ORGANIZATION_TYPE_Self-employed</th>\n",
       "      <th>ORGANIZATION_TYPE_Services</th>\n",
       "      <th>ORGANIZATION_TYPE_Telecom</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 5</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 6</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 7</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_University</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "      <th>ORGANIZATION_TYPE_nan</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>WALLSMATERIAL_MODE_nan</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_FRIDAY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_MONDAY</th>\n",
       "      <th>...</th>\n",
       "      <th>PREV_PRODUCT_COMBINATION_POS mobile with interest_MEAN</th>\n",
       "      <th>PREV_PRODUCT_COMBINATION_POS mobile without interest_MEAN</th>\n",
       "      <th>PREV_PRODUCT_COMBINATION_POS other with interest_MEAN</th>\n",
       "      <th>PREV_PRODUCT_COMBINATION_POS others without interest_MEAN</th>\n",
       "      <th>PREV_PRODUCT_COMBINATION_nan_MEAN</th>\n",
       "      <th>APR_AMT_ANNUITY_MIN</th>\n",
       "      <th>APR_AMT_ANNUITY_MAX</th>\n",
       "      <th>APR_AMT_ANNUITY_MEAN</th>\n",
       "      <th>APR_AMT_APPLICATION_MIN</th>\n",
       "      <th>APR_AMT_APPLICATION_MAX</th>\n",
       "      <th>APR_AMT_APPLICATION_MEAN</th>\n",
       "      <th>APR_AMT_CREDIT_MIN</th>\n",
       "      <th>APR_AMT_CREDIT_MAX</th>\n",
       "      <th>APR_AMT_CREDIT_MEAN</th>\n",
       "      <th>APR_APP_CREDIT_PERC_MIN</th>\n",
       "      <th>APR_APP_CREDIT_PERC_MAX</th>\n",
       "      <th>APR_APP_CREDIT_PERC_MEAN</th>\n",
       "      <th>APR_APP_CREDIT_PERC_VAR</th>\n",
       "      <th>APR_AMT_DOWN_PAYMENT_MIN</th>\n",
       "      <th>APR_AMT_DOWN_PAYMENT_MAX</th>\n",
       "      <th>APR_AMT_DOWN_PAYMENT_MEAN</th>\n",
       "      <th>APR_AMT_GOODS_PRICE_MIN</th>\n",
       "      <th>APR_AMT_GOODS_PRICE_MAX</th>\n",
       "      <th>APR_AMT_GOODS_PRICE_MEAN</th>\n",
       "      <th>APR_HOUR_APPR_PROCESS_START_MIN</th>\n",
       "      <th>APR_HOUR_APPR_PROCESS_START_MAX</th>\n",
       "      <th>APR_HOUR_APPR_PROCESS_START_MEAN</th>\n",
       "      <th>APR_RATE_DOWN_PAYMENT_MIN</th>\n",
       "      <th>APR_RATE_DOWN_PAYMENT_MAX</th>\n",
       "      <th>APR_RATE_DOWN_PAYMENT_MEAN</th>\n",
       "      <th>APR_DAYS_DECISION_MIN</th>\n",
       "      <th>APR_DAYS_DECISION_MAX</th>\n",
       "      <th>APR_DAYS_DECISION_MEAN</th>\n",
       "      <th>APR_CNT_PAYMENT_MEAN</th>\n",
       "      <th>APR_CNT_PAYMENT_SUM</th>\n",
       "      <th>REF_AMT_ANNUITY_MIN</th>\n",
       "      <th>REF_AMT_ANNUITY_MAX</th>\n",
       "      <th>REF_AMT_ANNUITY_MEAN</th>\n",
       "      <th>REF_AMT_APPLICATION_MIN</th>\n",
       "      <th>REF_AMT_APPLICATION_MAX</th>\n",
       "      <th>REF_AMT_APPLICATION_MEAN</th>\n",
       "      <th>REF_AMT_CREDIT_MIN</th>\n",
       "      <th>REF_AMT_CREDIT_MAX</th>\n",
       "      <th>REF_AMT_CREDIT_MEAN</th>\n",
       "      <th>REF_APP_CREDIT_PERC_MIN</th>\n",
       "      <th>REF_APP_CREDIT_PERC_MAX</th>\n",
       "      <th>REF_APP_CREDIT_PERC_MEAN</th>\n",
       "      <th>REF_APP_CREDIT_PERC_VAR</th>\n",
       "      <th>REF_AMT_DOWN_PAYMENT_MIN</th>\n",
       "      <th>REF_AMT_DOWN_PAYMENT_MAX</th>\n",
       "      <th>REF_AMT_DOWN_PAYMENT_MEAN</th>\n",
       "      <th>REF_AMT_GOODS_PRICE_MIN</th>\n",
       "      <th>REF_AMT_GOODS_PRICE_MAX</th>\n",
       "      <th>REF_AMT_GOODS_PRICE_MEAN</th>\n",
       "      <th>REF_HOUR_APPR_PROCESS_START_MIN</th>\n",
       "      <th>REF_HOUR_APPR_PROCESS_START_MAX</th>\n",
       "      <th>REF_HOUR_APPR_PROCESS_START_MEAN</th>\n",
       "      <th>REF_RATE_DOWN_PAYMENT_MIN</th>\n",
       "      <th>REF_RATE_DOWN_PAYMENT_MAX</th>\n",
       "      <th>REF_RATE_DOWN_PAYMENT_MEAN</th>\n",
       "      <th>REF_DAYS_DECISION_MIN</th>\n",
       "      <th>REF_DAYS_DECISION_MAX</th>\n",
       "      <th>REF_DAYS_DECISION_MEAN</th>\n",
       "      <th>REF_CNT_PAYMENT_MEAN</th>\n",
       "      <th>REF_CNT_PAYMENT_SUM</th>\n",
       "      <th>POS_MONTHS_BALANCE_MAX</th>\n",
       "      <th>POS_MONTHS_BALANCE_MEAN</th>\n",
       "      <th>POS_MONTHS_BALANCE_SIZE</th>\n",
       "      <th>POS_SK_DPD_MAX</th>\n",
       "      <th>POS_SK_DPD_MEAN</th>\n",
       "      <th>POS_SK_DPD_DEF_MAX</th>\n",
       "      <th>POS_SK_DPD_DEF_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Active_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Approved_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Canceled_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Completed_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Demand_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Returned to the store_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_XNA_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>POS_COUNT</th>\n",
       "      <th>INS_NUM_INSTALMENT_VERSION_NUNIQUE</th>\n",
       "      <th>INS_DPD_MAX</th>\n",
       "      <th>INS_DPD_MEAN</th>\n",
       "      <th>INS_DPD_SUM</th>\n",
       "      <th>INS_DBD_MAX</th>\n",
       "      <th>INS_DBD_MEAN</th>\n",
       "      <th>INS_DBD_SUM</th>\n",
       "      <th>INS_PAYMENT_PERC_MAX</th>\n",
       "      <th>INS_PAYMENT_PERC_MEAN</th>\n",
       "      <th>INS_PAYMENT_PERC_SUM</th>\n",
       "      <th>INS_PAYMENT_PERC_VAR</th>\n",
       "      <th>INS_PAYMENT_DIFF_MAX</th>\n",
       "      <th>INS_PAYMENT_DIFF_MEAN</th>\n",
       "      <th>INS_PAYMENT_DIFF_SUM</th>\n",
       "      <th>INS_PAYMENT_DIFF_VAR</th>\n",
       "      <th>INS_AMT_INSTALMENT_MAX</th>\n",
       "      <th>INS_AMT_INSTALMENT_MEAN</th>\n",
       "      <th>INS_AMT_INSTALMENT_SUM</th>\n",
       "      <th>INS_AMT_PAYMENT_MIN</th>\n",
       "      <th>INS_AMT_PAYMENT_MAX</th>\n",
       "      <th>INS_AMT_PAYMENT_MEAN</th>\n",
       "      <th>INS_AMT_PAYMENT_SUM</th>\n",
       "      <th>INS_DAYS_ENTRY_PAYMENT_MAX</th>\n",
       "      <th>INS_DAYS_ENTRY_PAYMENT_MEAN</th>\n",
       "      <th>INS_DAYS_ENTRY_PAYMENT_SUM</th>\n",
       "      <th>INS_COUNT</th>\n",
       "      <th>CC_MONTHS_BALANCE_MIN</th>\n",
       "      <th>CC_MONTHS_BALANCE_MAX</th>\n",
       "      <th>CC_MONTHS_BALANCE_MEAN</th>\n",
       "      <th>CC_MONTHS_BALANCE_SUM</th>\n",
       "      <th>CC_MONTHS_BALANCE_VAR</th>\n",
       "      <th>CC_AMT_BALANCE_MIN</th>\n",
       "      <th>CC_AMT_BALANCE_MAX</th>\n",
       "      <th>CC_AMT_BALANCE_MEAN</th>\n",
       "      <th>CC_AMT_BALANCE_SUM</th>\n",
       "      <th>CC_AMT_BALANCE_VAR</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_MIN</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_MAX</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_SUM</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_MIN</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_MAX</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_MEAN</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_SUM</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_VAR</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_MIN</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_MAX</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_MEAN</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_SUM</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_VAR</th>\n",
       "      <th>CC_AMT_RECIVABLE_MIN</th>\n",
       "      <th>CC_AMT_RECIVABLE_MAX</th>\n",
       "      <th>CC_AMT_RECIVABLE_MEAN</th>\n",
       "      <th>CC_AMT_RECIVABLE_SUM</th>\n",
       "      <th>CC_AMT_RECIVABLE_VAR</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_MIN</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_MAX</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_MEAN</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_SUM</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_MIN</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_MAX</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_MEAN</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_SUM</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_VAR</th>\n",
       "      <th>CC_SK_DPD_MIN</th>\n",
       "      <th>CC_SK_DPD_MAX</th>\n",
       "      <th>CC_SK_DPD_MEAN</th>\n",
       "      <th>CC_SK_DPD_SUM</th>\n",
       "      <th>CC_SK_DPD_VAR</th>\n",
       "      <th>CC_SK_DPD_DEF_MIN</th>\n",
       "      <th>CC_SK_DPD_DEF_MAX</th>\n",
       "      <th>CC_SK_DPD_DEF_MEAN</th>\n",
       "      <th>CC_SK_DPD_DEF_SUM</th>\n",
       "      <th>CC_SK_DPD_DEF_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Active_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Active_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Active_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Active_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Active_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Approved_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Approved_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Approved_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Approved_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Approved_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Completed_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Completed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Completed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Completed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Completed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Demand_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Demand_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Demand_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Demand_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Demand_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "      <th>CC_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>-1134.0</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>179055.00</td>\n",
       "      <td>179055.0</td>\n",
       "      <td>179055.000</td>\n",
       "      <td>179055.0</td>\n",
       "      <td>179055.0</td>\n",
       "      <td>179055.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>179055.00</td>\n",
       "      <td>179055.0</td>\n",
       "      <td>179055.000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-606.0</td>\n",
       "      <td>-606.0</td>\n",
       "      <td>-606.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11240.865</td>\n",
       "      <td>17581.5675</td>\n",
       "      <td>14743.06875</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>220500.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>108643.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960490</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134957.0475</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>191250.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-642.0</td>\n",
       "      <td>-403.0</td>\n",
       "      <td>-551.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.421053</td>\n",
       "      <td>388.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-315.421053</td>\n",
       "      <td>-5993.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96107.175</td>\n",
       "      <td>24997.602995</td>\n",
       "      <td>701364.0825</td>\n",
       "      <td>7.535426e+08</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>3825000.0</td>\n",
       "      <td>4.773968e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>60750.0</td>\n",
       "      <td>2.589711e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>3329.348636</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>1.918232e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7408.53</td>\n",
       "      <td>365.790547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649883e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4760.2575</td>\n",
       "      <td>1623.508258</td>\n",
       "      <td>37493.9325</td>\n",
       "      <td>2.873010e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65250.0</td>\n",
       "      <td>9856.811065</td>\n",
       "      <td>140431.2075</td>\n",
       "      <td>1.609631e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23436.0</td>\n",
       "      <td>3986.601378</td>\n",
       "      <td>118969.8525</td>\n",
       "      <td>3.508893e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>23914.47654</td>\n",
       "      <td>671808.1725</td>\n",
       "      <td>6.904978e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95477.3325</td>\n",
       "      <td>24765.001041</td>\n",
       "      <td>691906.0275</td>\n",
       "      <td>7.523544e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95513.49</td>\n",
       "      <td>24770.597235</td>\n",
       "      <td>692068.7475</td>\n",
       "      <td>7.525507e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.260137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>-828.0</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.533482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6737.310</td>\n",
       "      <td>98356.995</td>\n",
       "      <td>56553.990</td>\n",
       "      <td>68809.50</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>435436.500</td>\n",
       "      <td>68053.5</td>\n",
       "      <td>1035882.0</td>\n",
       "      <td>484191.00</td>\n",
       "      <td>0.868825</td>\n",
       "      <td>1.011109</td>\n",
       "      <td>0.949329</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6885.0</td>\n",
       "      <td>3442.50</td>\n",
       "      <td>68809.50</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>435436.500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100061</td>\n",
       "      <td>0.050030</td>\n",
       "      <td>-2341.0</td>\n",
       "      <td>-746.0</td>\n",
       "      <td>-1305.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11240.865</td>\n",
       "      <td>17581.5675</td>\n",
       "      <td>14743.06875</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>220500.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>108643.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960490</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134957.0475</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>191250.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-642.0</td>\n",
       "      <td>-403.0</td>\n",
       "      <td>-551.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-43.785714</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>6662.970</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>-544.0</td>\n",
       "      <td>-1385.320000</td>\n",
       "      <td>-34633.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96107.175</td>\n",
       "      <td>24997.602995</td>\n",
       "      <td>701364.0825</td>\n",
       "      <td>7.535426e+08</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>3825000.0</td>\n",
       "      <td>4.773968e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>60750.0</td>\n",
       "      <td>2.589711e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>3329.348636</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>1.918232e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7408.53</td>\n",
       "      <td>365.790547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649883e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4760.2575</td>\n",
       "      <td>1623.508258</td>\n",
       "      <td>37493.9325</td>\n",
       "      <td>2.873010e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65250.0</td>\n",
       "      <td>9856.811065</td>\n",
       "      <td>140431.2075</td>\n",
       "      <td>1.609631e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23436.0</td>\n",
       "      <td>3986.601378</td>\n",
       "      <td>118969.8525</td>\n",
       "      <td>3.508893e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>23914.47654</td>\n",
       "      <td>671808.1725</td>\n",
       "      <td>6.904978e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95477.3325</td>\n",
       "      <td>24765.001041</td>\n",
       "      <td>691906.0275</td>\n",
       "      <td>7.523544e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95513.49</td>\n",
       "      <td>24770.597235</td>\n",
       "      <td>692068.7475</td>\n",
       "      <td>7.525507e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.260137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.506155</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>24282.00</td>\n",
       "      <td>24282.0</td>\n",
       "      <td>24282.000</td>\n",
       "      <td>20106.0</td>\n",
       "      <td>20106.0</td>\n",
       "      <td>20106.00</td>\n",
       "      <td>1.207699</td>\n",
       "      <td>1.207699</td>\n",
       "      <td>1.207699</td>\n",
       "      <td>0.010021</td>\n",
       "      <td>4860.00</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>4860.00</td>\n",
       "      <td>24282.00</td>\n",
       "      <td>24282.0</td>\n",
       "      <td>24282.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.212008</td>\n",
       "      <td>0.212008</td>\n",
       "      <td>0.212008</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>-815.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11240.865</td>\n",
       "      <td>17581.5675</td>\n",
       "      <td>14743.06875</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>220500.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>108643.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960490</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134957.0475</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>191250.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-642.0</td>\n",
       "      <td>-403.0</td>\n",
       "      <td>-551.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-25.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>-727.0</td>\n",
       "      <td>-761.666667</td>\n",
       "      <td>-2285.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96107.175</td>\n",
       "      <td>24997.602995</td>\n",
       "      <td>701364.0825</td>\n",
       "      <td>7.535426e+08</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>3825000.0</td>\n",
       "      <td>4.773968e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>60750.0</td>\n",
       "      <td>2.589711e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>3329.348636</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>1.918232e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7408.53</td>\n",
       "      <td>365.790547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649883e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4760.2575</td>\n",
       "      <td>1623.508258</td>\n",
       "      <td>37493.9325</td>\n",
       "      <td>2.873010e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65250.0</td>\n",
       "      <td>9856.811065</td>\n",
       "      <td>140431.2075</td>\n",
       "      <td>1.609631e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23436.0</td>\n",
       "      <td>3986.601378</td>\n",
       "      <td>118969.8525</td>\n",
       "      <td>3.508893e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>23914.47654</td>\n",
       "      <td>671808.1725</td>\n",
       "      <td>6.904978e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95477.3325</td>\n",
       "      <td>24765.001041</td>\n",
       "      <td>691906.0275</td>\n",
       "      <td>7.523544e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95513.49</td>\n",
       "      <td>24770.597235</td>\n",
       "      <td>692068.7475</td>\n",
       "      <td>7.525507e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.260137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.506155</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.533482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2482.920</td>\n",
       "      <td>39954.510</td>\n",
       "      <td>21842.190</td>\n",
       "      <td>26912.34</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>352265.868</td>\n",
       "      <td>24219.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>343728.90</td>\n",
       "      <td>0.943934</td>\n",
       "      <td>1.250017</td>\n",
       "      <td>1.061032</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>2693.34</td>\n",
       "      <td>66987.0</td>\n",
       "      <td>34840.17</td>\n",
       "      <td>26912.34</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>352265.868</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>0.108994</td>\n",
       "      <td>0.217830</td>\n",
       "      <td>0.163412</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-345.600000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>32696.100</td>\n",
       "      <td>32696.1000</td>\n",
       "      <td>32696.10000</td>\n",
       "      <td>688500.0</td>\n",
       "      <td>688500.0</td>\n",
       "      <td>688500.0</td>\n",
       "      <td>906615.0</td>\n",
       "      <td>906615.0</td>\n",
       "      <td>906615.0</td>\n",
       "      <td>0.759418</td>\n",
       "      <td>0.759418</td>\n",
       "      <td>0.759418</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688500.0000</td>\n",
       "      <td>688500.0</td>\n",
       "      <td>688500.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9.619048</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>310.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>691786.890</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>2482.920</td>\n",
       "      <td>691786.890</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-271.625000</td>\n",
       "      <td>-4346.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1620000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.589711e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7408.53</td>\n",
       "      <td>365.790547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649883e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65250.0</td>\n",
       "      <td>9856.811065</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.609631e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.260137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>-1106.0</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.506155</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>0.533482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1834.290</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>12278.805</td>\n",
       "      <td>17176.50</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>150530.250</td>\n",
       "      <td>14616.0</td>\n",
       "      <td>284400.0</td>\n",
       "      <td>166638.75</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>1.175185</td>\n",
       "      <td>0.969650</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>3105.00</td>\n",
       "      <td>3676.5</td>\n",
       "      <td>3390.75</td>\n",
       "      <td>17176.50</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>150530.250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>0.218890</td>\n",
       "      <td>0.159516</td>\n",
       "      <td>-2357.0</td>\n",
       "      <td>-374.0</td>\n",
       "      <td>-1222.833333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>124.0</td>\n",
       "      <td>11240.865</td>\n",
       "      <td>17581.5675</td>\n",
       "      <td>14743.06875</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>220500.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>108643.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960490</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134957.0475</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>191250.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-642.0</td>\n",
       "      <td>-403.0</td>\n",
       "      <td>-551.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-33.636364</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>63.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.590909</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>22655.655</td>\n",
       "      <td>452.384318</td>\n",
       "      <td>29857.365</td>\n",
       "      <td>8.084830e+06</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>835985.340</td>\n",
       "      <td>0.180</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>806127.975</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-1032.242424</td>\n",
       "      <td>-68128.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96107.175</td>\n",
       "      <td>24997.602995</td>\n",
       "      <td>701364.0825</td>\n",
       "      <td>7.535426e+08</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>3825000.0</td>\n",
       "      <td>4.773968e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>60750.0</td>\n",
       "      <td>2.589711e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>3329.348636</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>1.918232e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7408.53</td>\n",
       "      <td>365.790547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649883e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4760.2575</td>\n",
       "      <td>1623.508258</td>\n",
       "      <td>37493.9325</td>\n",
       "      <td>2.873010e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65250.0</td>\n",
       "      <td>9856.811065</td>\n",
       "      <td>140431.2075</td>\n",
       "      <td>1.609631e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23436.0</td>\n",
       "      <td>3986.601378</td>\n",
       "      <td>118969.8525</td>\n",
       "      <td>3.508893e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>23914.47654</td>\n",
       "      <td>671808.1725</td>\n",
       "      <td>6.904978e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95477.3325</td>\n",
       "      <td>24765.001041</td>\n",
       "      <td>691906.0275</td>\n",
       "      <td>7.523544e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95513.49</td>\n",
       "      <td>24770.597235</td>\n",
       "      <td>692068.7475</td>\n",
       "      <td>7.525507e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.260137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 816 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AMT_ANNUITY  AMT_CREDIT  AMT_GOODS_PRICE  AMT_INCOME_TOTAL  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_YEAR  APARTMENTS_AVG  APARTMENTS_MEDI  APARTMENTS_MODE  BASEMENTAREA_AVG  BASEMENTAREA_MEDI  BASEMENTAREA_MODE  CNT_CHILDREN  CNT_FAM_MEMBERS  CODE_GENDER  COMMONAREA_AVG  COMMONAREA_MEDI  COMMONAREA_MODE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_ID_PUBLISH  DAYS_LAST_PHONE_CHANGE  DAYS_REGISTRATION  DEF_30_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  ELEVATORS_AVG  ELEVATORS_MEDI  ELEVATORS_MODE  ENTRANCES_AVG  ENTRANCES_MEDI  ENTRANCES_MODE  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  FLAG_CONT_MOBILE  FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_2  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  \\\n",
       "0      0      24700.5    406597.5         351000.0          202500.0                        0.0                         0.0                        0.0                        0.0                         0.0                         1.0          0.0247           0.0250           0.0252            0.0369             0.0369             0.0383             0              1.0            0          0.0143           0.0144           0.0144       -9461         -637.0            -2120                 -1134.0            -3648.0                       2.0                       2.0           0.00            0.00          0.0000         0.0690          0.0690          0.0690      0.083037      0.262949      0.139376                 1                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                0                 0                 0                1                0   \n",
       "1      1      35698.5   1293502.5        1129500.0          270000.0                        0.0                         0.0                        0.0                        0.0                         0.0                         0.0          0.0959           0.0968           0.0924            0.0529             0.0529             0.0538             0              2.0            1          0.0605           0.0608           0.0497      -16765        -1188.0             -291                  -828.0            -1186.0                       0.0                       0.0           0.08            0.08          0.0806         0.0345          0.0345          0.0345      0.311267      0.622246      0.533482                 1                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                0                 0                 0                1                0   \n",
       "2      2       6750.0    135000.0         135000.0           67500.0                        0.0                         0.0                        0.0                        0.0                         0.0                         0.0          0.0880           0.0874           0.0840            0.0765             0.0761             0.0749             0              1.0            0          0.0213           0.0210           0.0192      -19046         -225.0            -2531                  -815.0            -4260.0                       0.0                       0.0           0.00            0.00          0.0000         0.1379          0.1379          0.1379      0.506155      0.555912      0.729567                 1                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                0                 0                 0                0                0   \n",
       "3      3      29686.5    312682.5         297000.0          135000.0                        0.0                         0.0                        0.0                        0.0                         0.0                         1.0          0.0880           0.0874           0.0840            0.0765             0.0761             0.0749             0              2.0            1          0.0213           0.0210           0.0192      -19005        -3039.0            -2437                  -617.0            -9833.0                       0.0                       0.0           0.00            0.00          0.0000         0.1379          0.1379          0.1379      0.506155      0.650442      0.533482                 1                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                0                 0                 0                1                0   \n",
       "4      4      21865.5    513000.0         513000.0          121500.0                        0.0                         0.0                        0.0                        0.0                         0.0                         0.0          0.0880           0.0874           0.0840            0.0765             0.0761             0.0749             0              1.0            0          0.0213           0.0210           0.0192      -19932        -3038.0            -3458                 -1106.0            -4311.0                       0.0                       0.0           0.00            0.00          0.0000         0.1379          0.1379          0.1379      0.506155      0.322738      0.533482                 1                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                0                 0                 0                0                0   \n",
       "\n",
       "   FLAG_DOCUMENT_5  FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  FLAG_EMAIL  FLAG_EMP_PHONE  FLAG_MOBIL  FLAG_OWN_CAR  FLAG_OWN_REALTY  FLAG_PHONE  FLAG_WORK_PHONE  FLOORSMAX_AVG  FLOORSMAX_MEDI  FLOORSMAX_MODE  FLOORSMIN_AVG  FLOORSMIN_MEDI  FLOORSMIN_MODE  HOUR_APPR_PROCESS_START  LANDAREA_AVG  LANDAREA_MEDI  LANDAREA_MODE  LIVE_CITY_NOT_WORK_CITY  LIVE_REGION_NOT_WORK_REGION  LIVINGAPARTMENTS_AVG  LIVINGAPARTMENTS_MEDI  LIVINGAPARTMENTS_MODE  LIVINGAREA_AVG  LIVINGAREA_MEDI  LIVINGAREA_MODE  NONLIVINGAPARTMENTS_AVG  NONLIVINGAPARTMENTS_MEDI  NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_AVG  NONLIVINGAREA_MEDI  NONLIVINGAREA_MODE  OBS_30_CNT_SOCIAL_CIRCLE  OBS_60_CNT_SOCIAL_CIRCLE  OWN_CAR_AGE  REGION_POPULATION_RELATIVE  REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  REG_CITY_NOT_LIVE_CITY  REG_CITY_NOT_WORK_CITY  REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  SK_ID_CURR  TARGET  TOTALAREA_MODE  YEARS_BEGINEXPLUATATION_AVG  \\\n",
       "0                0                0                0                0                0           0               1           1             0                0           1                0         0.0833          0.0833          0.0833         0.1250          0.1250          0.1250                       10        0.0369         0.0375         0.0377                        0                            0                0.0202                 0.0205                 0.0220          0.0190           0.0193           0.0198                   0.0000                    0.0000                       0.0             0.0000              0.0000              0.0000                       2.0                       2.0          9.0                    0.018801                     2                            2                       0                       0                           0                           0      100002     1.0          0.0149                       0.9722   \n",
       "1                0                0                0                0                0           0               1           1             0                1           1                0         0.2917          0.2917          0.2917         0.3333          0.3333          0.3333                       11        0.0130         0.0132         0.0128                        0                            0                0.0773                 0.0787                 0.0790          0.0549           0.0558           0.0554                   0.0039                    0.0039                       0.0             0.0098              0.0100              0.0000                       1.0                       1.0          9.0                    0.003541                     1                            1                       0                       0                           0                           0      100003     0.0          0.0714                       0.9851   \n",
       "2                0                0                0                0                0           0               1           1             1                0           1                1         0.1667          0.1667          0.1667         0.2083          0.2083          0.2083                        9        0.0482         0.0487         0.0459                        0                            0                0.0756                 0.0770                 0.0771          0.0749           0.0754           0.0733                   0.0000                    0.0000                       0.0             0.0036              0.0031              0.0011                       0.0                       0.0         26.0                    0.010032                     2                            2                       0                       0                           0                           0      100004     0.0          0.0690                       0.9816   \n",
       "3                0                0                0                0                0           0               1           1             0                0           0                0         0.1667          0.1667          0.1667         0.2083          0.2083          0.2083                       17        0.0482         0.0487         0.0459                        0                            0                0.0756                 0.0770                 0.0771          0.0749           0.0754           0.0733                   0.0000                    0.0000                       0.0             0.0036              0.0031              0.0011                       2.0                       2.0          9.0                    0.008019                     2                            2                       0                       0                           0                           0      100006     0.0          0.0690                       0.9816   \n",
       "4                0                0                0                1                0           0               1           1             0                0           0                0         0.1667          0.1667          0.1667         0.2083          0.2083          0.2083                       11        0.0482         0.0487         0.0459                        1                            0                0.0756                 0.0770                 0.0771          0.0749           0.0754           0.0733                   0.0000                    0.0000                       0.0             0.0036              0.0031              0.0011                       0.0                       0.0          9.0                    0.028663                     2                            2                       0                       1                           0                           0      100007     0.0          0.0690                       0.9816   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_MEDI  YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_AVG  YEARS_BUILD_MEDI  YEARS_BUILD_MODE  EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  EMERGENCYSTATE_MODE_nan  FONDKAPREMONT_MODE_not specified  FONDKAPREMONT_MODE_org spec account  FONDKAPREMONT_MODE_reg oper account  FONDKAPREMONT_MODE_reg oper spec account  FONDKAPREMONT_MODE_nan  HOUSETYPE_MODE_block of flats  HOUSETYPE_MODE_specific housing  HOUSETYPE_MODE_terraced house  HOUSETYPE_MODE_nan  NAME_CONTRACT_TYPE_Cash loans  NAME_CONTRACT_TYPE_Revolving loans  NAME_CONTRACT_TYPE_nan  NAME_EDUCATION_TYPE_Academic degree  NAME_EDUCATION_TYPE_Higher education  NAME_EDUCATION_TYPE_Incomplete higher  NAME_EDUCATION_TYPE_Lower secondary  NAME_EDUCATION_TYPE_Secondary / secondary special  NAME_EDUCATION_TYPE_nan  NAME_FAMILY_STATUS_Civil marriage  NAME_FAMILY_STATUS_Married  NAME_FAMILY_STATUS_Separated  NAME_FAMILY_STATUS_Single / not married  NAME_FAMILY_STATUS_Unknown  NAME_FAMILY_STATUS_Widow  \\\n",
       "0                        0.9722                        0.9722           0.6192            0.6243            0.6341                       1                        0                        0                                 0                                    0                                    1                                         0                       0                              1                                0                              0                   0                              1                                   0                       0                                    0                                     0                                      0                                    0                                                  1                        0                                  0                           0                             0                                        1                           0                         0   \n",
       "1                        0.9851                        0.9851           0.7960            0.7987            0.8040                       1                        0                        0                                 0                                    0                                    1                                         0                       0                              1                                0                              0                   0                              1                                   0                       0                                    0                                     1                                      0                                    0                                                  0                        0                                  0                           1                             0                                        0                           0                         0   \n",
       "2                        0.9816                        0.9816           0.7552            0.7585            0.7648                       0                        0                        1                                 0                                    0                                    0                                         0                       1                              0                                0                              0                   1                              0                                   1                       0                                    0                                     0                                      0                                    0                                                  1                        0                                  0                           0                             0                                        1                           0                         0   \n",
       "3                        0.9816                        0.9816           0.7552            0.7585            0.7648                       0                        0                        1                                 0                                    0                                    0                                         0                       1                              0                                0                              0                   1                              1                                   0                       0                                    0                                     0                                      0                                    0                                                  1                        0                                  1                           0                             0                                        0                           0                         0   \n",
       "4                        0.9816                        0.9816           0.7552            0.7585            0.7648                       0                        0                        1                                 0                                    0                                    0                                         0                       1                              0                                0                              0                   1                              1                                   0                       0                                    0                                     0                                      0                                    0                                                  1                        0                                  0                           0                             0                                        1                           0                         0   \n",
       "\n",
       "   NAME_FAMILY_STATUS_nan  NAME_HOUSING_TYPE_Co-op apartment  NAME_HOUSING_TYPE_House / apartment  NAME_HOUSING_TYPE_Municipal apartment  NAME_HOUSING_TYPE_Office apartment  NAME_HOUSING_TYPE_Rented apartment  NAME_HOUSING_TYPE_With parents  NAME_HOUSING_TYPE_nan  NAME_INCOME_TYPE_Businessman  NAME_INCOME_TYPE_Commercial associate  NAME_INCOME_TYPE_Maternity leave  NAME_INCOME_TYPE_Pensioner  NAME_INCOME_TYPE_State servant  NAME_INCOME_TYPE_Student  NAME_INCOME_TYPE_Unemployed  NAME_INCOME_TYPE_Working  NAME_INCOME_TYPE_nan  NAME_TYPE_SUITE_Children  NAME_TYPE_SUITE_Family  NAME_TYPE_SUITE_Group of people  NAME_TYPE_SUITE_Other_A  NAME_TYPE_SUITE_Other_B  NAME_TYPE_SUITE_Spouse, partner  NAME_TYPE_SUITE_Unaccompanied  NAME_TYPE_SUITE_nan  OCCUPATION_TYPE_Accountants  OCCUPATION_TYPE_Cleaning staff  OCCUPATION_TYPE_Cooking staff  OCCUPATION_TYPE_Core staff  OCCUPATION_TYPE_Drivers  OCCUPATION_TYPE_HR staff  OCCUPATION_TYPE_High skill tech staff  OCCUPATION_TYPE_IT staff  \\\n",
       "0                       0                                  0                                    1                                      0                                   0                                   0                               0                      0                             0                                      0                                 0                           0                               0                         0                            0                         1                     0                         0                       0                                0                        0                        0                                0                              1                    0                            0                               0                              0                           0                        0                         0                                      0                         0   \n",
       "1                       0                                  0                                    1                                      0                                   0                                   0                               0                      0                             0                                      0                                 0                           0                               1                         0                            0                         0                     0                         0                       1                                0                        0                        0                                0                              0                    0                            0                               0                              0                           1                        0                         0                                      0                         0   \n",
       "2                       0                                  0                                    1                                      0                                   0                                   0                               0                      0                             0                                      0                                 0                           0                               0                         0                            0                         1                     0                         0                       0                                0                        0                        0                                0                              1                    0                            0                               0                              0                           0                        0                         0                                      0                         0   \n",
       "3                       0                                  0                                    1                                      0                                   0                                   0                               0                      0                             0                                      0                                 0                           0                               0                         0                            0                         1                     0                         0                       0                                0                        0                        0                                0                              1                    0                            0                               0                              0                           0                        0                         0                                      0                         0   \n",
       "4                       0                                  0                                    1                                      0                                   0                                   0                               0                      0                             0                                      0                                 0                           0                               0                         0                            0                         1                     0                         0                       0                                0                        0                        0                                0                              1                    0                            0                               0                              0                           1                        0                         0                                      0                         0   \n",
       "\n",
       "   OCCUPATION_TYPE_Laborers  OCCUPATION_TYPE_Low-skill Laborers  OCCUPATION_TYPE_Managers  OCCUPATION_TYPE_Medicine staff  OCCUPATION_TYPE_Private service staff  OCCUPATION_TYPE_Realty agents  OCCUPATION_TYPE_Sales staff  OCCUPATION_TYPE_Secretaries  OCCUPATION_TYPE_Security staff  OCCUPATION_TYPE_Waiters/barmen staff  OCCUPATION_TYPE_nan  ORGANIZATION_TYPE_Advertising  ORGANIZATION_TYPE_Agriculture  ORGANIZATION_TYPE_Bank  ORGANIZATION_TYPE_Business Entity Type 1  ORGANIZATION_TYPE_Business Entity Type 2  ORGANIZATION_TYPE_Business Entity Type 3  ORGANIZATION_TYPE_Cleaning  ORGANIZATION_TYPE_Construction  ORGANIZATION_TYPE_Culture  ORGANIZATION_TYPE_Electricity  ORGANIZATION_TYPE_Emergency  ORGANIZATION_TYPE_Government  ORGANIZATION_TYPE_Hotel  ORGANIZATION_TYPE_Housing  ORGANIZATION_TYPE_Industry: type 1  ORGANIZATION_TYPE_Industry: type 10  ORGANIZATION_TYPE_Industry: type 11  ORGANIZATION_TYPE_Industry: type 12  ORGANIZATION_TYPE_Industry: type 13  \\\n",
       "0                         1                                   0                         0                               0                                      0                              0                            0                            0                               0                                     0                    0                              0                              0                       0                                         0                                         0                                         1                           0                               0                          0                              0                            0                             0                        0                          0                                   0                                    0                                    0                                    0                                    0   \n",
       "1                         0                                   0                         0                               0                                      0                              0                            0                            0                               0                                     0                    0                              0                              0                       0                                         0                                         0                                         0                           0                               0                          0                              0                            0                             0                        0                          0                                   0                                    0                                    0                                    0                                    0   \n",
       "2                         1                                   0                         0                               0                                      0                              0                            0                            0                               0                                     0                    0                              0                              0                       0                                         0                                         0                                         0                           0                               0                          0                              0                            0                             1                        0                          0                                   0                                    0                                    0                                    0                                    0   \n",
       "3                         1                                   0                         0                               0                                      0                              0                            0                            0                               0                                     0                    0                              0                              0                       0                                         0                                         0                                         1                           0                               0                          0                              0                            0                             0                        0                          0                                   0                                    0                                    0                                    0                                    0   \n",
       "4                         0                                   0                         0                               0                                      0                              0                            0                            0                               0                                     0                    0                              0                              0                       0                                         0                                         0                                         0                           0                               0                          0                              0                            0                             0                        0                          0                                   0                                    0                                    0                                    0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Industry: type 2  ORGANIZATION_TYPE_Industry: type 3  ORGANIZATION_TYPE_Industry: type 4  ORGANIZATION_TYPE_Industry: type 5  ORGANIZATION_TYPE_Industry: type 6  ORGANIZATION_TYPE_Industry: type 7  ORGANIZATION_TYPE_Industry: type 8  ORGANIZATION_TYPE_Industry: type 9  ORGANIZATION_TYPE_Insurance  ORGANIZATION_TYPE_Kindergarten  ORGANIZATION_TYPE_Legal Services  ORGANIZATION_TYPE_Medicine  ORGANIZATION_TYPE_Military  ORGANIZATION_TYPE_Mobile  ORGANIZATION_TYPE_Other  ORGANIZATION_TYPE_Police  ORGANIZATION_TYPE_Postal  ORGANIZATION_TYPE_Realtor  ORGANIZATION_TYPE_Religion  ORGANIZATION_TYPE_Restaurant  ORGANIZATION_TYPE_School  ORGANIZATION_TYPE_Security  ORGANIZATION_TYPE_Security Ministries  ORGANIZATION_TYPE_Self-employed  ORGANIZATION_TYPE_Services  ORGANIZATION_TYPE_Telecom  ORGANIZATION_TYPE_Trade: type 1  ORGANIZATION_TYPE_Trade: type 2  ORGANIZATION_TYPE_Trade: type 3  ORGANIZATION_TYPE_Trade: type 4  ORGANIZATION_TYPE_Trade: type 5  \\\n",
       "0                                   0                                   0                                   0                                   0                                   0                                   0                                   0                                   0                            0                               0                                 0                           0                           0                         0                        0                         0                         0                          0                           0                             0                         0                           0                                      0                                0                           0                          0                                0                                0                                0                                0                                0   \n",
       "1                                   0                                   0                                   0                                   0                                   0                                   0                                   0                                   0                            0                               0                                 0                           0                           0                         0                        0                         0                         0                          0                           0                             0                         1                           0                                      0                                0                           0                          0                                0                                0                                0                                0                                0   \n",
       "2                                   0                                   0                                   0                                   0                                   0                                   0                                   0                                   0                            0                               0                                 0                           0                           0                         0                        0                         0                         0                          0                           0                             0                         0                           0                                      0                                0                           0                          0                                0                                0                                0                                0                                0   \n",
       "3                                   0                                   0                                   0                                   0                                   0                                   0                                   0                                   0                            0                               0                                 0                           0                           0                         0                        0                         0                         0                          0                           0                             0                         0                           0                                      0                                0                           0                          0                                0                                0                                0                                0                                0   \n",
       "4                                   0                                   0                                   0                                   0                                   0                                   0                                   0                                   0                            0                               0                                 0                           0                           0                         0                        0                         0                         0                          0                           1                             0                         0                           0                                      0                                0                           0                          0                                0                                0                                0                                0                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 6  ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  ORGANIZATION_TYPE_XNA  ORGANIZATION_TYPE_nan  WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  WALLSMATERIAL_MODE_nan  WEEKDAY_APPR_PROCESS_START_FRIDAY  WEEKDAY_APPR_PROCESS_START_MONDAY    ...     PREV_PRODUCT_COMBINATION_POS mobile with interest_MEAN  PREV_PRODUCT_COMBINATION_POS mobile without interest_MEAN  PREV_PRODUCT_COMBINATION_POS other with interest_MEAN  PREV_PRODUCT_COMBINATION_POS others without interest_MEAN  PREV_PRODUCT_COMBINATION_nan_MEAN  APR_AMT_ANNUITY_MIN  APR_AMT_ANNUITY_MAX  APR_AMT_ANNUITY_MEAN  APR_AMT_APPLICATION_MIN  APR_AMT_APPLICATION_MAX  APR_AMT_APPLICATION_MEAN  \\\n",
       "0                                0                                0                                    0                                    0                                    0                                    0                             0                      0                      0                         0                         0                              0                          0                         0                                1                          0                       0                                  0                                  0    ...                                              0.000000                                                     0.0                                                        1.0                                                    0.0                                        0.0             9251.775             9251.775              9251.775                179055.00                 179055.0                179055.000   \n",
       "1                                0                                0                                    0                                    0                                    0                                    0                             0                      0                      0                         1                         0                              0                          0                         0                                0                          0                       0                                  0                                  1    ...                                              0.000000                                                     0.0                                                        0.0                                                    0.0                                        0.0             6737.310            98356.995             56553.990                 68809.50                 900000.0                435436.500   \n",
       "2                                0                                0                                    0                                    0                                    0                                    0                             0                      0                      0                         0                         0                              0                          0                         0                                0                          0                       1                                  0                                  1    ...                                              0.000000                                                     1.0                                                        0.0                                                    0.0                                        0.0             5357.250             5357.250              5357.250                 24282.00                  24282.0                 24282.000   \n",
       "3                                0                                0                                    0                                    0                                    0                                    0                             0                      0                      0                         0                         0                              0                          0                         0                                0                          0                       1                                  0                                  0    ...                                              0.000000                                                     0.0                                                        0.0                                                    0.0                                        0.0             2482.920            39954.510             21842.190                 26912.34                 675000.0                352265.868   \n",
       "4                                0                                0                                    0                                    0                                    0                                    0                             0                      0                      0                         0                         0                              0                          0                         0                                0                          0                       1                                  0                                  0    ...                                              0.166667                                                     0.0                                                        0.0                                                    0.0                                        0.0             1834.290            22678.785             12278.805                 17176.50                 247500.0                150530.250   \n",
       "\n",
       "   APR_AMT_CREDIT_MIN  APR_AMT_CREDIT_MAX  APR_AMT_CREDIT_MEAN  APR_APP_CREDIT_PERC_MIN  APR_APP_CREDIT_PERC_MAX  APR_APP_CREDIT_PERC_MEAN  APR_APP_CREDIT_PERC_VAR  APR_AMT_DOWN_PAYMENT_MIN  APR_AMT_DOWN_PAYMENT_MAX  APR_AMT_DOWN_PAYMENT_MEAN  APR_AMT_GOODS_PRICE_MIN  APR_AMT_GOODS_PRICE_MAX  APR_AMT_GOODS_PRICE_MEAN  APR_HOUR_APPR_PROCESS_START_MIN  APR_HOUR_APPR_PROCESS_START_MAX  APR_HOUR_APPR_PROCESS_START_MEAN  APR_RATE_DOWN_PAYMENT_MIN  APR_RATE_DOWN_PAYMENT_MAX  APR_RATE_DOWN_PAYMENT_MEAN  APR_DAYS_DECISION_MIN  APR_DAYS_DECISION_MAX  APR_DAYS_DECISION_MEAN  APR_CNT_PAYMENT_MEAN  APR_CNT_PAYMENT_SUM  REF_AMT_ANNUITY_MIN  REF_AMT_ANNUITY_MAX  REF_AMT_ANNUITY_MEAN  REF_AMT_APPLICATION_MIN  REF_AMT_APPLICATION_MAX  REF_AMT_APPLICATION_MEAN  REF_AMT_CREDIT_MIN  REF_AMT_CREDIT_MAX  REF_AMT_CREDIT_MEAN  REF_APP_CREDIT_PERC_MIN  REF_APP_CREDIT_PERC_MAX  REF_APP_CREDIT_PERC_MEAN  REF_APP_CREDIT_PERC_VAR  REF_AMT_DOWN_PAYMENT_MIN  REF_AMT_DOWN_PAYMENT_MAX  REF_AMT_DOWN_PAYMENT_MEAN  \\\n",
       "0            179055.0            179055.0            179055.00                 1.000000                 1.000000                  1.000000                 0.010021                      0.00                       0.0                       0.00                179055.00                 179055.0                179055.000                              9.0                              9.0                          9.000000                   0.000000                   0.000000                    0.000000                 -606.0                 -606.0             -606.000000             24.000000                 24.0            11240.865           17581.5675           14743.06875                  90000.0                 220500.0                  157500.0            108643.5            225000.0             180000.0                 0.924908                 1.000000                  0.960490                 0.003205                       0.0                       0.0                        0.0   \n",
       "1             68053.5           1035882.0            484191.00                 0.868825                 1.011109                  0.949329                 0.005324                      0.00                    6885.0                    3442.50                 68809.50                 900000.0                435436.500                             12.0                             17.0                         14.666667                   0.000000                   0.100061                    0.050030                -2341.0                 -746.0            -1305.000000             10.000000                 30.0            11240.865           17581.5675           14743.06875                  90000.0                 220500.0                  157500.0            108643.5            225000.0             180000.0                 0.924908                 1.000000                  0.960490                 0.003205                       0.0                       0.0                        0.0   \n",
       "2             20106.0             20106.0             20106.00                 1.207699                 1.207699                  1.207699                 0.010021                   4860.00                    4860.0                    4860.00                 24282.00                  24282.0                 24282.000                              5.0                              5.0                          5.000000                   0.212008                   0.212008                    0.212008                 -815.0                 -815.0             -815.000000              4.000000                  4.0            11240.865           17581.5675           14743.06875                  90000.0                 220500.0                  157500.0            108643.5            225000.0             180000.0                 0.924908                 1.000000                  0.960490                 0.003205                       0.0                       0.0                        0.0   \n",
       "3             24219.0            675000.0            343728.90                 0.943934                 1.250017                  1.061032                 0.014849                   2693.34                   66987.0                   34840.17                 26912.34                 675000.0                352265.868                             12.0                             15.0                         14.400000                   0.108994                   0.217830                    0.163412                 -617.0                 -181.0             -345.600000             18.000000                 90.0            32696.100           32696.1000           32696.10000                 688500.0                 688500.0                  688500.0            906615.0            906615.0             906615.0                 0.759418                 0.759418                  0.759418                 0.003205                       0.0                       0.0                        0.0   \n",
       "4             14616.0            284400.0            166638.75                 0.791139                 1.175185                  0.969650                 0.016456                   3105.00                    3676.5                    3390.75                 17176.50                 247500.0                150530.250                              8.0                             15.0                         12.333333                   0.100143                   0.218890                    0.159516                -2357.0                 -374.0            -1222.833333             20.666667                124.0            11240.865           17581.5675           14743.06875                  90000.0                 220500.0                  157500.0            108643.5            225000.0             180000.0                 0.924908                 1.000000                  0.960490                 0.003205                       0.0                       0.0                        0.0   \n",
       "\n",
       "   REF_AMT_GOODS_PRICE_MIN  REF_AMT_GOODS_PRICE_MAX  REF_AMT_GOODS_PRICE_MEAN  REF_HOUR_APPR_PROCESS_START_MIN  REF_HOUR_APPR_PROCESS_START_MAX  REF_HOUR_APPR_PROCESS_START_MEAN  REF_RATE_DOWN_PAYMENT_MIN  REF_RATE_DOWN_PAYMENT_MAX  REF_RATE_DOWN_PAYMENT_MEAN  REF_DAYS_DECISION_MIN  REF_DAYS_DECISION_MAX  REF_DAYS_DECISION_MEAN  REF_CNT_PAYMENT_MEAN  REF_CNT_PAYMENT_SUM  POS_MONTHS_BALANCE_MAX  POS_MONTHS_BALANCE_MEAN  POS_MONTHS_BALANCE_SIZE  POS_SK_DPD_MAX  POS_SK_DPD_MEAN  POS_SK_DPD_DEF_MAX  POS_SK_DPD_DEF_MEAN  POS_NAME_CONTRACT_STATUS_Active_MEAN  POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN  POS_NAME_CONTRACT_STATUS_Approved_MEAN  POS_NAME_CONTRACT_STATUS_Canceled_MEAN  POS_NAME_CONTRACT_STATUS_Completed_MEAN  POS_NAME_CONTRACT_STATUS_Demand_MEAN  POS_NAME_CONTRACT_STATUS_Returned to the store_MEAN  POS_NAME_CONTRACT_STATUS_Signed_MEAN  POS_NAME_CONTRACT_STATUS_XNA_MEAN  POS_NAME_CONTRACT_STATUS_nan_MEAN  POS_COUNT  INS_NUM_INSTALMENT_VERSION_NUNIQUE  INS_DPD_MAX  \\\n",
       "0              134957.0475                 225000.0                  191250.0                             11.0                             13.0                         12.333333                        0.0                        0.0                         0.0                 -642.0                 -403.0                  -551.0                  14.0                 24.0                    -1.0               -10.000000                     19.0             0.0              0.0                 0.0                  0.0                              1.000000                                           0.0                                     0.0                                     0.0                                 0.000000                                   0.0                                           0.000000                                0.000000                                0.0                                0.0       19.0                                 2.0          0.0   \n",
       "1              134957.0475                 225000.0                  191250.0                             11.0                             13.0                         12.333333                        0.0                        0.0                         0.0                 -642.0                 -403.0                  -551.0                  14.0                 24.0                   -18.0               -43.785714                     28.0             0.0              0.0                 0.0                  0.0                              0.928571                                           0.0                                     0.0                                     0.0                                 0.071429                                   0.0                                           0.000000                                0.000000                                0.0                                0.0       28.0                                 2.0          0.0   \n",
       "2              134957.0475                 225000.0                  191250.0                             11.0                             13.0                         12.333333                        0.0                        0.0                         0.0                 -642.0                 -403.0                  -551.0                  14.0                 24.0                   -24.0               -25.500000                      4.0             0.0              0.0                 0.0                  0.0                              0.750000                                           0.0                                     0.0                                     0.0                                 0.250000                                   0.0                                           0.000000                                0.000000                                0.0                                0.0        4.0                                 2.0          0.0   \n",
       "3              688500.0000                 688500.0                  688500.0                             15.0                             15.0                         15.000000                        0.0                        0.0                         0.0                 -181.0                 -181.0                  -181.0                  48.0                 48.0                    -1.0                -9.619048                     21.0             0.0              0.0                 0.0                  0.0                              0.857143                                           0.0                                     0.0                                     0.0                                 0.095238                                   0.0                                           0.047619                                0.000000                                0.0                                0.0       21.0                                 2.0          0.0   \n",
       "4              134957.0475                 225000.0                  191250.0                             11.0                             13.0                         12.333333                        0.0                        0.0                         0.0                 -642.0                 -403.0                  -551.0                  14.0                 24.0                    -1.0               -33.636364                     66.0             0.0              0.0                 0.0                  0.0                              0.939394                                           0.0                                     0.0                                     0.0                                 0.045455                                   0.0                                           0.000000                                0.015152                                0.0                                0.0       66.0                                 2.0         12.0   \n",
       "\n",
       "   INS_DPD_MEAN  INS_DPD_SUM  INS_DBD_MAX  INS_DBD_MEAN  INS_DBD_SUM  INS_PAYMENT_PERC_MAX  INS_PAYMENT_PERC_MEAN  INS_PAYMENT_PERC_SUM  INS_PAYMENT_PERC_VAR  INS_PAYMENT_DIFF_MAX  INS_PAYMENT_DIFF_MEAN  INS_PAYMENT_DIFF_SUM  INS_PAYMENT_DIFF_VAR  INS_AMT_INSTALMENT_MAX  INS_AMT_INSTALMENT_MEAN  INS_AMT_INSTALMENT_SUM  INS_AMT_PAYMENT_MIN  INS_AMT_PAYMENT_MAX  INS_AMT_PAYMENT_MEAN  INS_AMT_PAYMENT_SUM  INS_DAYS_ENTRY_PAYMENT_MAX  INS_DAYS_ENTRY_PAYMENT_MEAN  INS_DAYS_ENTRY_PAYMENT_SUM  INS_COUNT  CC_MONTHS_BALANCE_MIN  CC_MONTHS_BALANCE_MAX  CC_MONTHS_BALANCE_MEAN  CC_MONTHS_BALANCE_SUM  CC_MONTHS_BALANCE_VAR  CC_AMT_BALANCE_MIN  CC_AMT_BALANCE_MAX  CC_AMT_BALANCE_MEAN  CC_AMT_BALANCE_SUM  CC_AMT_BALANCE_VAR  CC_AMT_CREDIT_LIMIT_ACTUAL_MIN  CC_AMT_CREDIT_LIMIT_ACTUAL_MAX  CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN  CC_AMT_CREDIT_LIMIT_ACTUAL_SUM  CC_AMT_CREDIT_LIMIT_ACTUAL_VAR  CC_AMT_DRAWINGS_ATM_CURRENT_MIN  CC_AMT_DRAWINGS_ATM_CURRENT_MAX  CC_AMT_DRAWINGS_ATM_CURRENT_MEAN  \\\n",
       "0      0.000000          0.0         31.0     20.421053        388.0                   1.0               1.000000                  19.0              0.000000                 0.000               0.000000                 0.000          0.000000e+00               53093.745             11559.247105              219625.695             9251.775            53093.745          11559.247105           219625.695                       -49.0                  -315.421053                     -5993.0       19.0                  -22.0                   -1.0                   -12.0                 -253.0              42.166667                 0.0           96107.175         24997.602995         701364.0825        7.535426e+08                         45000.0                        180000.0                         149000.0                       3825000.0                    4.773968e+08                              0.0                          90000.0                            4500.0   \n",
       "1      0.000000          0.0         14.0      7.160000        179.0                   1.0               1.000000                  25.0              0.000000                 0.000               0.000000                 0.000          0.000000e+00              560835.360             64754.586000             1618864.650             6662.970           560835.360          64754.586000          1618864.650                      -544.0                 -1385.320000                    -34633.0       25.0                  -22.0                   -1.0                   -12.0                 -253.0              42.166667                 0.0           96107.175         24997.602995         701364.0825        7.535426e+08                         45000.0                        180000.0                         149000.0                       3825000.0                    4.773968e+08                              0.0                          90000.0                            4500.0   \n",
       "2      0.000000          0.0         11.0      7.666667         23.0                   1.0               1.000000                   3.0              0.000000                 0.000               0.000000                 0.000          0.000000e+00               10573.965              7096.155000               21288.465             5357.250            10573.965           7096.155000            21288.465                      -727.0                  -761.666667                     -2285.0        3.0                  -22.0                   -1.0                   -12.0                 -253.0              42.166667                 0.0           96107.175         24997.602995         701364.0825        7.535426e+08                         45000.0                        180000.0                         149000.0                       3825000.0                    4.773968e+08                              0.0                          90000.0                            4500.0   \n",
       "3      0.000000          0.0         77.0     19.375000        310.0                   1.0               1.000000                  16.0              0.000000                 0.000               0.000000                 0.000          0.000000e+00              691786.890             62947.088438             1007153.415             2482.920           691786.890          62947.088438          1007153.415                       -12.0                  -271.625000                     -4346.0       16.0                   -6.0                   -1.0                    -3.5                  -21.0               3.500000                 0.0               0.000             0.000000              0.0000        0.000000e+00                        270000.0                        270000.0                         270000.0                       1620000.0                    0.000000e+00                              0.0                          90000.0                            4500.0   \n",
       "4      0.954545         63.0         31.0      4.590909        303.0                   1.0               0.954545                  63.0              0.043995             22655.655             452.384318             29857.365          8.084830e+06               22678.785             12666.444545              835985.340                0.180            22678.785          12214.060227           806127.975                       -14.0                 -1032.242424                    -68128.0       66.0                  -22.0                   -1.0                   -12.0                 -253.0              42.166667                 0.0           96107.175         24997.602995         701364.0825        7.535426e+08                         45000.0                        180000.0                         149000.0                       3825000.0                    4.773968e+08                              0.0                          90000.0                            4500.0   \n",
       "\n",
       "   CC_AMT_DRAWINGS_ATM_CURRENT_SUM  CC_AMT_DRAWINGS_ATM_CURRENT_VAR  CC_AMT_DRAWINGS_CURRENT_MIN  CC_AMT_DRAWINGS_CURRENT_MAX  CC_AMT_DRAWINGS_CURRENT_MEAN  CC_AMT_DRAWINGS_CURRENT_SUM  CC_AMT_DRAWINGS_CURRENT_VAR  CC_AMT_DRAWINGS_OTHER_CURRENT_MIN  CC_AMT_DRAWINGS_OTHER_CURRENT_MAX  CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN  CC_AMT_DRAWINGS_OTHER_CURRENT_SUM  CC_AMT_DRAWINGS_OTHER_CURRENT_VAR  CC_AMT_DRAWINGS_POS_CURRENT_MIN  CC_AMT_DRAWINGS_POS_CURRENT_MAX  CC_AMT_DRAWINGS_POS_CURRENT_MEAN  CC_AMT_DRAWINGS_POS_CURRENT_SUM  CC_AMT_DRAWINGS_POS_CURRENT_VAR  CC_AMT_INST_MIN_REGULARITY_MIN  CC_AMT_INST_MIN_REGULARITY_MAX  CC_AMT_INST_MIN_REGULARITY_MEAN  CC_AMT_INST_MIN_REGULARITY_SUM  CC_AMT_INST_MIN_REGULARITY_VAR  CC_AMT_PAYMENT_CURRENT_MIN  CC_AMT_PAYMENT_CURRENT_MAX  CC_AMT_PAYMENT_CURRENT_MEAN  CC_AMT_PAYMENT_CURRENT_SUM  CC_AMT_PAYMENT_CURRENT_VAR  CC_AMT_PAYMENT_TOTAL_CURRENT_MIN  CC_AMT_PAYMENT_TOTAL_CURRENT_MAX  CC_AMT_PAYMENT_TOTAL_CURRENT_MEAN  CC_AMT_PAYMENT_TOTAL_CURRENT_SUM  \\\n",
       "0                          60750.0                     2.589711e+08                          0.0                      67500.0                   3329.348636                     143100.0                 1.918232e+08                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0                          7408.53                        365.790547                              0.0                     2.649883e+06                             0.0                       4760.2575                      1623.508258                      37493.9325                    2.873010e+06                         0.0                     65250.0                  9856.811065                 140431.2075                1.609631e+08                               0.0                           23436.0                        3986.601378                       118969.8525   \n",
       "1                          60750.0                     2.589711e+08                          0.0                      67500.0                   3329.348636                     143100.0                 1.918232e+08                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0                          7408.53                        365.790547                              0.0                     2.649883e+06                             0.0                       4760.2575                      1623.508258                      37493.9325                    2.873010e+06                         0.0                     65250.0                  9856.811065                 140431.2075                1.609631e+08                               0.0                           23436.0                        3986.601378                       118969.8525   \n",
       "2                          60750.0                     2.589711e+08                          0.0                      67500.0                   3329.348636                     143100.0                 1.918232e+08                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0                          7408.53                        365.790547                              0.0                     2.649883e+06                             0.0                       4760.2575                      1623.508258                      37493.9325                    2.873010e+06                         0.0                     65250.0                  9856.811065                 140431.2075                1.609631e+08                               0.0                           23436.0                        3986.601378                       118969.8525   \n",
       "3                              0.0                     2.589711e+08                          0.0                          0.0                      0.000000                          0.0                 0.000000e+00                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0                          7408.53                        365.790547                              0.0                     2.649883e+06                             0.0                          0.0000                         0.000000                          0.0000                    0.000000e+00                         0.0                     65250.0                  9856.811065                      0.0000                1.609631e+08                               0.0                               0.0                           0.000000                            0.0000   \n",
       "4                          60750.0                     2.589711e+08                          0.0                      67500.0                   3329.348636                     143100.0                 1.918232e+08                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0                          7408.53                        365.790547                              0.0                     2.649883e+06                             0.0                       4760.2575                      1623.508258                      37493.9325                    2.873010e+06                         0.0                     65250.0                  9856.811065                 140431.2075                1.609631e+08                               0.0                           23436.0                        3986.601378                       118969.8525   \n",
       "\n",
       "   CC_AMT_PAYMENT_TOTAL_CURRENT_VAR  CC_AMT_RECEIVABLE_PRINCIPAL_MIN  CC_AMT_RECEIVABLE_PRINCIPAL_MAX  CC_AMT_RECEIVABLE_PRINCIPAL_MEAN  CC_AMT_RECEIVABLE_PRINCIPAL_SUM  CC_AMT_RECEIVABLE_PRINCIPAL_VAR  CC_AMT_RECIVABLE_MIN  CC_AMT_RECIVABLE_MAX  CC_AMT_RECIVABLE_MEAN  CC_AMT_RECIVABLE_SUM  CC_AMT_RECIVABLE_VAR  CC_AMT_TOTAL_RECEIVABLE_MIN  CC_AMT_TOTAL_RECEIVABLE_MAX  CC_AMT_TOTAL_RECEIVABLE_MEAN  CC_AMT_TOTAL_RECEIVABLE_SUM  CC_AMT_TOTAL_RECEIVABLE_VAR  CC_CNT_DRAWINGS_ATM_CURRENT_MIN  CC_CNT_DRAWINGS_ATM_CURRENT_MAX  CC_CNT_DRAWINGS_ATM_CURRENT_MEAN  CC_CNT_DRAWINGS_ATM_CURRENT_SUM  CC_CNT_DRAWINGS_ATM_CURRENT_VAR  CC_CNT_DRAWINGS_CURRENT_MIN  CC_CNT_DRAWINGS_CURRENT_MAX  CC_CNT_DRAWINGS_CURRENT_MEAN  CC_CNT_DRAWINGS_CURRENT_SUM  CC_CNT_DRAWINGS_CURRENT_VAR  CC_CNT_DRAWINGS_OTHER_CURRENT_MIN  CC_CNT_DRAWINGS_OTHER_CURRENT_MAX  CC_CNT_DRAWINGS_OTHER_CURRENT_MEAN  CC_CNT_DRAWINGS_OTHER_CURRENT_SUM  CC_CNT_DRAWINGS_OTHER_CURRENT_VAR  CC_CNT_DRAWINGS_POS_CURRENT_MIN  \\\n",
       "0                      3.508893e+07                              0.0                          90000.0                       23914.47654                      671808.1725                     6.904978e+08                   0.0            95477.3325           24765.001041           691906.0275          7.523544e+08                          0.0                     95513.49                  24770.597235                  692068.7475                 7.525507e+08                              0.0                              3.0                          0.260137                              3.0                         0.529088                          0.0                          3.0                      0.205128                          8.0                       0.4674                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0   \n",
       "1                      3.508893e+07                              0.0                          90000.0                       23914.47654                      671808.1725                     6.904978e+08                   0.0            95477.3325           24765.001041           691906.0275          7.523544e+08                          0.0                     95513.49                  24770.597235                  692068.7475                 7.525507e+08                              0.0                              3.0                          0.260137                              3.0                         0.529088                          0.0                          3.0                      0.205128                          8.0                       0.4674                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0   \n",
       "2                      3.508893e+07                              0.0                          90000.0                       23914.47654                      671808.1725                     6.904978e+08                   0.0            95477.3325           24765.001041           691906.0275          7.523544e+08                          0.0                     95513.49                  24770.597235                  692068.7475                 7.525507e+08                              0.0                              3.0                          0.260137                              3.0                         0.529088                          0.0                          3.0                      0.205128                          8.0                       0.4674                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0   \n",
       "3                      0.000000e+00                              0.0                              0.0                           0.00000                           0.0000                     0.000000e+00                   0.0                0.0000               0.000000                0.0000          0.000000e+00                          0.0                         0.00                      0.000000                       0.0000                 0.000000e+00                              0.0                              3.0                          0.260137                              0.0                         0.529088                          0.0                          0.0                      0.000000                          0.0                       0.0000                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0   \n",
       "4                      3.508893e+07                              0.0                          90000.0                       23914.47654                      671808.1725                     6.904978e+08                   0.0            95477.3325           24765.001041           691906.0275          7.523544e+08                          0.0                     95513.49                  24770.597235                  692068.7475                 7.525507e+08                              0.0                              3.0                          0.260137                              3.0                         0.529088                          0.0                          3.0                      0.205128                          8.0                       0.4674                                0.0                                0.0                                 0.0                                0.0                                0.0                              0.0   \n",
       "\n",
       "   CC_CNT_DRAWINGS_POS_CURRENT_MAX  CC_CNT_DRAWINGS_POS_CURRENT_MEAN  CC_CNT_DRAWINGS_POS_CURRENT_SUM  CC_CNT_DRAWINGS_POS_CURRENT_VAR  CC_CNT_INSTALMENT_MATURE_CUM_MIN  CC_CNT_INSTALMENT_MATURE_CUM_MAX  CC_CNT_INSTALMENT_MATURE_CUM_MEAN  CC_CNT_INSTALMENT_MATURE_CUM_SUM  CC_CNT_INSTALMENT_MATURE_CUM_VAR  CC_SK_DPD_MIN  CC_SK_DPD_MAX  CC_SK_DPD_MEAN  CC_SK_DPD_SUM  CC_SK_DPD_VAR  CC_SK_DPD_DEF_MIN  CC_SK_DPD_DEF_MAX  CC_SK_DPD_DEF_MEAN  CC_SK_DPD_DEF_SUM  CC_SK_DPD_DEF_VAR  CC_NAME_CONTRACT_STATUS_Active_MIN  CC_NAME_CONTRACT_STATUS_Active_MAX  CC_NAME_CONTRACT_STATUS_Active_MEAN  CC_NAME_CONTRACT_STATUS_Active_SUM  CC_NAME_CONTRACT_STATUS_Active_VAR  CC_NAME_CONTRACT_STATUS_Approved_MIN  CC_NAME_CONTRACT_STATUS_Approved_MAX  CC_NAME_CONTRACT_STATUS_Approved_MEAN  CC_NAME_CONTRACT_STATUS_Approved_SUM  CC_NAME_CONTRACT_STATUS_Approved_VAR  CC_NAME_CONTRACT_STATUS_Completed_MIN  CC_NAME_CONTRACT_STATUS_Completed_MAX  CC_NAME_CONTRACT_STATUS_Completed_MEAN  \\\n",
       "0                              1.0                          0.052083                              0.0                           0.0625                               0.0                               7.0                                3.8                              48.0                               6.0            0.0            0.0             0.0            0.0            0.0                0.0                0.0                 0.0                0.0                0.0                                 1.0                                 1.0                                  1.0                                21.0                                 0.0                                   0.0                                   0.0                                    0.0                                   0.0                                   0.0                                    0.0                                    0.0                                     0.0   \n",
       "1                              1.0                          0.052083                              0.0                           0.0625                               0.0                               7.0                                3.8                              48.0                               6.0            0.0            0.0             0.0            0.0            0.0                0.0                0.0                 0.0                0.0                0.0                                 1.0                                 1.0                                  1.0                                21.0                                 0.0                                   0.0                                   0.0                                    0.0                                   0.0                                   0.0                                    0.0                                    0.0                                     0.0   \n",
       "2                              1.0                          0.052083                              0.0                           0.0625                               0.0                               7.0                                3.8                              48.0                               6.0            0.0            0.0             0.0            0.0            0.0                0.0                0.0                 0.0                0.0                0.0                                 1.0                                 1.0                                  1.0                                21.0                                 0.0                                   0.0                                   0.0                                    0.0                                   0.0                                   0.0                                    0.0                                    0.0                                     0.0   \n",
       "3                              1.0                          0.052083                              0.0                           0.0625                               0.0                               0.0                                0.0                               0.0                               0.0            0.0            0.0             0.0            0.0            0.0                0.0                0.0                 0.0                0.0                0.0                                 1.0                                 1.0                                  1.0                                 6.0                                 0.0                                   0.0                                   0.0                                    0.0                                   0.0                                   0.0                                    0.0                                    0.0                                     0.0   \n",
       "4                              1.0                          0.052083                              0.0                           0.0625                               0.0                               7.0                                3.8                              48.0                               6.0            0.0            0.0             0.0            0.0            0.0                0.0                0.0                 0.0                0.0                0.0                                 1.0                                 1.0                                  1.0                                21.0                                 0.0                                   0.0                                   0.0                                    0.0                                   0.0                                   0.0                                    0.0                                    0.0                                     0.0   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_Completed_SUM  CC_NAME_CONTRACT_STATUS_Completed_VAR  CC_NAME_CONTRACT_STATUS_Demand_MIN  CC_NAME_CONTRACT_STATUS_Demand_MAX  CC_NAME_CONTRACT_STATUS_Demand_MEAN  CC_NAME_CONTRACT_STATUS_Demand_SUM  CC_NAME_CONTRACT_STATUS_Demand_VAR  CC_NAME_CONTRACT_STATUS_Refused_MIN  CC_NAME_CONTRACT_STATUS_Refused_MAX  CC_NAME_CONTRACT_STATUS_Refused_MEAN  CC_NAME_CONTRACT_STATUS_Refused_SUM  CC_NAME_CONTRACT_STATUS_Refused_VAR  CC_NAME_CONTRACT_STATUS_Sent proposal_MIN  CC_NAME_CONTRACT_STATUS_Sent proposal_MAX  CC_NAME_CONTRACT_STATUS_Sent proposal_MEAN  CC_NAME_CONTRACT_STATUS_Sent proposal_SUM  CC_NAME_CONTRACT_STATUS_Sent proposal_VAR  CC_NAME_CONTRACT_STATUS_Signed_MIN  CC_NAME_CONTRACT_STATUS_Signed_MAX  CC_NAME_CONTRACT_STATUS_Signed_MEAN  CC_NAME_CONTRACT_STATUS_Signed_SUM  CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n",
       "0                                    0.0                                    0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                                  0.0                                  0.0                                   0.0                                  0.0                                  0.0                                        0.0                                        0.0                                         0.0                                        0.0                                        0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                              0.0                              0.0                               0.0                              0.0   \n",
       "1                                    0.0                                    0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                                  0.0                                  0.0                                   0.0                                  0.0                                  0.0                                        0.0                                        0.0                                         0.0                                        0.0                                        0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                              0.0                              0.0                               0.0                              0.0   \n",
       "2                                    0.0                                    0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                                  0.0                                  0.0                                   0.0                                  0.0                                  0.0                                        0.0                                        0.0                                         0.0                                        0.0                                        0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                              0.0                              0.0                               0.0                              0.0   \n",
       "3                                    0.0                                    0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                                  0.0                                  0.0                                   0.0                                  0.0                                  0.0                                        0.0                                        0.0                                         0.0                                        0.0                                        0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                              0.0                              0.0                               0.0                              0.0   \n",
       "4                                    0.0                                    0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                                  0.0                                  0.0                                   0.0                                  0.0                                  0.0                                        0.0                                        0.0                                         0.0                                        0.0                                        0.0                                 0.0                                 0.0                                  0.0                                 0.0                                 0.0                              0.0                              0.0                               0.0                              0.0   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_nan_VAR  CC_COUNT  \n",
       "0                              0.0      22.0  \n",
       "1                              0.0      22.0  \n",
       "2                              0.0      22.0  \n",
       "3                              0.0       6.0  \n",
       "4                              0.0      22.0  \n",
       "\n",
       "[5 rows x 816 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_imp.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df_imp.isnull().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fit LogisticRegression. fit shape: (215257, 816)\n",
      "Train Accuracy Score: 0.9199422086157477\n",
      "Train AUC Score: 0.7806786098495464\n",
      "Accuracy Score: 0.9190062219524356\n",
      "AUC Score: 0.7713584983739853\n",
      "fit LogisticRegression - done in 21832s\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(penalty='l1', C=1, random_state=1001)\n",
    "\n",
    "with timer(\"fit LogisticRegression\"):\n",
    "    fit_alg(log_clf, X_train_imp, X_val_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fit RandomForestClassifier. fit shape: (215257, 816)\n",
      "Train Accuracy Score: 0.9192732408237595\n",
      "Train AUC Score: 0.7531070345256892\n",
      "Accuracy Score: 0.9192663732737876\n",
      "AUC Score: 0.7417840647256758\n",
      "fit RandomForestClassifier - done in 2589s\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=5000, \n",
    "                        max_leaf_nodes=30, \n",
    "                        max_features=0.1,\n",
    "                        max_depth=5,\n",
    "                        bootstrap=True, n_jobs=-1, random_state=27)\n",
    "with timer(\"fit RandomForestClassifier\"):\n",
    "    fit_alg(rnd_clf, X_train_imp, X_val_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fit LGBMClassifier. fit shape: (215257, 816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.925967564353308\n",
      "Train AUC Score: 0.8816385539163776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9199601101307261\n",
      "AUC Score: 0.7850767103046055\n",
      "fit lgb.LGBMClassifier - done in 775s\n"
     ]
    }
   ],
   "source": [
    " lgb_clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=30, max_depth=8,\n",
    "    learning_rate=0.01, n_estimators=3000,  #10000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=40, \n",
    "    min_child_samples=500, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.5, reg_lambda=0.8, random_state=27, n_jobs=-1, silent=False\n",
    ")\n",
    "\n",
    "with timer(\"fit lgb.LGBMClassifier\"):\n",
    "    fit_alg(lgb_clf, X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lgb_clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=30, max_depth=8,\n",
    "    learning_rate=0.01, n_estimators=3000,  #10000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=40, \n",
    "    min_child_samples=500, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.5, reg_lambda=0.8, random_state=27, n_jobs=-1, silent=False\n",
    ")\n",
    "\n",
    "    \n",
    "Starting fit LGBMClassifier. fit shape: (215257, 816)\n",
    "\n",
    "Train Accuracy Score: 0.925967564353308\n",
    "Train AUC Score: 0.8816385539163776\n",
    "\n",
    "Accuracy Score: 0.9199601101307261\n",
    "AUC Score: 0.7850767103046055\n",
    "fit lgb.LGBMClassifier - done in 775s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#run result\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=30, max_depth=8,\n",
    "    learning_rate=0.01, n_estimators=5000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.1, random_state=27, n_jobs=-1, silent=False\n",
    ")\n",
    "\n",
    "with timer(\"fit lgb.LGBMClassifier\"):\n",
    "    fit_alg(lgb_clf, X_train, X_val)\n",
    "\n",
    "#result output\n",
    "Starting fit LGBMClassifier. fit shape: (215257, 816)\n",
    "\n",
    "\n",
    "Train Accuracy Score: 0.9309197842578871\n",
    "Train AUC Score: 0.9281868536765366\n",
    "\n",
    "Accuracy Score: 0.9196891191709845\n",
    "AUC Score: 0.7841070665789232\n",
    "fit lgb.LGBMClassifier - done in 1342s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "       # clf = LGBMClassifier(\n",
    "       #     nthread=4,\n",
    "       #     n_estimators=10000,\n",
    "       #     learning_rate=0.02,\n",
    "       #     num_leaves=34,\n",
    "       #     colsample_bytree=0.9497036,\n",
    "       #     subsample=0.8715623,\n",
    "       #     max_depth=8,\n",
    "       #     reg_alpha=0.041545473,\n",
    "       #     reg_lambda=0.0735294,\n",
    "       #     min_split_gain=0.0222415,\n",
    "       #     min_child_weight=39.3259775,\n",
    "       #    silent=-1,\n",
    "       #    verbose=-1, )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fit XGBClassifier. fit shape: (215257, 816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9385803945980851\n",
      "Train AUC Score: 0.9531765308983519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9192663732737876\n",
      "AUC Score: 0.7819690354187543\n",
      "fit XGBClassifier - done in 5406s\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "        learning_rate =0.05,\n",
    "        n_estimators=2000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        silent=False,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "\n",
    "with timer(\"fit XGBClassifier\"):\n",
    "    fit_alg(xgb_clf, X_train, X_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#run result\n",
    "xgb_clf = XGBClassifier(\n",
    "        learning_rate =0.05,\n",
    "        n_estimators=2000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        silent=False,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "\n",
    "with timer(\"fit XGBClassifier\"):\n",
    "    fit_alg(xgb_clf, X_train, X_val)\n",
    "    \n",
    "#result output\n",
    "Starting fit XGBClassifier. fit shape: (215257, 816)\n",
    "\n",
    "Train Accuracy Score: 0.9385803945980851\n",
    "Train AUC Score: 0.9531765308983519\n",
    "\n",
    "Accuracy Score: 0.9192663732737876\n",
    "AUC Score: 0.7819690354187543\n",
    "fit XGBClassifier - done in 5406s\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_val['TARGET'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "X_val_imp_feats = X_val_imp[feats]\n",
    "X_val_feats = X_val[feats]\n",
    "\n",
    "\n",
    "seclvl_train_all = np.concatenate(( np.array([log_clf.predict_proba(X_val_imp_feats)[:,1]]).T,\n",
    "                                np.array([rnd_clf.predict_proba(X_val_imp_feats)[:,1]]).T,\n",
    "                                np.array([xgb_clf.predict_proba(X_val_feats)[:,1]]).T,\n",
    "                                np.array([lgb_clf.predict_proba(X_val_feats)[:,1]]).T\n",
    "                            ), axis=1)\n",
    "\n",
    "level2_df = pd.concat([X_val['TARGET'].reset_index(),pd.DataFrame(seclvl_train_all)], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_val_imp_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CV XGBClassifier. CV shape: (92254, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9200157177312268\n",
      "Train AUC Score: 0.792282311251377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9201170604812486\n",
      "AUC Score: 0.7812430707724887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9201387477473816\n",
      "Train AUC Score: 0.787785941391247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9192455693458349\n",
      "AUC Score: 0.7987751015060607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9200032519003293\n",
      "Train AUC Score: 0.7891696923048264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9201127310172891\n",
      "AUC Score: 0.7938567119435864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9202753238306867\n",
      "Train AUC Score: 0.7919839615464561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9191327913279133\n",
      "AUC Score: 0.7820151068332047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9199907864072407\n",
      "Train AUC Score: 0.7929110869394198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9201084010840108\n",
      "AUC Score: 0.7774934944382541\n",
      "Starting fit XGBClassifier. fit shape: (92254, 6)\n"
     ]
    }
   ],
   "source": [
    "gbm_level2 = xgb.XGBClassifier(\n",
    " learning_rate = 0.01,\n",
    " n_estimators= 1000,\n",
    " max_depth=2,\n",
    " min_child_weight=80,\n",
    " num_leaves=2,   \n",
    " gamma=0.1,  \n",
    " subsample=0.6, \n",
    " colsample_bytree=1,\n",
    " reg_alpha = 0.2,\n",
    " objective= 'binary:logistic',\n",
    " random_state=1001\n",
    " nthread= -1,\n",
    " silent=False,\n",
    " scale_pos_weight=1)\n",
    "\n",
    "cv_alg(gbm_level2, level2_df)\n",
    "fit_alg(gbm_level2, level2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CV LogisticRegression. CV shape: (92254, 6)\n",
      "Train Accuracy Score: 0.9192704804747839\n",
      "Train AUC Score: 0.7889077753934994\n",
      "Accuracy Score: 0.9192499458053327\n",
      "AUC Score: 0.7823180753820819\n",
      "Train Accuracy Score: 0.919271574326247\n",
      "Train AUC Score: 0.7845096232252045\n",
      "Accuracy Score: 0.9192455693458349\n",
      "AUC Score: 0.7999025795063212\n",
      "Train Accuracy Score: 0.919271574326247\n",
      "Train AUC Score: 0.7860802733636647\n",
      "Accuracy Score: 0.9192455693458349\n",
      "AUC Score: 0.793542390379192\n",
      "Train Accuracy Score: 0.9192591187469514\n",
      "Train AUC Score: 0.7886365388881904\n",
      "Accuracy Score: 0.9192953929539296\n",
      "AUC Score: 0.7833467280783091\n",
      "Train Accuracy Score: 0.9192591187469514\n",
      "Train AUC Score: 0.7897940122465313\n",
      "Accuracy Score: 0.9192953929539296\n",
      "AUC Score: 0.7788169984560241\n",
      "Starting fit LogisticRegression. fit shape: (92254, 6)\n"
     ]
    }
   ],
   "source": [
    "log_level2 = LogisticRegression(penalty='l2', C=0.001, random_state=1001)\n",
    "\n",
    "cv_alg(log_level2, level2_df)\n",
    "fit_alg(log_level2, level2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbm_level2  Submission 7: Kaggle - Your submission scored 0.785,\n",
    "gbm_level2 - \n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0.1, learning_rate=0.01, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=1000,\n",
    "       n_jobs=1, nthread=-1, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0.2, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=False, subsample=0.6)\n",
    "\n",
    "gbm_level2 = xgb.XGBClassifier(\n",
    " learning_rate = 0.01,\n",
    " n_estimators= 1000,\n",
    " max_depth=2,\n",
    " min_child_weight=1,\n",
    " gamma=0.1,  \n",
    " subsample=0.6, \n",
    " colsample_bytree=1,\n",
    " reg_alpha = 0.2,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " silent=False,\n",
    " scale_pos_weight=1)\n",
    " \n",
    "#output result\n",
    "Starting CV XGBClassifier. CV shape: (92254, 6)\n",
    "\n",
    "Train Accuracy Score: 0.9204086610118967\n",
    "Train AUC Score: 0.7935299766248891\n",
    "\n",
    "\n",
    "Accuracy Score: 0.9204422284847171\n",
    "AUC Score: 0.7813680639471254\n",
    "\n",
    "Train Accuracy Score: 0.9205587848732436\n",
    "Train AUC Score: 0.7890711977974596\n",
    "\n",
    "Accuracy Score: 0.9198959405994255\n",
    "AUC Score: 0.7989607227635132\n",
    "\n",
    "Train Accuracy Score: 0.920463937780307\n",
    "Train AUC Score: 0.7903746991957435\n",
    "\n",
    "Accuracy Score: 0.9201669286217549\n",
    "AUC Score: 0.7938135810182776\n",
    "\n",
    "\n",
    "Train Accuracy Score: 0.920600509457482\n",
    "Train AUC Score: 0.7930456208663245\n",
    "\n",
    "Accuracy Score: 0.919620596205962\n",
    "AUC Score: 0.7825277196384118\n",
    "\n",
    "Train Accuracy Score: 0.9203159720340361\n",
    "Train AUC Score: 0.7939689853297902\n",
    "\n",
    "Accuracy Score: 0.9202168021680217\n",
    "AUC Score: 0.7783441600647542\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pd.concat([X_val['TARGET'].reset_index(),pd.DataFrame(seclvl_train_all)], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "xgb_clf.predict_proba(X_val_feats)[:,1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pd.DataFrame(seclvl_train_all).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in [lgb_clf, xgb_clf, log_clf, rnd_clf]: \n",
    "    joblib.dump(clf, '{}_finalmodel_lvl1.pkl'.format(clf.__class__.__name__))\n",
    "    \n",
    "for clf in [gbm_level2, log_level2]: \n",
    "    joblib.dump(clf, '{}_finalmodel_lvl2.pkl'.format(clf.__class__.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path= \"D:/wangh/Kaggle/HomeCredit/result_submission8_{}{}.csv\"\n",
    "\n",
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "\n",
    "for clf, test_data_df in [\n",
    "        (lgb_clf, test_df), \n",
    "        (xgb_clf, test_df),\n",
    "        (log_clf, test_df_imp), \n",
    "        (rnd_clf, test_df_imp),\n",
    "    ]: \n",
    "    result_df=pd.DataFrame()\n",
    "    result_df['SK_ID_CURR'] = test_df['SK_ID_CURR']\n",
    "    result_df['TARGET'] = clf.predict_proba(test_data_df[feats])[:, 1]\n",
    "\n",
    "    submission_filepath = submission_path.format(clf.__class__.__name__,'_1stlvl')\n",
    "    result_df.to_csv(submission_filepath, index=False, float_format='%.6f')\n",
    "    \n",
    "    del result_df\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seclvl_test=test_df[feats]\n",
    "\n",
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "test_df_imp_feats = test_df_imp[feats]\n",
    "test_df_feats = test_df[feats]\n",
    "\n",
    "\n",
    "seclvl_train_all = np.concatenate(( np.array([log_clf.predict_proba(test_df_imp_feats)[:,1]]).T,\n",
    "                                np.array([rnd_clf.predict_proba(test_df_imp_feats)[:,1]]).T,\n",
    "                                np.array([xgb_clf.predict_proba(test_df_feats)[:,1]]).T,\n",
    "                                np.array([lgb_clf.predict_proba(test_df_feats)[:,1]]).T\n",
    "                            ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame()\n",
    "result_df['SK_ID_CURR'] = test_df['SK_ID_CURR']\n",
    "\n",
    "for clf_level2 in [gbm_level2, log_level2]: \n",
    "    result_df['TARGET'] = clf_level2.predict_proba(pd.DataFrame(seclvl_train_all))[:, 1]\n",
    "    submission_filePath = submission_path.format(clf_level2.__class__.__name__, '_2ndlvl')\n",
    "    result_df.to_csv(submission_filePath, index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_df_imp_feats\n",
    "del test_df_feats\n",
    "del result_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(alg, grid_params, grid_train_df, grid_target_df):\n",
    "    grid_search_result = GridSearchCV(estimator = alg, param_grid = grid_params, cv=5,\n",
    "                           scoring='roc_auc', return_train_score=True, verbose=10,n_jobs=8,iid=False)\n",
    "\n",
    "    grid_search_result.fit(grid_train_df, grid_target_df)\n",
    "\n",
    "    return grid_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in train_df.columns if f not in g_ignore_features]\n",
    "\n",
    "df_feats_imp = train_df_imp[feats]\n",
    "df_TARGET_imp = train_df_imp['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(random_state=27)\n",
    "\n",
    "rnd_param_grid = {\n",
    "     'n_estimators': [1000,10000, 3000], 'max_features': [0.1, 0.3, 0.5], \n",
    "     'min_samples_leaf':range(40, 300, 100), \n",
    "    #'max_depth': range(2, 12, 2),\n",
    "    #'oob_score':[True, False]\n",
    "}\n",
    "\n",
    "rnd_grid_search = grid_search(RandomForestClassifier(n_estimators=5000, \n",
    "                        max_leaf_nodes=30, \n",
    "                        max_features=0.1,\n",
    "                        max_depth=8,\n",
    "                        oob_score=True,\n",
    "                        bootstrap=True, n_jobs=-1, random_state=27), rnd_param_grid, \n",
    "                              df_feats_imp, df_TARGET_imp)\n",
    "rnd_grid_search.grid_scores_, rnd_grid_search.best_params_, rnd_grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in train_df.columns if f not in g_ignore_features]\n",
    "\n",
    "df_feats = train_df[feats]\n",
    "df_TARGET = train_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:390: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's auc: 0.738788 + 0.0032822\n",
      "[40]\tcv_agg's auc: 0.739973 + 0.00340554\n",
      "[60]\tcv_agg's auc: 0.738983 + 0.00344697\n",
      "[80]\tcv_agg's auc: 0.741239 + 0.00333113\n",
      "[100]\tcv_agg's auc: 0.742206 + 0.00319856\n",
      "[120]\tcv_agg's auc: 0.744196 + 0.00326907\n",
      "[140]\tcv_agg's auc: 0.745702 + 0.00348815\n",
      "[160]\tcv_agg's auc: 0.747244 + 0.00351115\n",
      "[180]\tcv_agg's auc: 0.748612 + 0.00343666\n",
      "[200]\tcv_agg's auc: 0.74952 + 0.00351955\n",
      "[220]\tcv_agg's auc: 0.750603 + 0.00346048\n",
      "[240]\tcv_agg's auc: 0.751364 + 0.00342972\n",
      "[260]\tcv_agg's auc: 0.753008 + 0.00346648\n",
      "[280]\tcv_agg's auc: 0.754261 + 0.00346019\n",
      "[300]\tcv_agg's auc: 0.755862 + 0.00339991\n",
      "[320]\tcv_agg's auc: 0.757563 + 0.00336221\n",
      "[340]\tcv_agg's auc: 0.759196 + 0.00324852\n",
      "[360]\tcv_agg's auc: 0.760702 + 0.00314682\n",
      "[380]\tcv_agg's auc: 0.762442 + 0.00311959\n",
      "[400]\tcv_agg's auc: 0.764085 + 0.00314281\n",
      "[420]\tcv_agg's auc: 0.765534 + 0.00310879\n",
      "[440]\tcv_agg's auc: 0.766975 + 0.00309674\n",
      "[460]\tcv_agg's auc: 0.768285 + 0.00304864\n",
      "[480]\tcv_agg's auc: 0.769466 + 0.00302535\n",
      "[500]\tcv_agg's auc: 0.770481 + 0.00300628\n",
      "[520]\tcv_agg's auc: 0.771495 + 0.00303225\n",
      "[540]\tcv_agg's auc: 0.772448 + 0.00301803\n",
      "[560]\tcv_agg's auc: 0.773353 + 0.00302518\n",
      "[580]\tcv_agg's auc: 0.774185 + 0.00298945\n",
      "[600]\tcv_agg's auc: 0.774931 + 0.00296529\n",
      "[620]\tcv_agg's auc: 0.775639 + 0.00291628\n",
      "[640]\tcv_agg's auc: 0.776305 + 0.00288653\n",
      "[660]\tcv_agg's auc: 0.776887 + 0.00286095\n",
      "[680]\tcv_agg's auc: 0.777444 + 0.00285606\n",
      "[700]\tcv_agg's auc: 0.777964 + 0.00284101\n",
      "[720]\tcv_agg's auc: 0.778461 + 0.00280938\n",
      "[740]\tcv_agg's auc: 0.778917 + 0.00279281\n",
      "[760]\tcv_agg's auc: 0.77936 + 0.00276404\n",
      "[780]\tcv_agg's auc: 0.77975 + 0.0027316\n",
      "[800]\tcv_agg's auc: 0.780109 + 0.00272355\n",
      "[820]\tcv_agg's auc: 0.780464 + 0.00272711\n",
      "[840]\tcv_agg's auc: 0.780803 + 0.00273769\n",
      "[860]\tcv_agg's auc: 0.78108 + 0.00270584\n",
      "[880]\tcv_agg's auc: 0.781379 + 0.00270376\n",
      "[900]\tcv_agg's auc: 0.781666 + 0.00268328\n",
      "[920]\tcv_agg's auc: 0.781938 + 0.00268294\n",
      "[940]\tcv_agg's auc: 0.782218 + 0.00266733\n",
      "[960]\tcv_agg's auc: 0.782458 + 0.00268164\n",
      "[980]\tcv_agg's auc: 0.782646 + 0.00264473\n",
      "[1000]\tcv_agg's auc: 0.782889 + 0.00264556\n",
      "[1020]\tcv_agg's auc: 0.783094 + 0.00265068\n",
      "[1040]\tcv_agg's auc: 0.783301 + 0.00266469\n",
      "[1060]\tcv_agg's auc: 0.783493 + 0.002663\n",
      "[1080]\tcv_agg's auc: 0.783677 + 0.00266043\n",
      "[1100]\tcv_agg's auc: 0.783849 + 0.00264256\n",
      "[1120]\tcv_agg's auc: 0.784034 + 0.0026129\n",
      "[1140]\tcv_agg's auc: 0.784177 + 0.00259581\n",
      "[1160]\tcv_agg's auc: 0.784325 + 0.00258837\n",
      "[1180]\tcv_agg's auc: 0.784452 + 0.00257277\n",
      "[1200]\tcv_agg's auc: 0.784578 + 0.00255848\n",
      "[1220]\tcv_agg's auc: 0.784686 + 0.00256008\n",
      "[1240]\tcv_agg's auc: 0.784809 + 0.00257092\n",
      "[1260]\tcv_agg's auc: 0.784897 + 0.00257598\n",
      "[1280]\tcv_agg's auc: 0.784997 + 0.00256515\n",
      "[1300]\tcv_agg's auc: 0.785095 + 0.00255975\n",
      "[1320]\tcv_agg's auc: 0.785228 + 0.00255021\n",
      "[1340]\tcv_agg's auc: 0.785309 + 0.0025528\n",
      "[1360]\tcv_agg's auc: 0.785381 + 0.00253633\n",
      "[1380]\tcv_agg's auc: 0.785461 + 0.0025213\n",
      "[1400]\tcv_agg's auc: 0.785528 + 0.00252292\n",
      "[1420]\tcv_agg's auc: 0.785616 + 0.00251242\n",
      "[1440]\tcv_agg's auc: 0.785694 + 0.00250107\n",
      "[1460]\tcv_agg's auc: 0.785757 + 0.00249743\n",
      "[1480]\tcv_agg's auc: 0.785821 + 0.00249318\n",
      "[1500]\tcv_agg's auc: 0.78591 + 0.00248436\n",
      "[1520]\tcv_agg's auc: 0.785969 + 0.00249782\n",
      "[1540]\tcv_agg's auc: 0.786015 + 0.00249315\n",
      "[1560]\tcv_agg's auc: 0.786047 + 0.00247781\n",
      "[1580]\tcv_agg's auc: 0.786103 + 0.0024795\n",
      "[1600]\tcv_agg's auc: 0.786163 + 0.0024782\n",
      "[1620]\tcv_agg's auc: 0.786212 + 0.00248362\n",
      "[1640]\tcv_agg's auc: 0.786288 + 0.00249114\n",
      "[1660]\tcv_agg's auc: 0.786317 + 0.00248416\n",
      "[1680]\tcv_agg's auc: 0.786361 + 0.0024687\n",
      "[1700]\tcv_agg's auc: 0.786398 + 0.00245745\n",
      "[1720]\tcv_agg's auc: 0.786435 + 0.00244995\n",
      "[1740]\tcv_agg's auc: 0.786459 + 0.00244923\n",
      "[1760]\tcv_agg's auc: 0.78649 + 0.00245089\n",
      "[1780]\tcv_agg's auc: 0.786545 + 0.00247641\n",
      "[1800]\tcv_agg's auc: 0.786576 + 0.00247636\n",
      "[1820]\tcv_agg's auc: 0.7866 + 0.0024948\n",
      "[1840]\tcv_agg's auc: 0.786627 + 0.00248042\n",
      "[1860]\tcv_agg's auc: 0.786657 + 0.0024863\n",
      "[1880]\tcv_agg's auc: 0.786676 + 0.00249806\n",
      "[1900]\tcv_agg's auc: 0.786695 + 0.00247252\n",
      "[1920]\tcv_agg's auc: 0.786709 + 0.00247467\n",
      "[1940]\tcv_agg's auc: 0.786724 + 0.00247091\n",
      "[1960]\tcv_agg's auc: 0.786744 + 0.00248044\n",
      "[1980]\tcv_agg's auc: 0.78676 + 0.00246942\n",
      "[2000]\tcv_agg's auc: 0.786767 + 0.00245537\n",
      "[2020]\tcv_agg's auc: 0.78678 + 0.00247752\n",
      "[2040]\tcv_agg's auc: 0.78681 + 0.00247531\n",
      "[2060]\tcv_agg's auc: 0.786831 + 0.0024796\n",
      "[2080]\tcv_agg's auc: 0.786852 + 0.00247597\n",
      "[2100]\tcv_agg's auc: 0.78686 + 0.00248262\n",
      "[2120]\tcv_agg's auc: 0.78687 + 0.00249995\n",
      "[2140]\tcv_agg's auc: 0.786856 + 0.00248413\n",
      "[2160]\tcv_agg's auc: 0.786872 + 0.00248949\n",
      "[2180]\tcv_agg's auc: 0.786864 + 0.00247811\n",
      "[2200]\tcv_agg's auc: 0.786877 + 0.00248253\n",
      "[2220]\tcv_agg's auc: 0.786885 + 0.00246948\n",
      "[2240]\tcv_agg's auc: 0.786914 + 0.00245557\n",
      "[2260]\tcv_agg's auc: 0.786934 + 0.002454\n",
      "[2280]\tcv_agg's auc: 0.786952 + 0.00245014\n",
      "[2300]\tcv_agg's auc: 0.786953 + 0.00244668\n",
      "[2320]\tcv_agg's auc: 0.786959 + 0.00243771\n",
      "[2340]\tcv_agg's auc: 0.786983 + 0.00243043\n",
      "[2360]\tcv_agg's auc: 0.786979 + 0.00241871\n",
      "[2380]\tcv_agg's auc: 0.78699 + 0.00241667\n",
      "[2400]\tcv_agg's auc: 0.787006 + 0.00243178\n",
      "[2420]\tcv_agg's auc: 0.787017 + 0.00243465\n",
      "[2440]\tcv_agg's auc: 0.787043 + 0.00243746\n",
      "[2460]\tcv_agg's auc: 0.787057 + 0.00242742\n",
      "[2480]\tcv_agg's auc: 0.787074 + 0.00241836\n",
      "[2500]\tcv_agg's auc: 0.78709 + 0.0023996\n",
      "[2520]\tcv_agg's auc: 0.787095 + 0.00239034\n",
      "[2540]\tcv_agg's auc: 0.78711 + 0.00239697\n",
      "[2560]\tcv_agg's auc: 0.787128 + 0.00241266\n",
      "[2580]\tcv_agg's auc: 0.787138 + 0.00242053\n",
      "[2600]\tcv_agg's auc: 0.787145 + 0.00239647\n",
      "[2620]\tcv_agg's auc: 0.787156 + 0.00240397\n",
      "[2640]\tcv_agg's auc: 0.787159 + 0.00238607\n",
      "[2660]\tcv_agg's auc: 0.787182 + 0.0023786\n",
      "[2680]\tcv_agg's auc: 0.787184 + 0.00236937\n",
      "[2700]\tcv_agg's auc: 0.787189 + 0.00236698\n",
      "[2720]\tcv_agg's auc: 0.787195 + 0.00235929\n",
      "[2740]\tcv_agg's auc: 0.787207 + 0.00233888\n",
      "[2760]\tcv_agg's auc: 0.787201 + 0.00235142\n",
      "[2780]\tcv_agg's auc: 0.787207 + 0.00234396\n",
      "[2800]\tcv_agg's auc: 0.787222 + 0.00235152\n",
      "[2820]\tcv_agg's auc: 0.787242 + 0.00236501\n",
      "[2840]\tcv_agg's auc: 0.787266 + 0.00237039\n",
      "[2860]\tcv_agg's auc: 0.787264 + 0.00236708\n",
      "[2880]\tcv_agg's auc: 0.787259 + 0.00235413\n",
      "[2900]\tcv_agg's auc: 0.787251 + 0.00233522\n",
      "[2920]\tcv_agg's auc: 0.787257 + 0.00232159\n",
      "[2940]\tcv_agg's auc: 0.787248 + 0.00231881\n",
      "[2960]\tcv_agg's auc: 0.787262 + 0.00232029\n",
      "[2980]\tcv_agg's auc: 0.787246 + 0.00232965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc-mean': [0.7098111705909742,\n",
       "  0.7157302683080881,\n",
       "  0.7170503297075597,\n",
       "  0.7246847297570228,\n",
       "  0.7262433121331824,\n",
       "  0.726747290818077,\n",
       "  0.7326943372085626,\n",
       "  0.7322340334081654,\n",
       "  0.7328961480092154,\n",
       "  0.7326242919376217,\n",
       "  0.7351581047600073,\n",
       "  0.7372818092061357,\n",
       "  0.7375229462292385,\n",
       "  0.739094462061417,\n",
       "  0.738927433454214,\n",
       "  0.739648604178577,\n",
       "  0.7393220475369393,\n",
       "  0.7393918591306334,\n",
       "  0.7391273715632914,\n",
       "  0.7387877031887892,\n",
       "  0.7385077401543307,\n",
       "  0.7382617872000904,\n",
       "  0.7379318503844499,\n",
       "  0.7383259331546659,\n",
       "  0.7381204838321392,\n",
       "  0.7388020826220811,\n",
       "  0.7384739098381267,\n",
       "  0.7381965659460974,\n",
       "  0.738011384570836,\n",
       "  0.7382617508855476,\n",
       "  0.7385780212007548,\n",
       "  0.7394006846309263,\n",
       "  0.7399008548743767,\n",
       "  0.739699977876266,\n",
       "  0.7395265378213799,\n",
       "  0.7393058793372187,\n",
       "  0.7395473807655911,\n",
       "  0.7397265665705879,\n",
       "  0.7401500689118371,\n",
       "  0.7399725764694212,\n",
       "  0.7398086883620619,\n",
       "  0.7396657630344213,\n",
       "  0.7398136923824858,\n",
       "  0.7396666315524925,\n",
       "  0.7395593718274093,\n",
       "  0.7394551657323143,\n",
       "  0.7397487743705178,\n",
       "  0.7397070937956671,\n",
       "  0.7395927052262511,\n",
       "  0.7394625040057566,\n",
       "  0.7396382451540653,\n",
       "  0.7395259493492758,\n",
       "  0.7394756359629392,\n",
       "  0.739435729908927,\n",
       "  0.7393666583419749,\n",
       "  0.7393031227531188,\n",
       "  0.7392133374966032,\n",
       "  0.7391474634740149,\n",
       "  0.7390725177175117,\n",
       "  0.7389827324298125,\n",
       "  0.7389454344891593,\n",
       "  0.7388728278019674,\n",
       "  0.7391810166927792,\n",
       "  0.7394329582139496,\n",
       "  0.7393630625349129,\n",
       "  0.7393172384432134,\n",
       "  0.7395736905134972,\n",
       "  0.7394999985237167,\n",
       "  0.7394650713949638,\n",
       "  0.7397738868575823,\n",
       "  0.7396971079362946,\n",
       "  0.7399774505063135,\n",
       "  0.7402132779262385,\n",
       "  0.7403975906638365,\n",
       "  0.7403525634348368,\n",
       "  0.7409819777283098,\n",
       "  0.7411411997255893,\n",
       "  0.7413291502170167,\n",
       "  0.7412977568968369,\n",
       "  0.7412385178870258,\n",
       "  0.7412101720950296,\n",
       "  0.7411656338440792,\n",
       "  0.7413935387375193,\n",
       "  0.7413410198256221,\n",
       "  0.7412952152503012,\n",
       "  0.7415632329450117,\n",
       "  0.741515926630498,\n",
       "  0.7416913281941996,\n",
       "  0.7416334168971378,\n",
       "  0.7417993311798348,\n",
       "  0.7417656322653471,\n",
       "  0.7417445241081672,\n",
       "  0.7418867013959434,\n",
       "  0.7418523387038778,\n",
       "  0.7420260901944717,\n",
       "  0.7419717606986023,\n",
       "  0.7419408040282732,\n",
       "  0.741944271720672,\n",
       "  0.7421783583654582,\n",
       "  0.7422060846048423,\n",
       "  0.742636505836652,\n",
       "  0.7426219299264086,\n",
       "  0.7426183648400062,\n",
       "  0.7428000163410218,\n",
       "  0.74296375302905,\n",
       "  0.7429697139940369,\n",
       "  0.7429772228705916,\n",
       "  0.7431670404421252,\n",
       "  0.7433521097600513,\n",
       "  0.7433285223139798,\n",
       "  0.743325929435829,\n",
       "  0.7433181972245058,\n",
       "  0.7433232050558835,\n",
       "  0.7434917080576803,\n",
       "  0.743676988241375,\n",
       "  0.7436863627080135,\n",
       "  0.7440530633025615,\n",
       "  0.7440500730562617,\n",
       "  0.7441959969905712,\n",
       "  0.7441964725043635,\n",
       "  0.7441959278888325,\n",
       "  0.744180357632213,\n",
       "  0.744190951924967,\n",
       "  0.7441922099528228,\n",
       "  0.7441880384760661,\n",
       "  0.7444055658930079,\n",
       "  0.7447234680597437,\n",
       "  0.7448484160290402,\n",
       "  0.7449918782342148,\n",
       "  0.7451262318496277,\n",
       "  0.745145870886707,\n",
       "  0.7451398749376971,\n",
       "  0.7451427259984,\n",
       "  0.7451398598121823,\n",
       "  0.7452596766314229,\n",
       "  0.7452781426253646,\n",
       "  0.7454633996731947,\n",
       "  0.7457322316045019,\n",
       "  0.7457185799474824,\n",
       "  0.7457021355197739,\n",
       "  0.7456783876780765,\n",
       "  0.7459490364606556,\n",
       "  0.7461031095187798,\n",
       "  0.7462276727530798,\n",
       "  0.7462274953471166,\n",
       "  0.7463380942804083,\n",
       "  0.7463097316793283,\n",
       "  0.7463063830743668,\n",
       "  0.7463109953719785,\n",
       "  0.7464156667570914,\n",
       "  0.7464192541438432,\n",
       "  0.7465787755310485,\n",
       "  0.7465747892137774,\n",
       "  0.7467341245413401,\n",
       "  0.7467134810422726,\n",
       "  0.7468540550525647,\n",
       "  0.7469776169057938,\n",
       "  0.7469609116354897,\n",
       "  0.747099135771816,\n",
       "  0.7472440453322171,\n",
       "  0.7472297293959362,\n",
       "  0.7473351343831375,\n",
       "  0.7473311558959962,\n",
       "  0.7472982454604311,\n",
       "  0.7474352111740007,\n",
       "  0.7475547228918875,\n",
       "  0.7475338667113505,\n",
       "  0.7476392291597324,\n",
       "  0.74788822630324,\n",
       "  0.7478621237700992,\n",
       "  0.7479962133264403,\n",
       "  0.7479965085276689,\n",
       "  0.7479874995244472,\n",
       "  0.7480808673163066,\n",
       "  0.7481913012277797,\n",
       "  0.7481789089967891,\n",
       "  0.7482986837233819,\n",
       "  0.7483971375650135,\n",
       "  0.7485052094909499,\n",
       "  0.7486115967214942,\n",
       "  0.7486976869187372,\n",
       "  0.7488039077790613,\n",
       "  0.7488898410307879,\n",
       "  0.7488723733283866,\n",
       "  0.7488727153750355,\n",
       "  0.7489732455430849,\n",
       "  0.7489659072760193,\n",
       "  0.748951156601262,\n",
       "  0.7490543875506048,\n",
       "  0.7491499844673004,\n",
       "  0.7491495595333066,\n",
       "  0.749146069048906,\n",
       "  0.7491436465409524,\n",
       "  0.7492420420756074,\n",
       "  0.7492549041669,\n",
       "  0.7493975474030952,\n",
       "  0.7494068423114001,\n",
       "  0.749410458236823,\n",
       "  0.7494178616761269,\n",
       "  0.7495197571940172,\n",
       "  0.7496142788382951,\n",
       "  0.7496152435105085,\n",
       "  0.7496226661481051,\n",
       "  0.7497288569270913,\n",
       "  0.7497439979412508,\n",
       "  0.74973729784271,\n",
       "  0.7497556368461452,\n",
       "  0.7498553404058224,\n",
       "  0.7498723200279428,\n",
       "  0.7498828618219184,\n",
       "  0.7499095582132341,\n",
       "  0.7499128384103704,\n",
       "  0.7500268577018934,\n",
       "  0.7500579733607722,\n",
       "  0.7502526558895543,\n",
       "  0.7504645528716323,\n",
       "  0.7504856491472458,\n",
       "  0.750574223723589,\n",
       "  0.7506101483258399,\n",
       "  0.7506033859238558,\n",
       "  0.7506217252570144,\n",
       "  0.7506511087680199,\n",
       "  0.7506809481463811,\n",
       "  0.7506945779645091,\n",
       "  0.7508028711417915,\n",
       "  0.7508336142183267,\n",
       "  0.7509457458954178,\n",
       "  0.7509753899473347,\n",
       "  0.7509987013268306,\n",
       "  0.7510115649848221,\n",
       "  0.7510553534625168,\n",
       "  0.7510551458684647,\n",
       "  0.7510939612748434,\n",
       "  0.7511206045134029,\n",
       "  0.751164365608006,\n",
       "  0.7512116314916655,\n",
       "  0.7512578567882956,\n",
       "  0.75130521506586,\n",
       "  0.7513395664187532,\n",
       "  0.7513640968614109,\n",
       "  0.751409181105543,\n",
       "  0.7514722450127695,\n",
       "  0.7515781618060446,\n",
       "  0.7516115676884005,\n",
       "  0.7516683519182802,\n",
       "  0.7517837269399881,\n",
       "  0.7518436289994572,\n",
       "  0.7519631467217167,\n",
       "  0.7520227996205481,\n",
       "  0.7521363333611013,\n",
       "  0.7522713519963222,\n",
       "  0.7524072979059697,\n",
       "  0.7524596418151006,\n",
       "  0.7525991456422509,\n",
       "  0.7527246616000425,\n",
       "  0.7527659366502745,\n",
       "  0.7528226028335618,\n",
       "  0.7528608561109273,\n",
       "  0.7529182946302553,\n",
       "  0.7530080276928022,\n",
       "  0.7530778290187536,\n",
       "  0.7531341161395513,\n",
       "  0.7532310024152132,\n",
       "  0.7532835172117189,\n",
       "  0.7533358728308407,\n",
       "  0.7533991588461059,\n",
       "  0.7534355719254098,\n",
       "  0.75349201489383,\n",
       "  0.7535464736723361,\n",
       "  0.7536090860389268,\n",
       "  0.7536689957743096,\n",
       "  0.7537276840161632,\n",
       "  0.7537759877768917,\n",
       "  0.7538329140635069,\n",
       "  0.7539100516500239,\n",
       "  0.7539523086056402,\n",
       "  0.7540235179062917,\n",
       "  0.7540837287401653,\n",
       "  0.7541510985247368,\n",
       "  0.7542610472747285,\n",
       "  0.754369388318869,\n",
       "  0.754408518798053,\n",
       "  0.754462856535972,\n",
       "  0.754527933553572,\n",
       "  0.7546174308887372,\n",
       "  0.7546669488756301,\n",
       "  0.7547261322621497,\n",
       "  0.7548007132672518,\n",
       "  0.7549070094426586,\n",
       "  0.7550487052388537,\n",
       "  0.7551708793963803,\n",
       "  0.7552299856010847,\n",
       "  0.7552888576257814,\n",
       "  0.7553586355536785,\n",
       "  0.7554184844806492,\n",
       "  0.7554681598090367,\n",
       "  0.7555727079241146,\n",
       "  0.7556865532392429,\n",
       "  0.7557971925919466,\n",
       "  0.7558616318797707,\n",
       "  0.7560181440458851,\n",
       "  0.7560905576973515,\n",
       "  0.7561730199024702,\n",
       "  0.756249879901905,\n",
       "  0.7563259135246607,\n",
       "  0.7563592088144933,\n",
       "  0.7564303624997673,\n",
       "  0.7565048758404332,\n",
       "  0.7565623571731767,\n",
       "  0.7566681539446056,\n",
       "  0.7567656854867871,\n",
       "  0.7568619366156811,\n",
       "  0.7569856426575419,\n",
       "  0.7570385403999901,\n",
       "  0.7571675476607664,\n",
       "  0.7572786106046765,\n",
       "  0.7573470683865419,\n",
       "  0.757423016009852,\n",
       "  0.7574981097142413,\n",
       "  0.7575629524470104,\n",
       "  0.7576652368576817,\n",
       "  0.7577433681580643,\n",
       "  0.7578204347849822,\n",
       "  0.7579221568464088,\n",
       "  0.757991041128047,\n",
       "  0.7580818413574919,\n",
       "  0.75814078543655,\n",
       "  0.7582104372113143,\n",
       "  0.7582940716153287,\n",
       "  0.7583604025967394,\n",
       "  0.7584700235411169,\n",
       "  0.7585288991966102,\n",
       "  0.7585931255686065,\n",
       "  0.7586825019105743,\n",
       "  0.7587606309203518,\n",
       "  0.7588422854469762,\n",
       "  0.7589171655214233,\n",
       "  0.7590223625922399,\n",
       "  0.75908067590489,\n",
       "  0.7591963936594981,\n",
       "  0.7593205621076613,\n",
       "  0.7593900401520903,\n",
       "  0.7594674213608041,\n",
       "  0.7595278201495642,\n",
       "  0.7596056263911215,\n",
       "  0.7596696225976737,\n",
       "  0.7597411035271137,\n",
       "  0.7598128174315887,\n",
       "  0.7598747451748316,\n",
       "  0.7599656413726914,\n",
       "  0.7600548217662902,\n",
       "  0.7601293612837519,\n",
       "  0.7602055487311021,\n",
       "  0.7602710104029263,\n",
       "  0.7603311146767535,\n",
       "  0.7604025940890328,\n",
       "  0.760484304813673,\n",
       "  0.7605498342857322,\n",
       "  0.7606318300144356,\n",
       "  0.7607018545647564,\n",
       "  0.7607685162189187,\n",
       "  0.7608674905922099,\n",
       "  0.7609944164424274,\n",
       "  0.7610704529060139,\n",
       "  0.7611443120860361,\n",
       "  0.7612278148243737,\n",
       "  0.7612991131540288,\n",
       "  0.7613622835564583,\n",
       "  0.7614676517019522,\n",
       "  0.7615710699414858,\n",
       "  0.761644812948283,\n",
       "  0.7617232771407708,\n",
       "  0.7618651053127745,\n",
       "  0.7619214915279372,\n",
       "  0.7620056212056865,\n",
       "  0.762079022245794,\n",
       "  0.7621618244866192,\n",
       "  0.7622576724415981,\n",
       "  0.7623749704452383,\n",
       "  0.7624415394224371,\n",
       "  0.762537335208229,\n",
       "  0.7626188744299149,\n",
       "  0.7627066655000309,\n",
       "  0.762773556648937,\n",
       "  0.7628440137434269,\n",
       "  0.7629458750380229,\n",
       "  0.7630377566079988,\n",
       "  0.7631461007444799,\n",
       "  0.763212623393795,\n",
       "  0.7632820387162447,\n",
       "  0.7633734400626092,\n",
       "  0.7634494410559958,\n",
       "  0.7635168144538095,\n",
       "  0.7635890391782689,\n",
       "  0.7636732920346386,\n",
       "  0.763746522639857,\n",
       "  0.7638308966386881,\n",
       "  0.7639096733808328,\n",
       "  0.7639963836293784,\n",
       "  0.7640846798725099,\n",
       "  0.7641506039954492,\n",
       "  0.7642348134236553,\n",
       "  0.7643180823276565,\n",
       "  0.7643860578504444,\n",
       "  0.7644497617581723,\n",
       "  0.7645156062138779,\n",
       "  0.7645882334102738,\n",
       "  0.7646537136968199,\n",
       "  0.7647355633811925,\n",
       "  0.7648075273792461,\n",
       "  0.7649060883688549,\n",
       "  0.7649565173488848,\n",
       "  0.7650348759961357,\n",
       "  0.7650980471120117,\n",
       "  0.7651867794141585,\n",
       "  0.7652626627900366,\n",
       "  0.7653352964653815,\n",
       "  0.7654027446737401,\n",
       "  0.7654611343525195,\n",
       "  0.7655344392292726,\n",
       "  0.7656089610702017,\n",
       "  0.7656785944087253,\n",
       "  0.7657457311745206,\n",
       "  0.7658084213996511,\n",
       "  0.765882592760534,\n",
       "  0.765954874344082,\n",
       "  0.766024121697049,\n",
       "  0.7661068690888208,\n",
       "  0.7661765209391841,\n",
       "  0.7662471946120301,\n",
       "  0.7663188764547655,\n",
       "  0.766393651154883,\n",
       "  0.7664725262783495,\n",
       "  0.766558930771085,\n",
       "  0.76662397076866,\n",
       "  0.7667031614998465,\n",
       "  0.7667745554811918,\n",
       "  0.7668391502463177,\n",
       "  0.7669104565617364,\n",
       "  0.766974925892204,\n",
       "  0.7670506681096635,\n",
       "  0.767114746216715,\n",
       "  0.7671904042900122,\n",
       "  0.7672683909529323,\n",
       "  0.7673376532262729,\n",
       "  0.7673863858647236,\n",
       "  0.7674475022216147,\n",
       "  0.7674996967978366,\n",
       "  0.7675795094361637,\n",
       "  0.7676522628173609,\n",
       "  0.7677190176841957,\n",
       "  0.7677881659988511,\n",
       "  0.7678455588821673,\n",
       "  0.7679104549373779,\n",
       "  0.7679727467781006,\n",
       "  0.7680420930926207,\n",
       "  0.7681027057182217,\n",
       "  0.7681791754276663,\n",
       "  0.7682225587471188,\n",
       "  0.7682854049181418,\n",
       "  0.7683365243974027,\n",
       "  0.7684011575570601,\n",
       "  0.7684747851998284,\n",
       "  0.7685304081821787,\n",
       "  0.7685891554944473,\n",
       "  0.7686510669313419,\n",
       "  0.768724251413118,\n",
       "  0.7687840546749035,\n",
       "  0.7688214986705929,\n",
       "  0.768873440999249,\n",
       "  0.7689412347509682,\n",
       "  0.7689973422838201,\n",
       "  0.7690628283983874,\n",
       "  0.7691260686821875,\n",
       "  0.7691940548599441,\n",
       "  0.769247126533023,\n",
       "  0.7692976567747631,\n",
       "  0.7693659179752513,\n",
       "  0.769420463120386,\n",
       "  0.7694659481932616,\n",
       "  0.7695244482031309,\n",
       "  0.76956053635191,\n",
       "  0.7696196049854436,\n",
       "  0.7696821662829971,\n",
       "  0.769730405882428,\n",
       "  0.7697821002225721,\n",
       "  0.7698429501797758,\n",
       "  0.7698810332250803,\n",
       "  0.7699138332155834,\n",
       "  0.7699662828738384,\n",
       "  0.7700198282715548,\n",
       "  0.7700725721727991,\n",
       "  0.7701116592581849,\n",
       "  0.770164224290122,\n",
       "  0.7702182799000814,\n",
       "  0.7702809487559947,\n",
       "  0.7703395173384847,\n",
       "  0.770381189958522,\n",
       "  0.7704270284170868,\n",
       "  0.7704810819991036,\n",
       "  0.7705428802100152,\n",
       "  0.7705937659919103,\n",
       "  0.7706558641714791,\n",
       "  0.7707074745446189,\n",
       "  0.7707526546547625,\n",
       "  0.77081508123276,\n",
       "  0.7708658787149136,\n",
       "  0.7709136523868827,\n",
       "  0.7709653438974239,\n",
       "  0.7710031114419232,\n",
       "  0.7710700288848356,\n",
       "  0.7711100142825265,\n",
       "  0.7711591410063322,\n",
       "  0.7712027430130634,\n",
       "  0.7712511835361611,\n",
       "  0.7713068935284315,\n",
       "  0.7713466574443754,\n",
       "  0.7713949106529479,\n",
       "  0.7714401642583717,\n",
       "  0.7714950570906087,\n",
       "  0.7715410581444185,\n",
       "  0.7715887933236111,\n",
       "  0.7716355738008576,\n",
       "  0.7716755827964067,\n",
       "  0.7717313504163836,\n",
       "  0.7717901440299078,\n",
       "  0.7718454385905664,\n",
       "  0.7718967318929888,\n",
       "  0.7719381237954638,\n",
       "  0.7719893800175484,\n",
       "  0.7720323307588945,\n",
       "  0.7720782619190721,\n",
       "  0.7721285919837856,\n",
       "  0.7721878622051082,\n",
       "  0.7722333687332347,\n",
       "  0.7722854087194955,\n",
       "  0.7723325431922389,\n",
       "  0.7723650240404791,\n",
       "  0.7724101771191381,\n",
       "  0.7724475497219799,\n",
       "  0.7724900695234347,\n",
       "  0.7725300820887616,\n",
       "  0.7725716178543853,\n",
       "  0.7726119930502753,\n",
       "  0.7726527066324913,\n",
       "  0.7727067999770943,\n",
       "  0.7727655807282428,\n",
       "  0.7728164843096906,\n",
       "  0.7728690059222347,\n",
       "  0.7729286667250432,\n",
       "  0.7729784901247339,\n",
       "  0.773021891897805,\n",
       "  0.7730765417082335,\n",
       "  0.7731025296550113,\n",
       "  0.7731408264749914,\n",
       "  0.7731796334922306,\n",
       "  0.7732217336738556,\n",
       "  0.7732678969827209,\n",
       "  0.7733075910212261,\n",
       "  0.7733525659958687,\n",
       "  0.7733947251320082,\n",
       "  0.7734330590601133,\n",
       "  0.7734802220469097,\n",
       "  0.7735207774792794,\n",
       "  0.7735707611887518,\n",
       "  0.7736004776144834,\n",
       "  0.773647597909082,\n",
       "  0.7736913687335832,\n",
       "  0.7737272182101396,\n",
       "  0.7737699417280158,\n",
       "  0.7738085321227546,\n",
       "  0.7738413513472393,\n",
       "  0.7738959305752259,\n",
       "  0.7739330682170295,\n",
       "  0.7739727622242945,\n",
       "  0.7740201083918128,\n",
       "  0.774054272053408,\n",
       "  0.7740941057596478,\n",
       "  0.7741357263862071,\n",
       "  0.7741851849547077,\n",
       "  0.7742260823690529,\n",
       "  0.7742656809685885,\n",
       "  0.7742978938430829,\n",
       "  0.7743341187594861,\n",
       "  0.7743725018296276,\n",
       "  0.7744084111197227,\n",
       "  0.7744490713307155,\n",
       "  0.774507843451284,\n",
       "  0.7745298465195043,\n",
       "  0.774574620576277,\n",
       "  0.7746166643948005,\n",
       "  0.7746466564525294,\n",
       "  0.7746831763660726,\n",
       "  0.7747053481047211,\n",
       "  0.7747347545071956,\n",
       "  0.774769406243287,\n",
       "  0.7748026429573563,\n",
       "  0.7748465912116573,\n",
       "  0.7748958724720173,\n",
       "  0.7749310493685129,\n",
       "  0.7749758960377617,\n",
       "  0.7750083319961389,\n",
       "  0.7750391427546651,\n",
       "  0.775078755478094,\n",
       "  0.7751108849699995,\n",
       "  0.7751323691937964,\n",
       "  0.7751635924278207,\n",
       "  0.7751966831663784,\n",
       "  0.7752415947170503,\n",
       "  0.7752829473250387,\n",
       "  0.7753106687188366,\n",
       "  0.7753377523953727,\n",
       "  0.7753771500123021,\n",
       "  0.7754138915220185,\n",
       "  0.7754488617452102,\n",
       "  0.7754855933127992,\n",
       "  0.7755252937580569,\n",
       "  0.7755664611638202,\n",
       "  0.7755970089860008,\n",
       "  0.7756392793233944,\n",
       "  0.7756721384747691,\n",
       "  0.7757040079278938,\n",
       "  0.7757498428970684,\n",
       "  0.7757832656711141,\n",
       "  0.7758177564013302,\n",
       "  0.7758548541560408,\n",
       "  0.7758814655098423,\n",
       "  0.77591505565217,\n",
       "  0.7759617249399451,\n",
       "  0.7759981942753094,\n",
       "  0.7760277118929253,\n",
       "  0.7760537653259062,\n",
       "  0.7760951372329145,\n",
       "  0.7761257634547369,\n",
       "  0.7761530823049314,\n",
       "  0.7761768906652654,\n",
       "  0.7762116657120456,\n",
       "  0.7762397447731689,\n",
       "  0.776272177766548,\n",
       "  0.7763045865910245,\n",
       "  0.7763408685265485,\n",
       "  0.776365433612391,\n",
       "  0.7763855713233483,\n",
       "  0.7764182060168127,\n",
       "  0.776453090033068,\n",
       "  0.7764755390721987,\n",
       "  0.7765137760286607,\n",
       "  0.7765294521372359,\n",
       "  0.7765660133606065,\n",
       "  0.7765917839373995,\n",
       "  0.7766258101581871,\n",
       "  0.7766514069372873,\n",
       "  0.7766845346737029,\n",
       "  0.7767126393742877,\n",
       "  0.7767438840369093,\n",
       "  0.7767783897928515,\n",
       "  0.7768022552117377,\n",
       "  0.7768296396731212,\n",
       "  0.7768568352134082,\n",
       "  0.7768870118626973,\n",
       "  0.7769066131230808,\n",
       "  0.7769328632680579,\n",
       "  0.7769637153257,\n",
       "  0.7769953161976525,\n",
       "  0.7770271786343047,\n",
       "  0.7770508488691676,\n",
       "  0.7770884040092009,\n",
       "  0.7771236314507828,\n",
       "  0.7771491041564238,\n",
       "  0.7771731726391398,\n",
       "  0.7772026196510632,\n",
       "  0.7772294262409846,\n",
       "  0.7772504602381947,\n",
       "  0.7772778895491153,\n",
       "  0.7773076308669747,\n",
       "  0.7773430250505471,\n",
       "  0.7773697468647723,\n",
       "  0.7773984999081244,\n",
       "  0.7774200597421732,\n",
       "  0.777443682211208,\n",
       "  0.7774671279970196,\n",
       "  0.7775033571908124,\n",
       "  0.777520307235465,\n",
       "  0.7775405517765914,\n",
       "  0.7775662403445331,\n",
       "  0.7775875743435187,\n",
       "  0.7776154859833564,\n",
       "  0.7776383055315084,\n",
       "  0.7776665869633418,\n",
       "  0.777699223096175,\n",
       "  0.7777247899451922,\n",
       "  0.7777572779182186,\n",
       "  0.7777845191034645,\n",
       "  0.7778110214344345,\n",
       "  0.77783271380348,\n",
       "  0.777852115525037,\n",
       "  0.77788174779999,\n",
       "  0.7779162798354714,\n",
       "  0.7779425948024411,\n",
       "  0.7779644367888215,\n",
       "  0.7779862267266281,\n",
       "  0.7780150967131083,\n",
       "  0.7780392421608733,\n",
       "  0.7780681391083555,\n",
       "  0.7780891275081034,\n",
       "  0.7781174652136906,\n",
       "  0.7781403330996731,\n",
       "  0.7781664799409966,\n",
       "  0.7781904044615757,\n",
       "  0.7782142670174264,\n",
       "  0.7782392460394582,\n",
       "  0.778259749293729,\n",
       "  0.7782840778156037,\n",
       "  0.7783070340280943,\n",
       "  0.7783228212648198,\n",
       "  0.7783552835879253,\n",
       "  0.7783856475913725,\n",
       "  0.7784174814944012,\n",
       "  0.7784450639710865,\n",
       "  0.7784606553160509,\n",
       "  0.7784878388154954,\n",
       "  0.7785141267151656,\n",
       "  0.7785417861292515,\n",
       "  0.7785669198040274,\n",
       "  0.7785893638994029,\n",
       "  0.7786073691639828,\n",
       "  0.7786256478870779,\n",
       "  0.7786479052751908,\n",
       "  0.7786738326528801,\n",
       "  0.7787058773847789,\n",
       "  0.7787290673635302,\n",
       "  0.7787554001182568,\n",
       "  0.7787744726624843,\n",
       "  0.7787935836700877,\n",
       "  0.7788060015502558,\n",
       "  0.7788330261537558,\n",
       "  0.7788532515090528,\n",
       "  0.7788777240064981,\n",
       "  0.7788928501568161,\n",
       "  0.7789168702389185,\n",
       "  0.7789454330280395,\n",
       "  0.7789671182046769,\n",
       "  0.7789916469316052,\n",
       "  0.7790110436665728,\n",
       "  0.7790260250617514,\n",
       "  0.7790430128756772,\n",
       "  0.7790754651455443,\n",
       "  0.7791019382709925,\n",
       "  0.7791195993750988,\n",
       "  0.7791416536964709,\n",
       "  0.7791664460675202,\n",
       "  0.7791884597097166,\n",
       "  0.7792104035547363,\n",
       "  0.7792352414993674,\n",
       "  0.779258527644989,\n",
       "  0.7792769347397008,\n",
       "  0.779291767979496,\n",
       "  0.7793163907664765,\n",
       "  0.7793399769177547,\n",
       "  0.7793599371732927,\n",
       "  0.7793878317036351,\n",
       "  0.7794097456266244,\n",
       "  0.7794247505829894,\n",
       "  0.7794431412750363,\n",
       "  0.7794612804728237,\n",
       "  0.779484977039776,\n",
       "  0.7794974299105772,\n",
       "  0.7795203285310627,\n",
       "  0.7795307636176375,\n",
       "  0.7795532696124381,\n",
       "  0.779575601668921,\n",
       "  0.7795944362399052,\n",
       "  0.7796138328833072,\n",
       "  0.7796312909564117,\n",
       "  0.7796479987514647,\n",
       "  0.7796679875307213,\n",
       "  0.7796864187923574,\n",
       "  0.7797097705749392,\n",
       "  0.7797300108979556,\n",
       "  0.7797502739371603,\n",
       "  0.7797638432404199,\n",
       "  0.7797827925023382,\n",
       "  0.7797951142266879,\n",
       "  0.7798080344685037,\n",
       "  0.7798295152723095,\n",
       "  0.7798540525654974,\n",
       "  0.7798713481493518,\n",
       "  0.7798884856075933,\n",
       "  0.7799107009301655,\n",
       "  0.7799295540153964,\n",
       "  0.7799439170065605,\n",
       "  0.77995847807029,\n",
       "  0.7799699782456643,\n",
       "  0.7799977132348805,\n",
       "  0.7800151135811012,\n",
       "  0.7800359452763196,\n",
       "  0.7800554865704413,\n",
       "  0.7800753107578386,\n",
       "  0.7800900856328018,\n",
       "  0.7801088746068782,\n",
       "  0.7801274128532966,\n",
       "  0.780148602918802,\n",
       "  0.7801641985654398,\n",
       "  0.7801838916751166,\n",
       "  0.7802014452027793,\n",
       "  0.7802228760543068,\n",
       "  0.7802340436137098,\n",
       "  0.7802550997356865,\n",
       "  0.780274773602031,\n",
       "  0.7802963647906489,\n",
       "  0.780311761661029,\n",
       "  0.7803301010116225,\n",
       "  0.780350494496951,\n",
       "  0.7803712015116618,\n",
       "  0.7803862363944175,\n",
       "  0.7803983977512055,\n",
       "  0.7804135601663766,\n",
       "  0.7804308735866318,\n",
       "  0.7804473904673641,\n",
       "  0.7804642842646388,\n",
       "  0.7804868572446815,\n",
       "  0.7805015473035468,\n",
       "  0.7805135348615078,\n",
       "  0.7805296762282936,\n",
       "  0.7805451207804726,\n",
       "  0.7805591581764098,\n",
       "  0.7805809823064407,\n",
       "  0.7805983192256161,\n",
       "  0.7806134018178443,\n",
       "  0.780633218917316,\n",
       "  0.7806469221585592,\n",
       "  0.780665664827007,\n",
       "  0.7806796267108365,\n",
       "  0.7807012442585495,\n",
       "  0.7807157804063077,\n",
       "  0.7807352790048547,\n",
       "  0.7807534466604527,\n",
       "  0.7807767413748795,\n",
       "  0.7807895654359756,\n",
       "  0.7808031169367838,\n",
       "  0.7808181154783311,\n",
       "  0.7808286731181295,\n",
       "  0.780840935034649,\n",
       "  0.7808493836663246,\n",
       "  0.78086122662817,\n",
       "  0.7808743776695852,\n",
       "  0.7808900736874171,\n",
       "  0.7809087358207482,\n",
       "  0.780917822149233,\n",
       "  0.7809316037914033,\n",
       "  0.780943393282117,\n",
       "  0.7809610650378778,\n",
       "  0.780985766229881,\n",
       "  0.7810000023944015,\n",
       "  0.7810103569302709,\n",
       "  0.7810316787820535,\n",
       "  0.7810358988364621,\n",
       "  0.7810597370993312,\n",
       "  0.7810693000650527,\n",
       "  0.7810801362824774,\n",
       "  0.7810974475793679,\n",
       "  0.7811143384791535,\n",
       "  0.7811312771035842,\n",
       "  0.7811494911003483,\n",
       "  0.7811682815126718,\n",
       "  0.7811780197968003,\n",
       "  0.7811897451874996,\n",
       "  0.7812074012865045,\n",
       "  0.7812209456318662,\n",
       "  0.7812330030602592,\n",
       "  0.781243044096222,\n",
       "  0.7812559087666159,\n",
       "  0.7812670976092654,\n",
       "  0.7812855104234956,\n",
       "  0.7812974352884995,\n",
       "  0.7813166759956369,\n",
       "  0.7813284583601783,\n",
       "  0.7813515186664896,\n",
       "  0.7813641118345178,\n",
       "  0.781378589518544,\n",
       "  0.781392327614105,\n",
       "  0.7814109805060777,\n",
       "  0.7814178281832234,\n",
       "  0.781428834681756,\n",
       "  0.7814455481743243,\n",
       "  0.7814508426841918,\n",
       "  0.7814688072888015,\n",
       "  0.7814886293155198,\n",
       "  0.7815003476120557,\n",
       "  0.7815217599049148,\n",
       "  0.7815371852175673,\n",
       "  0.7815539970637583,\n",
       "  0.7815635422513251,\n",
       "  0.7815787573590673,\n",
       "  0.781589254434705,\n",
       "  0.7816025081437662,\n",
       "  0.7816148270589156,\n",
       "  0.7816255320963048,\n",
       "  0.781641828051149,\n",
       "  0.7816655973128431,\n",
       "  0.7816763309387629,\n",
       "  0.7816920398472365,\n",
       "  0.7817066166178019,\n",
       "  0.7817149448601588,\n",
       "  0.781732618767714,\n",
       "  0.781747782580189,\n",
       "  0.7817615592114608,\n",
       "  0.7817761559098331,\n",
       "  0.7817896682297236,\n",
       "  0.7818140438059336,\n",
       "  0.7818239801560113,\n",
       "  0.7818305143758074,\n",
       "  0.7818482573970226,\n",
       "  0.7818584609197405,\n",
       "  0.7818643396212981,\n",
       "  0.7818817399670274,\n",
       "  0.7818941158689863,\n",
       "  0.7819079558949672,\n",
       "  0.7819230256991585,\n",
       "  0.7819378526056451,\n",
       "  0.7819531069419281,\n",
       "  0.7819614864889156,\n",
       "  0.7819769253416637,\n",
       "  0.7819937485980327,\n",
       "  0.7820035923601039,\n",
       "  0.7820134823268494,\n",
       "  0.782031602972282,\n",
       "  0.7820437401393865,\n",
       "  0.7820585726246907,\n",
       "  0.7820703322037456,\n",
       "  0.7820831768904934,\n",
       "  0.7820953226268568,\n",
       "  0.7821106980227434,\n",
       "  0.7821241084521496,\n",
       "  0.782135238187952,\n",
       "  0.7821546826677156,\n",
       "  0.7821678558609412,\n",
       "  0.7821847717372878,\n",
       "  0.7822034039598168,\n",
       "  0.7822178004104653,\n",
       "  0.7822328103450644,\n",
       "  0.7822437469795793,\n",
       "  0.7822571446122032,\n",
       "  0.7822681283343226,\n",
       "  0.7822785405859859,\n",
       "  0.7822856084869023,\n",
       "  0.7822998104767657,\n",
       "  0.7823079257048735,\n",
       "  0.7823229783917186,\n",
       "  0.7823345114068764,\n",
       "  0.7823474430351661,\n",
       "  0.7823637511331805,\n",
       "  0.7823729236872778,\n",
       "  0.7823837328591416,\n",
       "  0.782398449975817,\n",
       "  0.7824085800944426,\n",
       "  0.7824179236032591,\n",
       "  0.7824248233256392,\n",
       "  0.7824439784629312,\n",
       "  0.7824577970881398,\n",
       "  0.7824698167291377,\n",
       "  0.7824772094840221,\n",
       "  0.7824846221655035,\n",
       "  0.7824914377741046,\n",
       "  0.7824995651302853,\n",
       "  0.7825067890253723,\n",
       "  0.782519573150404,\n",
       "  0.7825274218855196,\n",
       "  0.7825325681610904,\n",
       "  0.7825444503072816,\n",
       "  0.7825609741779465,\n",
       "  0.7825690038846257,\n",
       "  0.7825786039391659,\n",
       "  0.7825839012866384,\n",
       "  0.7825930361232563,\n",
       "  0.7826006718696417,\n",
       "  0.7826110634469214,\n",
       "  0.7826219260065299,\n",
       "  0.7826347371953577,\n",
       "  0.7826458456001899,\n",
       "  0.7826558974031403,\n",
       "  0.7826706686616733,\n",
       "  0.782679467099695,\n",
       "  0.7826921378951934,\n",
       "  0.7827086226873691,\n",
       "  0.782720486284091,\n",
       "  0.782742244212519,\n",
       "  0.7827499156010707,\n",
       "  0.7827600735404028,\n",
       "  0.7827730108310861,\n",
       "  0.7827831773003211,\n",
       "  0.782796842062562,\n",
       "  0.7828069159080009,\n",
       "  0.7828231320973795,\n",
       "  0.7828328604218893,\n",
       "  0.7828407540669051,\n",
       "  0.7828542193105456,\n",
       "  0.7828622582877187,\n",
       "  0.782876319169546,\n",
       "  0.782889171008817,\n",
       "  ...],\n",
       " 'auc-stdv': [0.0025118386174834647,\n",
       "  0.0033940797962131305,\n",
       "  0.003230111447601901,\n",
       "  0.0036372141805654673,\n",
       "  0.003930406624727124,\n",
       "  0.0033117306885576416,\n",
       "  0.0032290832171137838,\n",
       "  0.0033033142286122566,\n",
       "  0.0033491952327503196,\n",
       "  0.003131592702424153,\n",
       "  0.0034153100021034654,\n",
       "  0.0032159588395443616,\n",
       "  0.0033167571229381024,\n",
       "  0.0032639367045764318,\n",
       "  0.0033235822235645443,\n",
       "  0.00311768933468644,\n",
       "  0.003030971074659634,\n",
       "  0.0032236675242918113,\n",
       "  0.003279713950863316,\n",
       "  0.003282203256834876,\n",
       "  0.0032465216450192434,\n",
       "  0.0033061190197120603,\n",
       "  0.0032825599728984497,\n",
       "  0.0034953135472191015,\n",
       "  0.0035214345382453627,\n",
       "  0.003390000778476213,\n",
       "  0.0033769685265561734,\n",
       "  0.003378831295748072,\n",
       "  0.003363732205080782,\n",
       "  0.003383293555876312,\n",
       "  0.0035316903795641038,\n",
       "  0.0035695280673826504,\n",
       "  0.0034595536886138714,\n",
       "  0.0034367653824203463,\n",
       "  0.003431148469161069,\n",
       "  0.003405291203299998,\n",
       "  0.003515116370182577,\n",
       "  0.0035597336874133197,\n",
       "  0.0034630373790892443,\n",
       "  0.003405543392441353,\n",
       "  0.003418006581200635,\n",
       "  0.0034681156215531795,\n",
       "  0.003514966225927873,\n",
       "  0.0035480752276494413,\n",
       "  0.00358411604563788,\n",
       "  0.0035677121049001483,\n",
       "  0.003488239134983195,\n",
       "  0.0034831203588882023,\n",
       "  0.003434226101505925,\n",
       "  0.0034719783825045425,\n",
       "  0.0034889336569835015,\n",
       "  0.0034478858755769702,\n",
       "  0.0034809257715932625,\n",
       "  0.0034822820863585633,\n",
       "  0.003474302040698179,\n",
       "  0.0034754686094412035,\n",
       "  0.003452311352319874,\n",
       "  0.0034490909722977693,\n",
       "  0.003437548498120136,\n",
       "  0.003446971325299535,\n",
       "  0.003409864523176967,\n",
       "  0.0033874969848481976,\n",
       "  0.0033793757828850073,\n",
       "  0.003387462902716452,\n",
       "  0.0033861576432232653,\n",
       "  0.003312063982936037,\n",
       "  0.0032905988671552374,\n",
       "  0.0032595729340172148,\n",
       "  0.0032301774708425974,\n",
       "  0.0032468827082822566,\n",
       "  0.0032330475624220223,\n",
       "  0.003276578099878576,\n",
       "  0.003303800792575121,\n",
       "  0.0033323645642556908,\n",
       "  0.003303834470088924,\n",
       "  0.003351828901536493,\n",
       "  0.003392905345531247,\n",
       "  0.0034017150730494224,\n",
       "  0.003354002150599543,\n",
       "  0.003331134181705487,\n",
       "  0.0032966301985816295,\n",
       "  0.003294047043238862,\n",
       "  0.003267625689574563,\n",
       "  0.003237746086434832,\n",
       "  0.003211242115762034,\n",
       "  0.00317990527619338,\n",
       "  0.0031578047859650072,\n",
       "  0.003165765232751944,\n",
       "  0.00315946640728941,\n",
       "  0.003196291393760068,\n",
       "  0.0031919962439707133,\n",
       "  0.003187848665491238,\n",
       "  0.0032297640458906463,\n",
       "  0.0032005828282619395,\n",
       "  0.003199656532998739,\n",
       "  0.003192424754791226,\n",
       "  0.0031652016427727568,\n",
       "  0.0031827287030320502,\n",
       "  0.003161317887384784,\n",
       "  0.0031985555986629418,\n",
       "  0.0032110316218404776,\n",
       "  0.0032360035632850153,\n",
       "  0.0032326454465489147,\n",
       "  0.0032206547844539192,\n",
       "  0.0032039236834676427,\n",
       "  0.003209368511733242,\n",
       "  0.0032227850745536464,\n",
       "  0.0032187635625685494,\n",
       "  0.0032281920773927024,\n",
       "  0.003239336144033186,\n",
       "  0.0032675124198994297,\n",
       "  0.0032775944763661683,\n",
       "  0.003300211942175345,\n",
       "  0.0032994017768617663,\n",
       "  0.003289994572030794,\n",
       "  0.0032663542936032333,\n",
       "  0.0032728301069072825,\n",
       "  0.0032731657731875255,\n",
       "  0.003275002914772838,\n",
       "  0.003269065038028848,\n",
       "  0.0032904317930014465,\n",
       "  0.003300882350292826,\n",
       "  0.0033234729230497257,\n",
       "  0.003328374559658338,\n",
       "  0.0033414305493255168,\n",
       "  0.0033391163551915633,\n",
       "  0.003347352473633498,\n",
       "  0.0033629796781695885,\n",
       "  0.0033636537311207354,\n",
       "  0.0033788569174931634,\n",
       "  0.0033896957616375207,\n",
       "  0.0034009377704874513,\n",
       "  0.0033981793095818605,\n",
       "  0.0034220440987939933,\n",
       "  0.003439496661630464,\n",
       "  0.003471812465273711,\n",
       "  0.0034643209580951543,\n",
       "  0.0034870439863094074,\n",
       "  0.003474685316238042,\n",
       "  0.003488145977746636,\n",
       "  0.0034856285566895783,\n",
       "  0.003502898324032061,\n",
       "  0.003499366310506273,\n",
       "  0.0035031896100268167,\n",
       "  0.0034998882009902583,\n",
       "  0.003513281657694244,\n",
       "  0.0035239957586243893,\n",
       "  0.0035237315382376866,\n",
       "  0.0035164774942302787,\n",
       "  0.003533018138734637,\n",
       "  0.0035278790986447124,\n",
       "  0.0035318842302266237,\n",
       "  0.003529068382769567,\n",
       "  0.003520076508905757,\n",
       "  0.003524180224469345,\n",
       "  0.003530879953056868,\n",
       "  0.0035344146373766706,\n",
       "  0.003529378684919499,\n",
       "  0.003532030580616837,\n",
       "  0.003511153216023648,\n",
       "  0.0035101216898069014,\n",
       "  0.0035242235013995,\n",
       "  0.0035136028018394137,\n",
       "  0.003506513776680342,\n",
       "  0.003476287660177252,\n",
       "  0.003468746438188737,\n",
       "  0.0034789620973007607,\n",
       "  0.0034698725968186515,\n",
       "  0.003470544173127759,\n",
       "  0.0034779730458756055,\n",
       "  0.0034893945244666314,\n",
       "  0.003479955536044885,\n",
       "  0.003477503232031555,\n",
       "  0.0034764839861381037,\n",
       "  0.0034647911311358904,\n",
       "  0.003469896010067242,\n",
       "  0.0034833468652888163,\n",
       "  0.003480902777387196,\n",
       "  0.003465292732003042,\n",
       "  0.003436660899805999,\n",
       "  0.0034408870462773813,\n",
       "  0.0034150972795411747,\n",
       "  0.0034120530646731084,\n",
       "  0.0034141014073957193,\n",
       "  0.003432431143582076,\n",
       "  0.0034573049433499936,\n",
       "  0.003472985940970296,\n",
       "  0.003472129504078228,\n",
       "  0.00346105296689721,\n",
       "  0.0034743601961340345,\n",
       "  0.0034941240966113473,\n",
       "  0.00350486145094726,\n",
       "  0.0035103991534003592,\n",
       "  0.0035197412234620365,\n",
       "  0.0035136302545807773,\n",
       "  0.0035206779917789323,\n",
       "  0.003504522813395316,\n",
       "  0.003530038245519788,\n",
       "  0.003530892174345424,\n",
       "  0.0035195522092177876,\n",
       "  0.0035139070201149116,\n",
       "  0.0035095400597810406,\n",
       "  0.003512270932186577,\n",
       "  0.003512107590333883,\n",
       "  0.0035135359444583084,\n",
       "  0.003521636780898897,\n",
       "  0.0035285918608940997,\n",
       "  0.0035267234790084725,\n",
       "  0.0035236928505621243,\n",
       "  0.003495567154701598,\n",
       "  0.003485295746577793,\n",
       "  0.003475616118641771,\n",
       "  0.0034808646967659455,\n",
       "  0.003481709319507495,\n",
       "  0.0034678093873725443,\n",
       "  0.003468264857072257,\n",
       "  0.0034606982400647184,\n",
       "  0.0034679889698473166,\n",
       "  0.0034714700773397574,\n",
       "  0.003460482254975915,\n",
       "  0.0034567636739596106,\n",
       "  0.003454384202606999,\n",
       "  0.0034733555248734225,\n",
       "  0.0034581195189568354,\n",
       "  0.0034835876000397837,\n",
       "  0.0034870419412521554,\n",
       "  0.0034823206104927775,\n",
       "  0.0034990783053503614,\n",
       "  0.0034984497991760667,\n",
       "  0.0034908269011312905,\n",
       "  0.003501692564138304,\n",
       "  0.0035184918064178378,\n",
       "  0.0034984970173289995,\n",
       "  0.0034939283921963478,\n",
       "  0.0034643020323676605,\n",
       "  0.003461431382559336,\n",
       "  0.003448320505050172,\n",
       "  0.0034466555060832828,\n",
       "  0.0034380117016306307,\n",
       "  0.0034297212392475304,\n",
       "  0.0034187397476102836,\n",
       "  0.003416226339085882,\n",
       "  0.003428586282087065,\n",
       "  0.0034146174237170584,\n",
       "  0.003394289264925098,\n",
       "  0.0033888309077747553,\n",
       "  0.003394745739156281,\n",
       "  0.003379504844928984,\n",
       "  0.003382280502017568,\n",
       "  0.0034050576764285433,\n",
       "  0.003403779271862455,\n",
       "  0.003397678800606658,\n",
       "  0.0034011575437949285,\n",
       "  0.003415358160412959,\n",
       "  0.0034371425165475914,\n",
       "  0.003440671007019731,\n",
       "  0.0034413612179168525,\n",
       "  0.0034365038660933533,\n",
       "  0.003447656585576253,\n",
       "  0.003466482006425378,\n",
       "  0.0034422890100471695,\n",
       "  0.003445864567657707,\n",
       "  0.003441867595731202,\n",
       "  0.003429833202929965,\n",
       "  0.003434244881237196,\n",
       "  0.0034505357496192957,\n",
       "  0.003462033726260589,\n",
       "  0.0034400692074421477,\n",
       "  0.003446245343203445,\n",
       "  0.003458221952432722,\n",
       "  0.0034572680127930603,\n",
       "  0.0034607360077365,\n",
       "  0.0034607844440352267,\n",
       "  0.0034762097220874316,\n",
       "  0.0034691794004593763,\n",
       "  0.003484208396165721,\n",
       "  0.0034675625350127958,\n",
       "  0.0034698038953388495,\n",
       "  0.0034489620590185018,\n",
       "  0.0034601945383190644,\n",
       "  0.0034548107099895806,\n",
       "  0.0034626966876316807,\n",
       "  0.003451925567309972,\n",
       "  0.0034475598799832284,\n",
       "  0.003469490250077011,\n",
       "  0.0034520715730336116,\n",
       "  0.003457104990699359,\n",
       "  0.0034583681272559444,\n",
       "  0.003448104498504826,\n",
       "  0.0034561986082968493,\n",
       "  0.003440765950279132,\n",
       "  0.0034053259651383523,\n",
       "  0.0034080807480433204,\n",
       "  0.003397162980654356,\n",
       "  0.0034167367146513495,\n",
       "  0.0034236307973485964,\n",
       "  0.0034389851226674507,\n",
       "  0.003424972048593307,\n",
       "  0.0034164950224315877,\n",
       "  0.003399910789066036,\n",
       "  0.0034080610392125807,\n",
       "  0.0034209253175503797,\n",
       "  0.003396906620931198,\n",
       "  0.0033795367201097056,\n",
       "  0.0033757585704658945,\n",
       "  0.003393796398991453,\n",
       "  0.0033620416268272664,\n",
       "  0.0033811641184266225,\n",
       "  0.003399760791642706,\n",
       "  0.0034095007870379736,\n",
       "  0.003402521732643375,\n",
       "  0.003395301006029956,\n",
       "  0.003385159644042529,\n",
       "  0.003381354757049898,\n",
       "  0.003369767242740155,\n",
       "  0.0033555890838752687,\n",
       "  0.00335201548231416,\n",
       "  0.0033712857001814284,\n",
       "  0.003354912914316782,\n",
       "  0.003362210900394681,\n",
       "  0.003349459313462848,\n",
       "  0.0033533249559930755,\n",
       "  0.0033335163977711254,\n",
       "  0.0033371480579204504,\n",
       "  0.0033434586232468145,\n",
       "  0.003340257431086397,\n",
       "  0.0033545910358950214,\n",
       "  0.003332859947971547,\n",
       "  0.003323203917984853,\n",
       "  0.0033124112947715383,\n",
       "  0.0033036898766060905,\n",
       "  0.0033173274092549608,\n",
       "  0.003319565684468968,\n",
       "  0.0033112163835832737,\n",
       "  0.003293319669280879,\n",
       "  0.003283363565677584,\n",
       "  0.0032712061615904177,\n",
       "  0.0032655629331692325,\n",
       "  0.0032432333125700205,\n",
       "  0.003248523737104438,\n",
       "  0.0032387100398597797,\n",
       "  0.0032330316107302254,\n",
       "  0.0032216707657062053,\n",
       "  0.0032079336724950675,\n",
       "  0.003191480559086782,\n",
       "  0.0031966308202231414,\n",
       "  0.003196361422365373,\n",
       "  0.003200980323327642,\n",
       "  0.0031705174239147213,\n",
       "  0.0031673332063991413,\n",
       "  0.003166017187248125,\n",
       "  0.003163967771969291,\n",
       "  0.003163903859630667,\n",
       "  0.0031514896789003495,\n",
       "  0.0031555992938476886,\n",
       "  0.0031513596794523935,\n",
       "  0.003147538723381344,\n",
       "  0.003151766573699966,\n",
       "  0.003152180757063788,\n",
       "  0.0031468155217528482,\n",
       "  0.0031535234208408466,\n",
       "  0.003163367263592176,\n",
       "  0.0031582714579780615,\n",
       "  0.0031386607776195145,\n",
       "  0.0031431164388780576,\n",
       "  0.003153934363848367,\n",
       "  0.003150820574542485,\n",
       "  0.0031339384750222535,\n",
       "  0.0031212781829735334,\n",
       "  0.0031331118028947117,\n",
       "  0.003132206057771727,\n",
       "  0.003118338297289766,\n",
       "  0.003119155994216829,\n",
       "  0.003117103468220906,\n",
       "  0.003112420162533616,\n",
       "  0.0031210092492825452,\n",
       "  0.00311938030576301,\n",
       "  0.00312142189355467,\n",
       "  0.003123823557240206,\n",
       "  0.0031195919117567275,\n",
       "  0.0031096637677646725,\n",
       "  0.0031200099168782764,\n",
       "  0.0031060484821907246,\n",
       "  0.003127853669019277,\n",
       "  0.003141378882690623,\n",
       "  0.0031414458355268175,\n",
       "  0.003155464962484729,\n",
       "  0.0031545422621340907,\n",
       "  0.0031393233574968545,\n",
       "  0.0031453963750344514,\n",
       "  0.0031559341863155537,\n",
       "  0.003176492604176756,\n",
       "  0.003163750230026659,\n",
       "  0.0031606155778784975,\n",
       "  0.003147110849759019,\n",
       "  0.003132448768827219,\n",
       "  0.0031381773557362393,\n",
       "  0.003145431880456902,\n",
       "  0.0031450753908309923,\n",
       "  0.0031428127061616826,\n",
       "  0.0031314673671433988,\n",
       "  0.0031297011173744807,\n",
       "  0.003123016182150995,\n",
       "  0.0031313457439358402,\n",
       "  0.003102770388086403,\n",
       "  0.0031135760683262893,\n",
       "  0.003108411182371826,\n",
       "  0.0031098929875416677,\n",
       "  0.0031015206983092975,\n",
       "  0.0031029190880304124,\n",
       "  0.0030895557710945314,\n",
       "  0.003089007964476422,\n",
       "  0.003094874144162669,\n",
       "  0.00309372429642089,\n",
       "  0.003098621413759031,\n",
       "  0.003108174430443857,\n",
       "  0.003095656737864028,\n",
       "  0.0030893181846752557,\n",
       "  0.00310237390910233,\n",
       "  0.003108793487614402,\n",
       "  0.003115005760062901,\n",
       "  0.00310387959482008,\n",
       "  0.003096352902732358,\n",
       "  0.0030936274469712016,\n",
       "  0.0031100462918126626,\n",
       "  0.0030910505103595677,\n",
       "  0.0030973955683414817,\n",
       "  0.0030974765830189413,\n",
       "  0.0030947348273481783,\n",
       "  0.003105647698461759,\n",
       "  0.0031093878069767783,\n",
       "  0.0031041894864264484,\n",
       "  0.0031081762318055607,\n",
       "  0.0030941704919654855,\n",
       "  0.0030895163644053575,\n",
       "  0.003079217519352921,\n",
       "  0.0030782244632606365,\n",
       "  0.003083291834378901,\n",
       "  0.0030775570255956604,\n",
       "  0.003096737763398654,\n",
       "  0.003086180382396192,\n",
       "  0.003087971856391328,\n",
       "  0.003082630800893811,\n",
       "  0.0030874521038961053,\n",
       "  0.003082718416965323,\n",
       "  0.003089049018197431,\n",
       "  0.003092980610706766,\n",
       "  0.003101768159949292,\n",
       "  0.0031003684187793845,\n",
       "  0.0030918345483205447,\n",
       "  0.0030851218987923566,\n",
       "  0.003088433174384359,\n",
       "  0.003086001979442112,\n",
       "  0.003088429833989812,\n",
       "  0.003070631649781879,\n",
       "  0.0030669917948457684,\n",
       "  0.003070218056373172,\n",
       "  0.0030609234400505512,\n",
       "  0.003061720438515472,\n",
       "  0.0030486388595552623,\n",
       "  0.003046548951344278,\n",
       "  0.0030547957046340992,\n",
       "  0.00305548457007721,\n",
       "  0.0030453900556416647,\n",
       "  0.003040107733177747,\n",
       "  0.003046072452885909,\n",
       "  0.003032144751851779,\n",
       "  0.0030224100935091636,\n",
       "  0.0030232006778084593,\n",
       "  0.0030182575907640005,\n",
       "  0.0030169236955993745,\n",
       "  0.002997020569935116,\n",
       "  0.0030086623990023043,\n",
       "  0.0030112414688599647,\n",
       "  0.003017470059789395,\n",
       "  0.003018498808595905,\n",
       "  0.003020353493604127,\n",
       "  0.00302377148869241,\n",
       "  0.003028655433412218,\n",
       "  0.0030253547190249724,\n",
       "  0.003018084831893882,\n",
       "  0.0030171720084430664,\n",
       "  0.003015768844256848,\n",
       "  0.00301639376679557,\n",
       "  0.0030157208492739996,\n",
       "  0.0030092623602110654,\n",
       "  0.0030113750412235005,\n",
       "  0.003013016420593734,\n",
       "  0.0030129286017880267,\n",
       "  0.0029970227299759658,\n",
       "  0.0029913039625336464,\n",
       "  0.0029914493691115267,\n",
       "  0.0030032980306803412,\n",
       "  0.003005081780537919,\n",
       "  0.002998031840597712,\n",
       "  0.0029931405964965154,\n",
       "  0.0030013061697596573,\n",
       "  0.002999420978985781,\n",
       "  0.0029930324433494614,\n",
       "  0.003006278369317109,\n",
       "  0.003019416123466267,\n",
       "  0.0030262288652813593,\n",
       "  0.003020139867074663,\n",
       "  0.003019788872235394,\n",
       "  0.0030122737557532536,\n",
       "  0.003000961453861636,\n",
       "  0.003004066176519718,\n",
       "  0.0030153115508965997,\n",
       "  0.002994952037486467,\n",
       "  0.003004155605412335,\n",
       "  0.003003096674304031,\n",
       "  0.0030005199308930893,\n",
       "  0.003002530080739221,\n",
       "  0.0030075759263824896,\n",
       "  0.0030116451456400867,\n",
       "  0.0030094824883509495,\n",
       "  0.0030185959402530575,\n",
       "  0.0030291498659915277,\n",
       "  0.003034375747402513,\n",
       "  0.0030322548700135376,\n",
       "  0.0030437386214276483,\n",
       "  0.0030488072466794565,\n",
       "  0.003056018400773135,\n",
       "  0.0030635428090686626,\n",
       "  0.0030521655773902757,\n",
       "  0.003043832597448949,\n",
       "  0.0030383477237431087,\n",
       "  0.003037398740319929,\n",
       "  0.0030347158212134686,\n",
       "  0.003032348853258816,\n",
       "  0.0030285244948488853,\n",
       "  0.0030301398896983964,\n",
       "  0.0030356086768534994,\n",
       "  0.0030295447285411544,\n",
       "  0.003036920019449427,\n",
       "  0.0030350877450638484,\n",
       "  0.0030326165846391857,\n",
       "  0.003035004012749678,\n",
       "  0.0030303358483087742,\n",
       "  0.003018031971638024,\n",
       "  0.0030247472158399314,\n",
       "  0.003024083601902674,\n",
       "  0.0030125686308595757,\n",
       "  0.0030187108726452572,\n",
       "  0.003016630846181981,\n",
       "  0.003015828991569734,\n",
       "  0.003007644507973113,\n",
       "  0.0030055927849162913,\n",
       "  0.003000400168604927,\n",
       "  0.0030005256005589324,\n",
       "  0.0030016692229024576,\n",
       "  0.0029956439225121137,\n",
       "  0.0029989361641232933,\n",
       "  0.003005288867797353,\n",
       "  0.0030029766948876783,\n",
       "  0.0030136449831613863,\n",
       "  0.0030284288298963215,\n",
       "  0.0030217702394766855,\n",
       "  0.003032896931967684,\n",
       "  0.003025180537388321,\n",
       "  0.003014874738813839,\n",
       "  0.0030202245709808383,\n",
       "  0.0030183609338941503,\n",
       "  0.0030201262298182705,\n",
       "  0.0030142682871048486,\n",
       "  0.0030175999349838062,\n",
       "  0.003019419491536181,\n",
       "  0.0030174370260493545,\n",
       "  0.0030190540367488294,\n",
       "  0.003015645033271102,\n",
       "  0.0030144728824772,\n",
       "  0.0030128738871850577,\n",
       "  0.0029957949711843096,\n",
       "  0.002991908975560208,\n",
       "  0.002992709821054925,\n",
       "  0.0030027675471446893,\n",
       "  0.003002409469201267,\n",
       "  0.0030042932479905668,\n",
       "  0.0030081082377362268,\n",
       "  0.0029894527557438465,\n",
       "  0.0029915642528214547,\n",
       "  0.0030049389540208337,\n",
       "  0.0029989508859132137,\n",
       "  0.0029971979032199806,\n",
       "  0.002994582381646117,\n",
       "  0.002992203992638443,\n",
       "  0.002998014669588066,\n",
       "  0.0029810010371949893,\n",
       "  0.002987254564159038,\n",
       "  0.0029900619161069707,\n",
       "  0.0029880861349027097,\n",
       "  0.002980202890200061,\n",
       "  0.0029797844378750926,\n",
       "  0.002968791917369135,\n",
       "  0.0029644444663776475,\n",
       "  0.002963814258912986,\n",
       "  0.0029607870095585695,\n",
       "  0.0029611182085805903,\n",
       "  0.0029657034760518907,\n",
       "  0.0029652909282916083,\n",
       "  0.002963060004247191,\n",
       "  0.0029706622341365966,\n",
       "  0.002964629719733813,\n",
       "  0.0029592267451925554,\n",
       "  0.0029466320726679513,\n",
       "  0.0029408437988816495,\n",
       "  0.0029347560257283905,\n",
       "  0.0029392055288328775,\n",
       "  0.0029346377373180754,\n",
       "  0.0029251734521354867,\n",
       "  0.0029294095916473618,\n",
       "  0.0029231931865809973,\n",
       "  0.0029282470794115664,\n",
       "  0.002930966710455673,\n",
       "  0.002922880625420085,\n",
       "  0.0029252857789318896,\n",
       "  0.0029267320866564967,\n",
       "  0.002926607660970805,\n",
       "  0.002926184197245092,\n",
       "  0.002916280907228181,\n",
       "  0.0029131432062259434,\n",
       "  0.0029031583980386848,\n",
       "  0.0029016274859355864,\n",
       "  0.002904072550266905,\n",
       "  0.0028991884789892146,\n",
       "  0.0029041552296514127,\n",
       "  0.0029006806856215154,\n",
       "  0.0029000537284701645,\n",
       "  0.0029039853850365725,\n",
       "  0.0029082028864353443,\n",
       "  0.002909119830938919,\n",
       "  0.0029040116768630497,\n",
       "  0.0029023964384399807,\n",
       "  0.0029018760347016568,\n",
       "  0.0029020715513631153,\n",
       "  0.0028946266147200058,\n",
       "  0.0028882777724992034,\n",
       "  0.0028946602250570154,\n",
       "  0.0028856933723576256,\n",
       "  0.002886525014672646,\n",
       "  0.0028824871519263027,\n",
       "  0.0028844717736700924,\n",
       "  0.0028798025688653046,\n",
       "  0.0028802987473359755,\n",
       "  0.002879711197769032,\n",
       "  0.002881172638475808,\n",
       "  0.0028779651828663025,\n",
       "  0.0028769623648351203,\n",
       "  0.002879243440407508,\n",
       "  0.0028720195882351567,\n",
       "  0.002873513880132871,\n",
       "  0.0028683840224745434,\n",
       "  0.0028666156242693292,\n",
       "  0.0028661768818278918,\n",
       "  0.002861813109968412,\n",
       "  0.0028640063719831276,\n",
       "  0.002861851677198817,\n",
       "  0.0028706806932315915,\n",
       "  0.0028642368085241205,\n",
       "  0.002860952906469595,\n",
       "  0.0028696201303511147,\n",
       "  0.00286508404895557,\n",
       "  0.0028618823241996862,\n",
       "  0.002859136782706037,\n",
       "  0.0028665492360664744,\n",
       "  0.0028654511971268745,\n",
       "  0.002864260954708189,\n",
       "  0.0028575225794288416,\n",
       "  0.0028404251374405096,\n",
       "  0.002846857627057977,\n",
       "  0.0028446794911292537,\n",
       "  0.002847843319786166,\n",
       "  0.002849560594649633,\n",
       "  0.0028539038610703856,\n",
       "  0.0028523633227337066,\n",
       "  0.0028499189169071217,\n",
       "  0.0028505401898417573,\n",
       "  0.0028480268000217568,\n",
       "  0.0028476377593257963,\n",
       "  0.002856056425798012,\n",
       "  0.0028527266754723763,\n",
       "  0.0028517433921693342,\n",
       "  0.0028536170370711844,\n",
       "  0.002852965401342265,\n",
       "  0.002842782596420416,\n",
       "  0.002843074449440832,\n",
       "  0.002848175138276232,\n",
       "  0.0028529990608606266,\n",
       "  0.00285997563336145,\n",
       "  0.002855709693985298,\n",
       "  0.002851350973574371,\n",
       "  0.002851725172049676,\n",
       "  0.002854832379798785,\n",
       "  0.0028525842246335687,\n",
       "  0.002846035909164722,\n",
       "  0.0028448522192274224,\n",
       "  0.0028406894153169856,\n",
       "  0.002833637993325825,\n",
       "  0.002836997989787806,\n",
       "  0.002841005543289387,\n",
       "  0.0028408626565007327,\n",
       "  0.0028452708853749886,\n",
       "  0.002846097161361287,\n",
       "  0.0028368676147270113,\n",
       "  0.002825759749985913,\n",
       "  0.002825541726877198,\n",
       "  0.002814134566114522,\n",
       "  0.0028146442055582933,\n",
       "  0.0028115570103303318,\n",
       "  0.002806514801780574,\n",
       "  0.0028068022467289456,\n",
       "  0.002812537571630256,\n",
       "  0.002809118726038952,\n",
       "  0.0028007465268049562,\n",
       "  0.0027999260334438435,\n",
       "  0.002800414042165265,\n",
       "  0.002806168041742293,\n",
       "  0.002811128986775272,\n",
       "  0.002809754379778939,\n",
       "  0.0028093832510128636,\n",
       "  0.0028105533252461754,\n",
       "  0.002808122851759148,\n",
       "  0.002803613753315861,\n",
       "  0.002804646962982856,\n",
       "  0.0028068217879561384,\n",
       "  0.0028118784013714333,\n",
       "  0.0027974838155215465,\n",
       "  0.0027988047078974557,\n",
       "  0.00280294209648342,\n",
       "  0.0027949935725816786,\n",
       "  0.002798870006100558,\n",
       "  0.0027972337509788703,\n",
       "  0.002796410092420888,\n",
       "  0.0027966639201757494,\n",
       "  0.002792003160501149,\n",
       "  0.0027866176376860974,\n",
       "  0.0027831829065847542,\n",
       "  0.0027855302039540997,\n",
       "  0.0027933375849277004,\n",
       "  0.0027928136356455946,\n",
       "  0.002785050939534726,\n",
       "  0.0027837716501965893,\n",
       "  0.0027789343882443484,\n",
       "  0.002781758486708097,\n",
       "  0.002782797649356437,\n",
       "  0.00278121464540166,\n",
       "  0.0027743465209602194,\n",
       "  0.0027721445115140245,\n",
       "  0.0027731119506580666,\n",
       "  0.002773277656192868,\n",
       "  0.0027703494420273857,\n",
       "  0.002763241746473424,\n",
       "  0.0027644198919667324,\n",
       "  0.0027637173438373615,\n",
       "  0.0027595263537571776,\n",
       "  0.002765088076664635,\n",
       "  0.002765753650262332,\n",
       "  0.0027661725189424193,\n",
       "  0.0027650886949308257,\n",
       "  0.0027640412128642536,\n",
       "  0.0027639288383111177,\n",
       "  0.002757909433720065,\n",
       "  0.002761212629052651,\n",
       "  0.0027569302928765033,\n",
       "  0.002755491029994692,\n",
       "  0.002751286976621787,\n",
       "  0.0027538054909783264,\n",
       "  0.0027566833670653263,\n",
       "  0.002761348574204649,\n",
       "  0.0027596908137046193,\n",
       "  0.002748952654621632,\n",
       "  0.0027468047292338337,\n",
       "  0.0027354259372516644,\n",
       "  0.002738575785995824,\n",
       "  0.0027344168480560277,\n",
       "  0.0027351632846011587,\n",
       "  0.002731016253745896,\n",
       "  0.0027394427464132653,\n",
       "  0.002740794062178883,\n",
       "  0.0027315959410671702,\n",
       "  0.0027338176309527405,\n",
       "  0.002730126164298399,\n",
       "  0.0027266109035843315,\n",
       "  0.002728436774714428,\n",
       "  0.0027312882425154427,\n",
       "  0.002734331799922794,\n",
       "  0.00273452006554105,\n",
       "  0.002739893386130096,\n",
       "  0.0027421107588051453,\n",
       "  0.0027415312037597926,\n",
       "  0.0027394818237475808,\n",
       "  0.002739169197010104,\n",
       "  0.002729240076161813,\n",
       "  0.002730743444684415,\n",
       "  0.002730032545590412,\n",
       "  0.002730026754358055,\n",
       "  0.0027243740675319847,\n",
       "  0.0027213365961042315,\n",
       "  0.0027242219231404167,\n",
       "  0.0027235493746604828,\n",
       "  0.0027202914803724724,\n",
       "  0.0027194707259814072,\n",
       "  0.0027227656664267313,\n",
       "  0.002722647734060209,\n",
       "  0.0027265566823440938,\n",
       "  0.002723110043561527,\n",
       "  0.0027258261681720733,\n",
       "  0.0027299578175063086,\n",
       "  0.002725797949108698,\n",
       "  0.00272492001645473,\n",
       "  0.0027332678236593267,\n",
       "  0.002725114424331866,\n",
       "  0.002722671471715215,\n",
       "  0.002730503116202518,\n",
       "  0.0027266212556881064,\n",
       "  0.002720002882243982,\n",
       "  0.002718934947316657,\n",
       "  0.0027139420198122577,\n",
       "  0.002720688994391604,\n",
       "  0.002727111164476799,\n",
       "  0.0027294251756342877,\n",
       "  0.002729421629778497,\n",
       "  0.0027273404184908214,\n",
       "  0.0027316889677932556,\n",
       "  0.0027360286084399613,\n",
       "  0.0027323385299883453,\n",
       "  0.002732875790966294,\n",
       "  0.002735570798201152,\n",
       "  0.0027323972633539113,\n",
       "  0.0027353715613321903,\n",
       "  0.002734356852247942,\n",
       "  0.002734676400460513,\n",
       "  0.0027348198168786757,\n",
       "  0.002733002693035969,\n",
       "  0.0027335376583339285,\n",
       "  0.002734986986646838,\n",
       "  0.002733620373663181,\n",
       "  0.002738110276438271,\n",
       "  0.002740593959315934,\n",
       "  0.0027376923268802736,\n",
       "  0.002741480267398636,\n",
       "  0.0027444603530321944,\n",
       "  0.002749694158525515,\n",
       "  0.0027445067235443536,\n",
       "  0.0027453784384520244,\n",
       "  0.002744133361778105,\n",
       "  0.00273754815594519,\n",
       "  0.002736494831419673,\n",
       "  0.0027388305178349392,\n",
       "  0.0027396201569995617,\n",
       "  0.002734634755202582,\n",
       "  0.0027323116058434616,\n",
       "  0.0027284661364321166,\n",
       "  0.002726278527669385,\n",
       "  0.002718893820560541,\n",
       "  0.0027207310123138675,\n",
       "  0.002718374922315481,\n",
       "  0.002711619637655539,\n",
       "  0.002705899618364023,\n",
       "  0.0027058366908813904,\n",
       "  0.0027080249954593203,\n",
       "  0.0027038931600209927,\n",
       "  0.002701551873878046,\n",
       "  0.002698092316392831,\n",
       "  0.002699766659080898,\n",
       "  0.002695764509965966,\n",
       "  0.002694771471645771,\n",
       "  0.00269475113893611,\n",
       "  0.0026947466541007983,\n",
       "  0.0026965009975547585,\n",
       "  0.00269700357522301,\n",
       "  0.0027038143559223794,\n",
       "  0.0026980412283613034,\n",
       "  0.0027030489688094116,\n",
       "  0.002703472754082369,\n",
       "  0.0027058179540615647,\n",
       "  0.002706532171999645,\n",
       "  0.0027059525411768236,\n",
       "  0.0027068152199669856,\n",
       "  0.002703761158152305,\n",
       "  0.002699287022854906,\n",
       "  0.00269969444730501,\n",
       "  0.0026984708206470444,\n",
       "  0.0026949644348174726,\n",
       "  0.0026963728730437808,\n",
       "  0.0026998977415962065,\n",
       "  0.00270217083310609,\n",
       "  0.00269394342780062,\n",
       "  0.0026968574840817226,\n",
       "  0.0026882732013286665,\n",
       "  0.0026869915458975747,\n",
       "  0.0026858427089162915,\n",
       "  0.0026896648418057827,\n",
       "  0.0026864452881101035,\n",
       "  0.002690909032023045,\n",
       "  0.002695652919626754,\n",
       "  0.002697483644186414,\n",
       "  0.002686330837941838,\n",
       "  0.002688277359568702,\n",
       "  0.0026832769158001853,\n",
       "  0.00269062534932332,\n",
       "  0.00269281139863177,\n",
       "  0.002695689742711731,\n",
       "  0.0026966701169990597,\n",
       "  0.0026940278269055526,\n",
       "  0.002689604872327966,\n",
       "  0.0026895920709528744,\n",
       "  0.002697871044802675,\n",
       "  0.0027000131229989234,\n",
       "  0.002698746347517335,\n",
       "  0.002698859413108486,\n",
       "  0.0026985112366167325,\n",
       "  0.002692009804054855,\n",
       "  0.002690612752329107,\n",
       "  0.002686181491525185,\n",
       "  0.0026878677713280995,\n",
       "  0.002685065051422344,\n",
       "  0.002678912389147743,\n",
       "  0.0026796431506432208,\n",
       "  0.0026829404981628642,\n",
       "  0.002685440418090793,\n",
       "  0.0026871829033769017,\n",
       "  0.0026892747363668123,\n",
       "  0.002693303419005183,\n",
       "  0.002691965025315784,\n",
       "  0.0026928190546106905,\n",
       "  0.0026902283865044368,\n",
       "  0.0026855929620034787,\n",
       "  0.0026790477990446876,\n",
       "  0.00268182062309231,\n",
       "  0.0026817137594062246,\n",
       "  0.002679246492754957,\n",
       "  0.002674015207898897,\n",
       "  0.0026716937181162593,\n",
       "  0.0026658402982339376,\n",
       "  0.0026648383334427193,\n",
       "  0.002666590590150211,\n",
       "  0.002669115556687369,\n",
       "  0.002671390859091101,\n",
       "  0.002667326606737345,\n",
       "  0.00266771185347882,\n",
       "  0.0026627452739726816,\n",
       "  0.002664984720233224,\n",
       "  0.0026704199842635533,\n",
       "  0.0026700063742718366,\n",
       "  0.002675702726341531,\n",
       "  0.002673612904595121,\n",
       "  0.002680812963283862,\n",
       "  0.002683936084678033,\n",
       "  0.0026777807883816038,\n",
       "  0.0026788866399847797,\n",
       "  0.002680290135396771,\n",
       "  0.0026808901907105077,\n",
       "  0.002690400752433329,\n",
       "  0.0026908509386910067,\n",
       "  0.0026872545884529023,\n",
       "  0.002685801734934383,\n",
       "  0.0026911886658582706,\n",
       "  0.0026881116767475143,\n",
       "  0.002681638244843135,\n",
       "  0.0026721161654600705,\n",
       "  0.002673940540937477,\n",
       "  0.0026719173987260784,\n",
       "  0.002672469462398415,\n",
       "  0.002671451018896593,\n",
       "  0.0026741560852380384,\n",
       "  0.002672788704727082,\n",
       "  0.0026723678094838,\n",
       "  0.002667387311438901,\n",
       "  0.00266430717030183,\n",
       "  0.002654169928399484,\n",
       "  0.002645936793846648,\n",
       "  0.0026472526339022854,\n",
       "  0.002649670837310188,\n",
       "  0.002654998136396463,\n",
       "  0.0026549801013397703,\n",
       "  0.002647393886166946,\n",
       "  0.0026471520679388367,\n",
       "  0.0026442108031740864,\n",
       "  0.002644726041179385,\n",
       "  0.0026520728727751795,\n",
       "  0.0026555370166677834,\n",
       "  0.002655153946317169,\n",
       "  0.0026459076386846653,\n",
       "  0.0026452688801934707,\n",
       "  0.002650072263825216,\n",
       "  0.002648443409901991,\n",
       "  0.0026554469605250164,\n",
       "  0.002657400543800453,\n",
       "  0.0026547045656004514,\n",
       "  0.002652606831204054,\n",
       "  0.002654433132208717,\n",
       "  0.0026496016389703464,\n",
       "  0.002645974732463981,\n",
       "  0.002648578827808513,\n",
       "  0.002649573660631221,\n",
       "  0.002649854628462265,\n",
       "  0.0026489813901039334,\n",
       "  0.00264514732595478,\n",
       "  0.0026455632190034873,\n",
       "  ...]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(data=df_feats, label=df_TARGET)\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "          'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 10 ,\n",
    "          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n",
    "          'min_split_gain':.01, 'min_child_weight':1}\n",
    "lgb_result=lgb.cv(params, lgb_train, stratified=True, metrics={'auc'}, num_boost_round=5000,\n",
    "                      nfold=5, early_stopping_rounds=150, verbose_eval=20)\n",
    "lgb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2849"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-e989b700b78a>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-e989b700b78a>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    'min_child_weigh':range(20,100,20)\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#grid search\n",
    "lgb_param_test1 = {\n",
    "    'max_depth':[8], #range(2,10,2),\n",
    "    'num_leaves':[30], #range(30,60,10),\n",
    "    'min_child_samples':range(200,1000,300),\n",
    "    'min_child_weight':range(20,100,20)\n",
    "    \n",
    "}\n",
    "lgb_gsearch1 = GridSearchCV(estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=48, max_depth=7,\n",
    "    learning_rate=0.01, n_estimators=len(lgb_result['auc-mean']),  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.1, random_state=1001, n_jobs=-1, silent=False\n",
    "), param_grid = lgb_param_test1, scoring='roc_auc',n_jobs=4,verbose=10,iid=False, cv=5)\n",
    "\n",
    "\n",
    "lgb_gsearch1.fit(df_feats, df_TARGET, eval_metric='auc', verbose = 50)\n",
    "lgb_gsearch1.grid_scores_, lgb_gsearch1.best_params_, lgb_gsearch1.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, train, train_target, useTrainCV=True, cv_folds=5, early_stopping_rounds=150, val_percent=0.2):\n",
    "    \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size= val_percent, random_state=1001)\n",
    "    for train_index, test_index in split.split(train, train_target):\n",
    "        dtrain, dtest = train.loc[train_index], train.loc[test_index]\n",
    "        dtrain_target, dtest_target = train_target.loc[train_index], train_target.loc[test_index]\n",
    "            \n",
    "            \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain.values, label=dtrain_target.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics={'auc'}, early_stopping_rounds=early_stopping_rounds)\n",
    "        print(\"n_estimators use : %d\" % cvresult.shape[0])\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, dtrain_target,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\ndtrain Model Report\")\n",
    "    print(\"dtrain Accuracy : %.4g\" % metrics.accuracy_score(dtrain_target, dtrain_predictions))\n",
    "    print(\"dtrain AUC Score: %f\" % metrics.roc_auc_score(dtrain_target, dtrain_predprob)) \n",
    "    \n",
    "    #     Predict on validation data:\n",
    "    dtest_predictions = alg.predict(dtest)\n",
    "    dtest_predprob = alg.predict_proba(dtest)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\ndtest Model Report\")\n",
    "    print(\"dtest Accuracy : %.4g\" % metrics.accuracy_score(dtest_target, dtest_predictions))\n",
    "    print(\"dtest AUC Score: %f\" % metrics.roc_auc_score(dtest_target, dtest_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        silent=False,    \n",
    "        seed=1001)\n",
    "modelfit(xgb1, df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, \n",
    "                                                  n_estimators=xgb1.get_params()['n_estimators'], \n",
    "                                        max_depth=5,\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, \n",
    "                                                         random_state=1001, silent=False,  seed=1001, verbose=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',n_jobs=4,verbose=10,iid=False, cv=5)\n",
    "gsearch1.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=xgb1.get_params()['n_estimators'],\n",
    "                                                  max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "                                                  gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,\n",
    "                                                  random_state=27, silent=False, seed=27), \n",
    "                       param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False,verbose=10, cv=5)\n",
    "gsearch3.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=1000, \n",
    "                                                  max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "                                                  gamma=gsearch3.best_params_['gamma'], \n",
    "                                        subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=2, verbose=10,silent=False,\n",
    "                                                  scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, verbose=10,cv=5)\n",
    "gsearch4.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=232,\n",
    "                                                  max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "                                                  gamma=gsearch3.best_params_['gamma'],  \n",
    "                                                  subsample=gsearch4.best_params_[\"subsample\"], \n",
    "                                        colsample_bytree=gsearch4.best_params_[\"colsample_bytree\"],\n",
    "                                                  silent=False,\n",
    "                                        objective= 'binary:logistic', nthread=2, verbose=10,\n",
    "                                                  scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth==gsearch1.best_params_['max_depth'],\n",
    "        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "        gamma=gsearch3.best_params_['gamma'], \n",
    "        subsample=gsearch4.best_params_[\"subsample\"],\n",
    "        colsample_bytree=gsearch4.best_params_[\"colsample_bytree\"],\n",
    "        reg_alpha=gsearch6.best_params_[\"reg_alpha\"],\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        scale_pos_weight=1,\n",
    "        silent=False,\n",
    "        seed=27)\n",
    "modelfit(xgb3, df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=5000,\n",
    "        max_depth=gsearch1.best_params_['max_depth'],\n",
    "        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "        gamma=gsearch3.best_params_['gamma'],\n",
    "        subsample=gsearch4.best_params_[\"subsample\"],\n",
    "        colsample_bytree=gsearch4.best_params_[\"colsample_bytree\"],\n",
    "        reg_alpha=gsearch6.best_params_[\"reg_alpha\"],\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        silent=False,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "modelfit(xgb4, df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "X_val_imp_feats = X_val_imp[feats]\n",
    "X_val_feats = X_val[feats]\n",
    "\n",
    "grid_seclvl_train_all = np.concatenate(( np.array([log_clf.predict_proba(X_val_imp_feats)[:,1]]).T,\n",
    "                                np.array([rnd_clf.predict_proba(X_val_imp_feats)[:,1]]).T,\n",
    "                                np.array([xgb_clf.predict_proba(X_val_feats)[:,1]]).T,\n",
    "                                np.array([lgb_clf.predict_proba(X_val_feats)[:,1]]).T\n",
    "                            ), axis=1)\n",
    "\n",
    "grid_level2_df = pd.concat([X_val['TARGET'].reset_index(),pd.DataFrame(grid_seclvl_train_all)], axis=1)\n",
    "\n",
    "feats_level2 = [f for f in grid_level2_df.columns if f not in g_ignore_features]\n",
    "level2_df_feats = grid_level2_df[feats_level2]\n",
    "level2_df_TARGET = grid_level2_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097511</td>\n",
       "      <td>0.075185</td>\n",
       "      <td>0.119020</td>\n",
       "      <td>0.115630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044863</td>\n",
       "      <td>0.077860</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.050541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032726</td>\n",
       "      <td>0.059147</td>\n",
       "      <td>0.073451</td>\n",
       "      <td>0.044999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022680</td>\n",
       "      <td>0.054122</td>\n",
       "      <td>0.019203</td>\n",
       "      <td>0.010699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.362191</td>\n",
       "      <td>0.182466</td>\n",
       "      <td>0.503716</td>\n",
       "      <td>0.562541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.097511  0.075185  0.119020  0.115630\n",
       "1  0.044863  0.077860  0.037171  0.050541\n",
       "2  0.032726  0.059147  0.073451  0.044999\n",
       "3  0.022680  0.054122  0.019203  0.010699\n",
       "4  0.362191  0.182466  0.503716  0.562541"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2_df_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=8)]: Done  52 out of  60 | elapsed:   20.5s remaining:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done  60 out of  60 | elapsed:   20.9s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.50000, std: 0.00000, params: {'C': 0.001, 'penalty': 'l1'},\n",
       "  mean: 0.78756, std: 0.00168, params: {'C': 0.001, 'penalty': 'l2'},\n",
       "  mean: 0.78754, std: 0.00159, params: {'C': 0.01, 'penalty': 'l1'},\n",
       "  mean: 0.78755, std: 0.00178, params: {'C': 0.01, 'penalty': 'l2'},\n",
       "  mean: 0.78660, std: 0.00214, params: {'C': 0.1, 'penalty': 'l1'},\n",
       "  mean: 0.78719, std: 0.00194, params: {'C': 0.1, 'penalty': 'l2'},\n",
       "  mean: 0.78462, std: 0.00259, params: {'C': 1, 'penalty': 'l1'},\n",
       "  mean: 0.78553, std: 0.00237, params: {'C': 1, 'penalty': 'l2'},\n",
       "  mean: 0.78448, std: 0.00262, params: {'C': 2, 'penalty': 'l1'},\n",
       "  mean: 0.78504, std: 0.00248, params: {'C': 2, 'penalty': 'l2'},\n",
       "  mean: 0.78438, std: 0.00263, params: {'C': 10, 'penalty': 'l1'},\n",
       "  mean: 0.78450, std: 0.00261, params: {'C': 10, 'penalty': 'l2'}],\n",
       " {'C': 0.001, 'penalty': 'l2'},\n",
       " 0.7875643917280424)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_param_grid_level2 = {'penalty':['l1','l2'],'C': [0.001, 0.01, 0.1, 1, 2, 10] }\n",
    "log_grid_search_level2 = grid_search(LogisticRegression(), log_param_grid_level2,\n",
    "                                     level2_df_feats, level2_df_TARGET)\n",
    "\n",
    "log_grid_search_level2.grid_scores_, log_grid_search_level2.best_params_, log_grid_search_level2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_param_grid_level2 = {'penalty':['l1','l2'],'C': [0.001, 0.01, 0.1, 1, 2, 10] }\n",
    "log_grid_search_level2 = grid_search(LogisticRegression(), log_param_grid_level2,\n",
    "                                     level2_df_feats, level2_df_TARGET)\n",
    "\n",
    "log_grid_search_level2.grid_scores_, log_grid_search_level2.best_params_, log_grid_search_level2.best_score_\n",
    "([mean: 0.50000, std: 0.00000, params: {'C': 0.001, 'penalty': 'l1'},\n",
    "  mean: 0.78756, std: 0.00168, params: {'C': 0.001, 'penalty': 'l2'},\n",
    "  mean: 0.78754, std: 0.00159, params: {'C': 0.01, 'penalty': 'l1'},\n",
    "  mean: 0.78755, std: 0.00178, params: {'C': 0.01, 'penalty': 'l2'},\n",
    "  mean: 0.78660, std: 0.00214, params: {'C': 0.1, 'penalty': 'l1'},\n",
    "  mean: 0.78719, std: 0.00194, params: {'C': 0.1, 'penalty': 'l2'},\n",
    "  mean: 0.78462, std: 0.00259, params: {'C': 1, 'penalty': 'l1'},\n",
    "  mean: 0.78553, std: 0.00237, params: {'C': 1, 'penalty': 'l2'},\n",
    "  mean: 0.78448, std: 0.00262, params: {'C': 2, 'penalty': 'l1'},\n",
    "  mean: 0.78504, std: 0.00248, params: {'C': 2, 'penalty': 'l2'},\n",
    "  mean: 0.78438, std: 0.00263, params: {'C': 10, 'penalty': 'l1'},\n",
    "  mean: 0.78450, std: 0.00261, params: {'C': 10, 'penalty': 'l2'}],\n",
    " {'C': 0.001, 'penalty': 'l2'},\n",
    " 0.7875643917280424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed: 48.2min\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=8)]: Done 997 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=8)]: Done 1042 tasks      | elapsed: 57.8min\n",
      "[Parallel(n_jobs=8)]: Done 1089 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed: 65.2min\n",
      "[Parallel(n_jobs=8)]: Done 1185 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed: 73.2min\n",
      "[Parallel(n_jobs=8)]: Done 1285 tasks      | elapsed: 77.5min\n",
      "[Parallel(n_jobs=8)]: Done 1336 tasks      | elapsed: 81.5min\n",
      "[Parallel(n_jobs=8)]: Done 1389 tasks      | elapsed: 85.8min\n",
      "[Parallel(n_jobs=8)]: Done 1440 out of 1440 | elapsed: 90.2min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78689, std: 0.00126, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78645, std: 0.00140, params: {'max_depth': 2, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78691, std: 0.00133, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78647, std: 0.00143, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78682, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78641, std: 0.00178, params: {'max_depth': 2, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78585, std: 0.00169, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78440, std: 0.00220, params: {'max_depth': 4, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78582, std: 0.00165, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00217, params: {'max_depth': 4, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78598, std: 0.00192, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78478, std: 0.00209, params: {'max_depth': 4, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78414, std: 0.00178, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78369, std: 0.00173, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78369, std: 0.00181, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78130, std: 0.00248, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78110, std: 0.00247, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78095, std: 0.00231, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78414, std: 0.00178, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78369, std: 0.00173, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78369, std: 0.00181, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78130, std: 0.00248, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78110, std: 0.00247, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78095, std: 0.00231, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78414, std: 0.00178, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78369, std: 0.00173, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78369, std: 0.00181, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78130, std: 0.00248, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78110, std: 0.00247, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78095, std: 0.00231, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78414, std: 0.00178, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78369, std: 0.00173, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78369, std: 0.00181, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78130, std: 0.00248, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78110, std: 0.00247, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78095, std: 0.00231, params: {'max_depth': 6, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78452, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78415, std: 0.00186, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78404, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78258, std: 0.00237, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78223, std: 0.00203, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78219, std: 0.00234, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78452, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78415, std: 0.00186, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78404, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78258, std: 0.00237, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78223, std: 0.00203, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78219, std: 0.00234, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78452, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78415, std: 0.00186, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78404, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78258, std: 0.00237, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78223, std: 0.00203, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78219, std: 0.00234, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78452, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78415, std: 0.00186, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78404, std: 0.00197, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78258, std: 0.00237, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78223, std: 0.00203, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78219, std: 0.00234, params: {'max_depth': 6, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78442, std: 0.00184, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78416, std: 0.00183, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78416, std: 0.00179, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78295, std: 0.00215, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78272, std: 0.00191, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78284, std: 0.00204, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78442, std: 0.00184, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78416, std: 0.00183, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78416, std: 0.00179, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78295, std: 0.00215, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78272, std: 0.00191, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78284, std: 0.00204, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78442, std: 0.00184, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78416, std: 0.00183, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78416, std: 0.00179, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78295, std: 0.00215, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78272, std: 0.00191, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78284, std: 0.00204, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78442, std: 0.00184, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78416, std: 0.00183, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78416, std: 0.00179, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78295, std: 0.00215, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78272, std: 0.00191, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78284, std: 0.00204, params: {'max_depth': 6, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78370, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78305, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78232, std: 0.00219, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78023, std: 0.00255, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.77939, std: 0.00249, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.77852, std: 0.00256, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78370, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78305, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78232, std: 0.00219, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78023, std: 0.00255, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.77939, std: 0.00249, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.77852, std: 0.00256, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78370, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78305, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78232, std: 0.00219, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78023, std: 0.00255, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.77939, std: 0.00249, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.77852, std: 0.00256, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78370, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78305, std: 0.00186, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78232, std: 0.00219, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78023, std: 0.00255, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.77939, std: 0.00249, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.77852, std: 0.00256, params: {'max_depth': 8, 'min_child_samples': 200, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78410, std: 0.00187, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78352, std: 0.00207, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78311, std: 0.00183, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78176, std: 0.00211, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78115, std: 0.00233, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78072, std: 0.00206, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78410, std: 0.00187, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78352, std: 0.00207, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78311, std: 0.00183, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78176, std: 0.00211, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78115, std: 0.00233, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78072, std: 0.00206, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78410, std: 0.00187, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78352, std: 0.00207, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78311, std: 0.00183, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78176, std: 0.00211, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78115, std: 0.00233, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78072, std: 0.00206, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78410, std: 0.00187, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78352, std: 0.00207, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78311, std: 0.00183, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78176, std: 0.00211, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78115, std: 0.00233, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78072, std: 0.00206, params: {'max_depth': 8, 'min_child_samples': 500, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78381, std: 0.00172, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78334, std: 0.00189, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78299, std: 0.00191, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78223, std: 0.00181, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78174, std: 0.00192, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78135, std: 0.00203, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 20, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78381, std: 0.00172, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78334, std: 0.00189, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78299, std: 0.00191, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78223, std: 0.00181, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78174, std: 0.00192, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78135, std: 0.00203, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 40, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78381, std: 0.00172, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78334, std: 0.00189, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78299, std: 0.00191, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78223, std: 0.00181, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78174, std: 0.00192, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78135, std: 0.00203, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 60, 'n_estimators': 2000, 'num_leaves': 50},\n",
       "  mean: 0.78381, std: 0.00172, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 30},\n",
       "  mean: 0.78334, std: 0.00189, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 40},\n",
       "  mean: 0.78299, std: 0.00191, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 1000, 'num_leaves': 50},\n",
       "  mean: 0.78223, std: 0.00181, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 30},\n",
       "  mean: 0.78174, std: 0.00192, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 40},\n",
       "  mean: 0.78135, std: 0.00203, params: {'max_depth': 8, 'min_child_samples': 800, 'min_child_weigh': 80, 'n_estimators': 2000, 'num_leaves': 50}],\n",
       " {'max_depth': 2,\n",
       "  'min_child_samples': 500,\n",
       "  'min_child_weigh': 20,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 30},\n",
       " 0.7869055229150952)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search\n",
    "lgb_param_level2 = {\n",
    "    'n_estimators': range (1000,3000, 1000),\n",
    "    'max_depth':range(2,10,2),\n",
    "    'num_leaves':range(30,60,10),\n",
    "    'min_child_samples':range(200,1000,300),\n",
    "    'min_child_weigh':range(20,100,20)\n",
    "}\n",
    "\n",
    "lgb_gsearch1_level2 = grid_search(lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=48, max_depth=7,\n",
    "    learning_rate=0.01, n_estimators=2000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.1, random_state=27, n_jobs=-1, silent=False), \n",
    "    lgb_param_level2, level2_df_feats, level2_df_TARGET)\n",
    "lgb_gsearch1_level2.grid_scores_, lgb_gsearch1_level2.best_params_, lgb_gsearch1_level2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=8)]: Done 997 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=8)]: Done 1042 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 1089 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 1185 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=8)]: Done 1285 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=8)]: Done 1336 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 1389 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=8)]: Done 1442 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=8)]: Done 1500 out of 1500 | elapsed: 38.2min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78669, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78669, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78673, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78669, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78669, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78673, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78669, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78669, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78673, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 20, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78669, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78672, std: 0.00148, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78672, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78674, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00148, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78669, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78672, std: 0.00148, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78672, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78674, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00148, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78669, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78672, std: 0.00148, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78670, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78672, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78674, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00148, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00149, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78671, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78670, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00150, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 40, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78669, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78667, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78666, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78668, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78669, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78666, std: 0.00157, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78669, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78667, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78666, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78668, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78669, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78666, std: 0.00157, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78669, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78667, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78666, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00156, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78670, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78668, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78669, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78669, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78668, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78667, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78667, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78666, std: 0.00157, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 60, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78674, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78672, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78674, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78675, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78674, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78672, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78674, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78672, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78674, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78675, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78674, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78672, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 20, 'reg_alpha': 0.4, 'reg_lambda': 0.4},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.0},\n",
       "  mean: 0.78674, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.2},\n",
       "  mean: 0.78672, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.3},\n",
       "  mean: 0.78674, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.0, 'reg_lambda': 0.4},\n",
       "  mean: 0.78674, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.0},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.1},\n",
       "  mean: 0.78675, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.4},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.0},\n",
       "  mean: 0.78674, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.1},\n",
       "  mean: 0.78672, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.2},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.2, 'reg_lambda': 0.4},\n",
       "  mean: 0.78671, std: 0.00155, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.0},\n",
       "  mean: 0.78672, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.2},\n",
       "  mean: 0.78671, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.3},\n",
       "  mean: 0.78673, std: 0.00151, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.3, 'reg_lambda': 0.4},\n",
       "  mean: 0.78675, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.0},\n",
       "  mean: 0.78673, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.1},\n",
       "  mean: 0.78673, std: 0.00152, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.2},\n",
       "  mean: 0.78673, std: 0.00154, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.3},\n",
       "  mean: 0.78671, std: 0.00153, params: {'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 30, 'reg_alpha': 0.4, 'reg_lambda': 0.4}],\n",
       " {'max_depth': 2,\n",
       "  'min_child_samples': 500,\n",
       "  'min_child_weight': 80,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 10,\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.2},\n",
       " 0.7867516578992596)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search\n",
    "lgb_param_level2 = {\n",
    "    'n_estimators': [1000], #range (1000,3000, 1000),\n",
    "    'max_depth': [2], #range(2,10,2),\n",
    "    'num_leaves': [10, 20, 30], #range(30,60,10),\n",
    "    'min_child_samples': 500, # range(200,1000,300),\n",
    "    'min_child_weight':range(20,100,20),\n",
    "    'reg_alpha': [i/10.0 for i in range(0,5),\n",
    "    'reg_lambda': [i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "lgb_gsearch1_level2 = grid_search(lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=48, max_depth=7,\n",
    "    learning_rate=0.01, n_estimators=2000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.1, random_state=27, n_jobs=-1, silent=False), \n",
    "    lgb_param_level2, level2_df_feats, level2_df_TARGET)\n",
    "lgb_gsearch1_level2.grid_scores_, lgb_gsearch1_level2.best_params_, lgb_gsearch1_level2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed:  5.6min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.8, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78680, std: 0.00156, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78675, std: 0.00152, params: {'colsample_bytree': 0.9, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78681, std: 0.00155, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78681, std: 0.00155, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78681, std: 0.00155, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78681, std: 0.00155, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 2, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 8, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.6},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.8},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 0.85},\n",
       "  mean: 0.78672, std: 0.00148, params: {'colsample_bytree': 1.0, 'max_depth': 2, 'min_child_samples': 500, 'min_child_weight': 80, 'n_estimators': 1000, 'num_leaves': 10, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1.0}],\n",
       " {'colsample_bytree': 1.0,\n",
       "  'max_depth': 2,\n",
       "  'min_child_samples': 500,\n",
       "  'min_child_weight': 80,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 2,\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.2,\n",
       "  'subsample': 0.6},\n",
       " 0.7868105299054646)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search\n",
    "lgb_param_level2 = {\n",
    "    'n_estimators': [1000], #range (1000,3000, 1000),\n",
    "    'max_depth': [2], #range(2,10,2),\n",
    "    'num_leaves': [2,5,8,10], #[10, 20, 30], #range(30,60,10),\n",
    "    'min_child_samples': [500], # range(200,1000,300),\n",
    "    'min_child_weight': [80], #range(20,100,20),\n",
    "    'reg_alpha':[0.1], #[i/10.0 for i in range(0,5)],\n",
    "    'reg_lambda': [0.2], #[i/10.0 for i in range(0,5)],\n",
    "    'subsample': [0.6, 0.8, 0.85, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "lgb_gsearch1_level2 = grid_search(lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=48, max_depth=7,\n",
    "    learning_rate=0.01, n_estimators=2000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.2, random_state=27, n_jobs=-1, silent=False), \n",
    "    lgb_param_level2, level2_df_feats, level2_df_TARGET)\n",
    "lgb_gsearch1_level2.grid_scores_, lgb_gsearch1_level2.best_params_, lgb_gsearch1_level2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#selected parameter\n",
    "#CV - 0.7868105299054646\n",
    "\n",
    "lgb_gsearch1_level2 = grid_search(lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=48, max_depth=7,\n",
    "    learning_rate=0.01, n_estimators=2000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.2, random_state=27, n_jobs=-1, silent=False), \n",
    "    lgb_param_level2, level2_df_feats, level2_df_TARGET)\n",
    "\n",
    "gb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=2, max_depth=2,\n",
    "    learning_rate=0.01, n_estimators=1000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=80, \n",
    "    min_child_samples=500, subsample=0.6, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.2, random_state=27, n_jobs=-1, silent=False)\n",
    "    \n",
    " {'colsample_bytree': 1.0,\n",
    "  'max_depth': 2,\n",
    "  'min_child_samples': 500,\n",
    "  'min_child_weight': 80,\n",
    "  'n_estimators': 1000,\n",
    "  'num_leaves': 2,\n",
    "  'reg_alpha': 0.1,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 0.6},\n",
    " 0.7868105299054646)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_level2 = {\n",
    "    'n_estimators':1000, # range (1000, 10000, 2000),\n",
    "    'max_depth':[2, 3], #range(3,10,2),\n",
    "    'min_child_weight':3, #range(1,6,2),\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)]\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]    \n",
    "}\n",
    "\n",
    "xgb_gsearch_level2 = grid_search(XGBClassifier(learning_rate =0.1, n_estimators=1000,\n",
    "                                                  max_depth=6,\n",
    "                                        min_child_weight=1,\n",
    "                                                  gamma=0, subsample=0.8, colsample_bytree=1,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,\n",
    "                                                  random_state=27, silent=False, seed=27), \n",
    "    xgb_param_level2, level2_df_feats, level2_df_TARGET)\n",
    "xgb_gsearch_level2.grid_scores_, xgb_gsearch_level2.best_params_, xgb_gsearch_level2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb_param_level2 = {\n",
    "    'n_estimators': range (1000, 10000, 2000),\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2),\n",
    "    #'gamma':[i/10.0 for i in range(0,5)],\n",
    "    #'subsample':[i/10.0 for i in range(6,10)],\n",
    "    #'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "    #'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]    \n",
    "}\n",
    "\n",
    "xgb_gsearch_level2 = grid_search(XGBClassifier(learning_rate =0.1, n_estimators=1000,\n",
    "                                                  max_depth=6,\n",
    "                                        min_child_weight=1,\n",
    "                                                  gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,\n",
    "                                                  random_state=27, silent=False, seed=27), \n",
    "    xgb_param_level2, level2_df_feats, level2_df_TARGET)\n",
    "xgb_gsearch_level2.grid_scores_, xgb_gsearch_level2.best_params_, xgb_gsearch_level2.best_score_\n",
    "\n",
    "#result output\n",
    "([mean: 0.77955, std: 0.00186, params: {'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 1000},\n",
    "  mean: 0.76449, std: 0.00424, params: {'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 3000},\n",
    "  mean: 0.75526, std: 0.00490, params: {'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 5000},\n",
    "  mean: 0.74743, std: 0.00631, params: {'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 7000},\n",
    "  mean: 0.74146, std: 0.00688, params: {'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 9000},\n",
    "  mean: 0.77977, std: 0.00152, params: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 1000},\n",
    "  mean: 0.76607, std: 0.00297, params: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 3000},\n",
    "  mean: 0.75533, std: 0.00463, params: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 5000},\n",
    "  mean: 0.74719, std: 0.00569, params: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 7000},\n",
    "  mean: 0.74193, std: 0.00617, params: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 9000},\n",
    "  mean: 0.77959, std: 0.00148, params: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 1000},\n",
    "  mean: 0.76560, std: 0.00330, params: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 3000},\n",
    "  mean: 0.75571, std: 0.00444, params: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 5000},\n",
    "  mean: 0.74800, std: 0.00550, params: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 7000},\n",
    "  mean: 0.74263, std: 0.00587, params: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 9000},\n",
    "  mean: 0.76887, std: 0.00314, params: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 1000},\n",
    "  mean: 0.74589, std: 0.00566, params: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 3000},\n",
    "  mean: 0.73536, std: 0.00731, params: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 5000},\n",
    "  mean: 0.72754, std: 0.00788, params: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 7000},\n",
    "  mean: 0.72150, std: 0.00810, params: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 9000},\n",
    "  mean: 0.76788, std: 0.00376, params: {'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 1000},\n",
    "  mean: 0.74411, std: 0.00583, params: {'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 3000},\n",
    "  mean: 0.73179, std: 0.00684, params: {'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 5000},\n",
    "  mean: 0.72395, std: 0.00695, params: {'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 7000},\n",
    "  mean: 0.71811, std: 0.00713, params: {'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 9000},\n",
    "  mean: 0.76738, std: 0.00285, params: {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 1000},\n",
    "  mean: 0.74422, std: 0.00521, params: {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 3000},\n",
    "  mean: 0.73283, std: 0.00634, params: {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 5000},\n",
    "  mean: 0.72481, std: 0.00689, params: {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 7000},\n",
    "  mean: 0.71887, std: 0.00680, params: {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 9000},\n",
    "  mean: 0.75709, std: 0.00508, params: {'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 1000},\n",
    "  mean: 0.73335, std: 0.00650, params: {'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 3000},\n",
    "  mean: 0.72100, std: 0.00742, params: {'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 5000},\n",
    "  mean: 0.71306, std: 0.00798, params: {'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 7000},\n",
    "  mean: 0.70680, std: 0.00805, params: {'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 9000},\n",
    "  mean: 0.75488, std: 0.00498, params: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 1000},\n",
    "  mean: 0.72896, std: 0.00596, params: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 3000},\n",
    "  mean: 0.71684, std: 0.00643, params: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 5000},\n",
    "  mean: 0.70897, std: 0.00723, params: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 7000},\n",
    "  mean: 0.70363, std: 0.00728, params: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 9000},\n",
    "  mean: 0.75537, std: 0.00477, params: {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 1000},\n",
    "  mean: 0.72882, std: 0.00649, params: {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 3000},\n",
    "  mean: 0.71708, std: 0.00695, params: {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 5000},\n",
    "  mean: 0.70945, std: 0.00769, params: {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 7000},\n",
    "  mean: 0.70383, std: 0.00813, params: {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 9000},\n",
    "  mean: 0.74826, std: 0.00543, params: {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 1000},\n",
    "  mean: 0.72195, std: 0.00650, params: {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 3000},\n",
    "  mean: 0.70971, std: 0.00715, params: {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 5000},\n",
    "  mean: 0.70295, std: 0.00768, params: {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 7000},\n",
    "  mean: 0.69831, std: 0.00789, params: {'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 9000},\n",
    "  mean: 0.74505, std: 0.00501, params: {'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 1000},\n",
    "  mean: 0.71821, std: 0.00645, params: {'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 3000},\n",
    "  mean: 0.70638, std: 0.00715, params: {'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 5000},\n",
    "  mean: 0.70005, std: 0.00767, params: {'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 7000},\n",
    "  mean: 0.69577, std: 0.00786, params: {'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 9000},\n",
    "  mean: 0.74644, std: 0.00673, params: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 1000},\n",
    "  mean: 0.71899, std: 0.00710, params: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 3000},\n",
    "  mean: 0.70694, std: 0.00756, params: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 5000},\n",
    "  mean: 0.70030, std: 0.00798, params: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 7000},\n",
    "  mean: 0.69562, std: 0.00852, params: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 9000}],\n",
    " {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 1000},\n",
    " 0.7797689162770496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_path=\"C:/Users/wangh/Kaggle/model_pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = joblib.load(os.path.join(model_pkl_path, \"LGBMClassifier_finalmodel_lvl1.pkl\"))\n",
    "xgb_clf = joblib.load(os.path.join(model_pkl_path, \"XGBClassifier_finalmodel_lvl1.pkl\"))\n",
    "log_clf = joblib.load(os.path.join(model_pkl_path, \"LogisticRegression_finalmodel_lvl1.pkl\"))\n",
    "rnd_clf = joblib.load(os.path.join(model_pkl_path, \"RandomForestClassifier_finalmodel_lvl1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
