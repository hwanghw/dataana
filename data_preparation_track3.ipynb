{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "from datetime import date\n",
    "import random \n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ignore_features=['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV', 'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kaggle_csv(filepath, num_rows, root=\"D:/wangh/Kaggle/HomeCredit/Data\"):\n",
    "    csv_path = os.path.join(root, filepath)\n",
    "    \n",
    "    if not os.path.isfile(csv_path) :\n",
    "            csv_path = os.path.join(\"E:/SparkExerciseData/Kaggle\", filepath)\n",
    "        \n",
    "    return pd.read_csv(csv_path, nrows = num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = True):\n",
    "    # Read data and merge\n",
    "    df = load_kaggle_csv('application_train.csv', num_rows)\n",
    "    test_df = load_kaggle_csv('application_test.csv', num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    \n",
    "    # Categorical features: Binary features and One-Hot encoding\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    #AMT_INCOME_TOTAL 117000000 -> nan\n",
    "    df['AMT_INCOME_TOTAL'].replace(117000000, np.nan, inplace= True)\n",
    "    \n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = load_kaggle_csv('bureau.csv', num_rows)\n",
    "    bb = load_kaggle_csv('bureau_balance.csv', num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(columns= 'SK_ID_BUREAU', inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACT_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLS_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = load_kaggle_csv('previous_application.csv', num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APR_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REF_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = load_kaggle_csv('POS_CASH_balance.csv', num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = load_kaggle_csv('installments_payments.csv', num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INS_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INS_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = load_kaggle_csv('credit_card_balance.csv', num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(columns = ['SK_ID_PREV'], inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_AUC(alg, input_train, input_Y, input_test, input_test_Y) :\n",
    "    predictions_train = alg.predict(input_train)\n",
    "    predictions_prob_train = alg.predict_proba(input_train)[:,1]\n",
    "    print(\"Train Accuracy Score:\", metrics.accuracy_score(input_Y, predictions_train))\n",
    "    print(\"Train AUC Score:\", metrics.roc_auc_score(input_Y, predictions_prob_train))\n",
    "\n",
    "    predictions = alg.predict(input_test)\n",
    "    predictions_prob = alg.predict_proba(input_test)[:,1]\n",
    "\n",
    "    print(\"Accuracy Score:\", metrics.accuracy_score(input_test_Y, predictions))\n",
    "    print(\"AUC Score:\", metrics.roc_auc_score(input_test_Y, predictions_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_alg(alg, cv_df, num_folds=5, stratified = True):\n",
    "    print(\"Starting CV {}. CV shape: {}\".format(alg.__class__.__name__,cv_df.shape))\n",
    "    \n",
    "    global g_ignore_features\n",
    "    \n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "        \n",
    "    feats = [f for f in cv_df.columns if f not in g_ignore_features]\n",
    "    \n",
    "    cv_df_feats = cv_df[feats]\n",
    "    cv_df_TARGET = cv_df['TARGET']\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(cv_df_feats, cv_df_TARGET)):\n",
    "        train_x, train_y = cv_df_feats.iloc[train_idx], cv_df_TARGET.iloc[train_idx]\n",
    "        valid_x, valid_y = cv_df_feats.iloc[valid_idx], cv_df_TARGET.iloc[valid_idx]   \n",
    "        alg.fit(train_x, train_y)\n",
    "        print_AUC(alg, train_x, train_y, valid_x,  valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def fit_alg(alg, fit_train_df, fit_val_df=None):\n",
    "    print(\"Starting fit {}. fit shape: {}\".format(alg.__class__.__name__,fit_train_df.shape))\n",
    "\n",
    "    global g_ignore_features\n",
    "    \n",
    "    feats = [f for f in fit_train_df.columns if f not in g_ignore_features]\n",
    "    \n",
    "    fit_X_train = fit_train_df[feats]\n",
    "    fit_y_train = fit_train_df['TARGET']\n",
    "    \n",
    "    if fit_val_df is None :\n",
    "        alg.fit(fit_X_train, fit_y_train)\n",
    "    else :\n",
    "        fit_X_test = fit_val_df[feats]\n",
    "        fit_y_test = fit_val_df['TARGET']          \n",
    "        alg.fit(fit_X_train, fit_y_train)\n",
    "\n",
    "        print_AUC(alg, fit_X_train, fit_y_train, fit_X_test,  fit_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, clf, num_folds, stratified = False):\n",
    "    global g_ignore_features\n",
    "    \n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in g_ignore_features]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "       # clf = LGBMClassifier(\n",
    "       #     nthread=4,\n",
    "       #     n_estimators=10000,\n",
    "       #     learning_rate=0.02,\n",
    "       #     num_leaves=34,\n",
    "       #     colsample_bytree=0.9497036,\n",
    "       #     subsample=0.8715623,\n",
    "       #     max_depth=8,\n",
    "       #     reg_alpha=0.041545473,\n",
    "       #     reg_lambda=0.0735294,\n",
    "       #     min_split_gain=0.0222415,\n",
    "       #     min_child_weight=39.3259775,\n",
    "       #    silent=-1,\n",
    "       #    verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 100)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances-01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Bureau df shape: (305811, 122)\n",
      "Process bureau and bureau_balance - done in 26s\n"
     ]
    }
   ],
   "source": [
    "#def prepare_data(debug = False):\n",
    "num_rows = 10000 if debug else None\n",
    "df = application_train_test(num_rows)\n",
    "with timer(\"Process bureau and bureau_balance\"):\n",
    "    bureau = bureau_and_balance(num_rows)\n",
    "    print(\"Bureau df shape:\", bureau.shape)\n",
    "    df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process previous_applications\"):\n",
    "    prev = previous_applications(num_rows)\n",
    "    print(\"Previous applications df shape:\", prev.shape)\n",
    "    df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process POS-CASH balance\"):\n",
    "    pos = pos_cash(num_rows)\n",
    "    print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "    df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process installments payments\"):\n",
    "    ins = installments_payments(num_rows)\n",
    "    print(\"Installments payments df shape:\", ins.shape)\n",
    "    df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "\n",
    "with timer(\"Process credit card balance\"):\n",
    "    cc = credit_card_balance(num_rows)\n",
    "    print(\"Credit card balance df shape:\", cc.shape)\n",
    "    df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "del bureau\n",
    "del prev\n",
    "del pos\n",
    "del ins  \n",
    "del cc\n",
    "gc.collect()\n",
    "#with timer(\"Run LightGBM with kfold\"):\n",
    "    #feat_importance = kfold_lightgbm(df, num_folds= 5, stratified = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[col for col in df.columns if df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "ignore_features_median =  ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV']\n",
    "relevant_features_median = [col for col in df.columns if col not in ignore_features_median]\n",
    "df_imp = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "for col in relevant_features_median :\n",
    "    col_median = df_imp[col].median()\n",
    "    if math.isnan(col_median) : \n",
    "        print(\"is nan:\", col)\n",
    "        col_median=0.0\n",
    "    df_imp[col].fillna(col_median, inplace=True)\n",
    "train_df_imp = df_imp[df_imp['TARGET'].notnull()]\n",
    "test_df_imp = df_imp[df_imp['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp.columns[np.isfinite(df_imp).all()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size= 0.3, random_state=1001)\n",
    "for train_index, val_index in split.split(train_df, train_df['TARGET']):\n",
    "    X_train, X_val = train_df.loc[train_index], train_df.loc[val_index]\n",
    "    X_train_imp, X_val_imp = train_df_imp.loc[train_index], train_df_imp.loc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TARGET'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['TARGET'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, X_train.shape, X_val.shape, X_train_imp.shape, X_val_imp.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isfinite(X_train_imp).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_imp.columns[np.isfinite(X_train_imp).all()==False]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_imp.isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "ignore_features_imputer =  ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV']\n",
    "relevant_features_imputer = [col for col in df.columns if col not in ignore_features_imputer]\n",
    "imp.fit(df[relevant_features_imputer])\n",
    "train_df_imp = pd.DataFrame(imp.transform(train_df[relevant_features_imputer]))\n",
    "train_df_imp = pd.concat([train_df[['TARGET','SK_ID_CURR']], train_df_imp], axis=1)\n",
    "test_df_imp = pd.DataFrame(imp.transform(test_df[relevant_features_imputer]).replace([np.inf, -np.inf], np.nan))\n",
    "test_df_imp = pd.concat([test_df[['TARGET','SK_ID_CURR']], test_df_imp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[relevant_features_median].iloc[5687:5689, 654:657].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_imp[relevant_features_median].iloc[5687:5689, 654:657].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_imp.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df_imp.isnull().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=30, max_depth=8,\n",
    "    learning_rate=0.01, n_estimators=5000,  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.1, random_state=27, n_jobs=-1, silent=False\n",
    ")\n",
    "\n",
    "with timer(\"fit lgb.LGBMClassifier\"):\n",
    "    fit_alg(lgb_clf, X_train, X_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "        learning_rate =0.05,\n",
    "        n_estimators=2000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        silent=False,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "\n",
    "with timer(\"fit XGBClassifier\"):\n",
    "    fit_alg(xgb_clf, X_train, X_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(penalty='l1', C=1, random_state=1001)\n",
    "\n",
    "with timer(\"fit LogisticRegression\"):\n",
    "    fit_alg(log_clf, X_train_imp, X_val_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=5000, \n",
    "                        max_leaf_nodes=30, \n",
    "                        max_features=0.1,\n",
    "                        max_depth=5,\n",
    "                        bootstrap=True, n_jobs=-1, random_state=27)\n",
    "with timer(\"fit RandomForestClassifier\"):\n",
    "    fit_alg(rnd_clf, X_train_imp, X_val_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['TARGET'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_imp_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_val['TARGET'].reset_index(),pd.DataFrame(seclvl_train_all)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.predict_proba(X_val_feats)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(seclvl_train_all).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "X_val_imp_feats = X_val_imp[feats]\n",
    "X_val_feats = X_val[feats]\n",
    "\n",
    "gbm_level2 = xgb.XGBClassifier(\n",
    " learning_rate = 0.01,\n",
    " n_estimators= 1000,\n",
    " max_depth=2,\n",
    " min_child_weight=1,\n",
    " gamma=0.1,  \n",
    " subsample=0.6, \n",
    " colsample_bytree=1,\n",
    " reg_alpha = 0.2,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " silent=False,\n",
    " scale_pos_weight=1)\n",
    "\n",
    "seclvl_train_all = np.concatenate(( np.array([log_clf.predict_proba(X_val_imp_feats)[:,1]]).T,\n",
    "                                np.array([rnd_clf.predict_proba(X_val_imp_feats)[:,1]]).T,\n",
    "                                np.array([xgb_clf.predict_proba(X_val_feats)[:,1]]).T,\n",
    "                                np.array([lgb_clf.predict_proba(X_val_feats)[:,1]]).T\n",
    "                            ), axis=1)\n",
    "\n",
    "level2_df = pd.concat([X_val['TARGET'].reset_index(),pd.DataFrame(seclvl_train_all)], axis=1)\n",
    "cv_alg(gbm_level2, level2_df)\n",
    "fit_alg(gbm_level2, level2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path= \"D:/wangh/Kaggle/HomeCredit/result_submission7_{}{}.csv\"\n",
    "\n",
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "\n",
    "for clf, test_data_df in [\n",
    "        (lgb_clf, test_df), \n",
    "        (xgb_clf, test_df),\n",
    "        (log_clf, test_df_imp), \n",
    "        (rnd_clf, test_df_imp),\n",
    "    ]: \n",
    "    result_df=pd.DataFrame()\n",
    "    result_df['SK_ID_CURR'] = test_df['SK_ID_CURR']\n",
    "    result_df['TARGET'] = clf.predict_proba(test_data_df[feats])[:, 1]\n",
    "\n",
    "    submission_filepath = submission_path.format(clf.__class__.__name__,'_1stlvl')\n",
    "    result_df.to_csv(submission_filepath, index=False, float_format='%.6f')\n",
    "    \n",
    "    del result_df\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seclvl_test=test_df[feats]\n",
    "\n",
    "feats = [f for f in test_df.columns if f not in g_ignore_features]\n",
    "test_df_imp_feats = test_df_imp[feats]\n",
    "test_df_feats = test_df[feats]\n",
    "\n",
    "\n",
    "seclvl_train_all = np.concatenate(( np.array([log_clf.predict_proba(test_df_imp_feats)[:,1]]).T,\n",
    "                                np.array([rnd_clf.predict_proba(test_df_imp_feats)[:,1]]).T,\n",
    "                                np.array([xgb_clf.predict_proba(test_df_feats)[:,1]]).T,\n",
    "                                np.array([lgb_clf.predict_proba(test_df_feats)[:,1]]).T\n",
    "                            ), axis=1)\n",
    "\n",
    "result_df=pd.DataFrame()\n",
    "result_df['SK_ID_CURR'] = test_df['SK_ID_CURR']\n",
    "result_df['TARGET'] = gbm_level2.predict_proba(pd.DataFrame(seclvl_train_all))[:, 1]\n",
    "\n",
    "submission_filePath = submission_path.format(gbm_level2.__class__.__name__, '_2ndlvl')\n",
    "result_df.to_csv(submission_filePath, index=False, float_format='%.6f')\n",
    "\n",
    "del test_df_imp_feats\n",
    "del test_df_feats\n",
    "del result_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV']]\n",
    "\n",
    "df_feats = train_df[feats]\n",
    "df_TARGET = train_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:390: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's auc: 0.738788 + 0.0032822\n",
      "[40]\tcv_agg's auc: 0.739973 + 0.00340554\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(data=df_feats, label=df_TARGET)\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "          'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 10 ,\n",
    "          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n",
    "          'min_split_gain':.01, 'min_child_weight':1}\n",
    "lgb_result=lgb.cv(params, lgb_train, stratified=True, metrics={'auc'}, num_boost_round=5000,\n",
    "                      nfold=5, early_stopping_rounds=150, verbose_eval=20)\n",
    "lgb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grid search\n",
    "lgb_param_test1 = {\n",
    "    'max_depth':[8], #range(2,10,2),\n",
    "    'num_leaves':[30], #range(30,60,10),\n",
    "    'min_child_samples':range(200,1000,300)\n",
    "    'min_child_weigh':range(20,100,20)\n",
    "    \n",
    "}\n",
    "lgb_gsearch1 = GridSearchCV(estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=48, max_depth=7,\n",
    "    learning_rate=0.01, n_estimators=len(lgb_result['auc-mean']),  \n",
    "    objective='binary', min_split_gain=0.02, min_child_weight=1, \n",
    "    min_child_samples=300, subsample=0.85, subsample_freq=0, colsample_bytree=0.95,\n",
    "    reg_alpha=0.1, reg_lambda=0.1, random_state=1001, n_jobs=-1, silent=False\n",
    "), param_grid = lgb_param_test1, scoring='roc_auc',n_jobs=4,verbose=10,iid=False, cv=5)\n",
    "\n",
    "\n",
    "lgb_gsearch1.fit(df_feats, df_TARGET, eval_metric='auc', verbose = 50)\n",
    "lgb_gsearch1.grid_scores_, lgb_gsearch1.best_params_, lgb_gsearch1.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train, train_target, useTrainCV=True, cv_folds=5, early_stopping_rounds=150, val_percent=0.2):\n",
    "    \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size= val_percent, random_state=1001)\n",
    "    for train_index, test_index in split.split(train, train_target):\n",
    "        dtrain, dtest = train.loc[train_index], train.loc[test_index]\n",
    "        dtrain_target, dtest_target = train_target.loc[train_index], train_target.loc[test_index]\n",
    "            \n",
    "            \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain.values, label=dtrain_target.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics={'auc'}, early_stopping_rounds=early_stopping_rounds)\n",
    "        print(\"n_estimators use : %d\" % cvresult.shape[0])\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, dtrain_target,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\ndtrain Model Report\")\n",
    "    print(\"dtrain Accuracy : %.4g\" % metrics.accuracy_score(dtrain_target, dtrain_predictions))\n",
    "    print(\"dtrain AUC Score: %f\" % metrics.roc_auc_score(dtrain_target, dtrain_predprob)) \n",
    "    \n",
    "    #     Predict on validation data:\n",
    "    dtest_predictions = alg.predict(dtest)\n",
    "    dtest_predprob = alg.predict_proba(dtest)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\ndtest Model Report\")\n",
    "    print(\"dtest Accuracy : %.4g\" % metrics.accuracy_score(dtest_target, dtest_predictions))\n",
    "    print(\"dtest AUC Score: %f\" % metrics.roc_auc_score(dtest_target, dtest_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        silent=False,    \n",
    "        seed=1001)\n",
    "modelfit(xgb1, df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, \n",
    "                                                  n_estimators=xgb1.get_params()['n_estimators'], \n",
    "                                        max_depth=5,\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, \n",
    "                                                         random_state=1001, silent=False,  seed=1001, verbose=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',n_jobs=4,verbose=10,iid=False, cv=5)\n",
    "gsearch1.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=xgb1.get_params()['n_estimators'],\n",
    "                                                  max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "                                                  gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,\n",
    "                                                  random_state=27, silent=False, seed=27), \n",
    "                       param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False,verbose=10, cv=5)\n",
    "gsearch3.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=1000, \n",
    "                                                  max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "                                                  gamma=gsearch3.best_params_['gamma'], \n",
    "                                        subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=2, verbose=10,silent=False,\n",
    "                                                  scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, verbose=10,cv=5)\n",
    "gsearch4.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=232,\n",
    "                                                  max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "                                                  gamma=gsearch3.best_params_['gamma'],  \n",
    "                                                  subsample=gsearch4.best_params_[\"subsample\"], \n",
    "                                        colsample_bytree=gsearch4.best_params_[\"colsample_bytree\"],\n",
    "                                                  silent=False,\n",
    "                                        objective= 'binary:logistic', nthread=2, verbose=10,\n",
    "                                                  scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth==gsearch1.best_params_['max_depth'],\n",
    "        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "        gamma=gsearch3.best_params_['gamma'], \n",
    "        subsample=gsearch4.best_params_[\"subsample\"],\n",
    "        colsample_bytree=gsearch4.best_params_[\"colsample_bytree\"],\n",
    "        reg_alpha=gsearch6.best_params_[\"reg_alpha\"],\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        scale_pos_weight=1,\n",
    "        silent=False,\n",
    "        seed=27)\n",
    "modelfit(xgb3, df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=5000,\n",
    "        max_depth=gsearch1.best_params_['max_depth'],\n",
    "        min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "        gamma=gsearch3.best_params_['gamma'],\n",
    "        subsample=gsearch4.best_params_[\"subsample\"],\n",
    "        colsample_bytree=gsearch4.best_params_[\"colsample_bytree\"],\n",
    "        reg_alpha=gsearch6.best_params_[\"reg_alpha\"],\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=8,\n",
    "        silent=False,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "modelfit(xgb4, df_feats, df_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
